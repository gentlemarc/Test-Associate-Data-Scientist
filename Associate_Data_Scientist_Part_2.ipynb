{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Associate Data Scientist - Part 2",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1bnbpL0dCh0BeFEx1u9S5YJcY85mlbaJs",
      "authorship_tag": "ABX9TyP4p+l8UsEPdJASuTc0nEA3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gentlemarc/Test-Associate-Data-Scientist/blob/master/Associate_Data_Scientist_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTD8A8zjuvgh",
        "colab_type": "text"
      },
      "source": [
        "# Associate Data Scientist - Technical Test - Part 2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TixHv-QvP4C",
        "colab_type": "text"
      },
      "source": [
        "In the second part of this assignment, I'm going to perform a topic model analysis on the provided dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTLPdQYuzG1Q",
        "colab_type": "text"
      },
      "source": [
        "## 1 What is Topic Modelling?\n",
        "\n",
        "Topic modeling is an unsupervised technique that intends to analyze large volumes of text data by clustering the documents into groups. In the case of topic modeling, the text data do not have any labels attached to it. Rather, topic modeling tries to group the documents into clusters based on similar characteristics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aUfoVpsqnof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRAoGqSI41XK",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Approaches to the Problem\n",
        "\n",
        "There are several existing algorithms we can use to perform the topic modeling. The most common of them are\n",
        "\n",
        "\n",
        "* **Latent Semantic Analysis (LSA/LSI)**\n",
        "* **Probabilistic Latent Semantic Analysis (pLSA)**\n",
        "* **Latent Dirichlet Allocation (LDA)**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOVhaRK__Sb3",
        "colab_type": "text"
      },
      "source": [
        "I will be using the Latent Dirichlet Allocation (LDA) from Gensim package along with the Mallet’s implementation (via Gensim). **Mallet has an efficient implementation of the LDA.** It is known to run faster and gives better topics segregation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLdZfy6D_4VJ",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 LDA Explanation\n",
        "\n",
        "LDA’s approach to topic modeling is it considers each document as a collection of topics in a certain proportion. And each topic as a collection of keywords, again, in a certain proportion.\n",
        "\n",
        "Once you provide the algorithm with the number of topics, all it does it to rearrange the topics distribution within the documents and keywords distribution within the topics to obtain a good composition of topic-keywords distribution.\n",
        "\n",
        "When I say topic, what is it actually and how it is represented?\n",
        "\n",
        "A topic is nothing but a collection of dominant keywords that are typical representatives. Just by looking at the keywords, you can identify what the topic is all about.\n",
        "\n",
        "The following are key factors to obtaining good segregation topics:\n",
        "\n",
        "\n",
        "\n",
        "1. The quality of text processing.\n",
        "2. The variety of topics the text talks about.\n",
        "3. The choice of topic modeling algorithm.\n",
        "4. The number of topics fed to the algorithm.\n",
        "5. The algorithms tuning parameters.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZHvW5mTA1Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIcN4I0hA3j-",
        "colab_type": "text"
      },
      "source": [
        "## 2 Load the dataset and Import the libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFQ4Cu5kCt00",
        "colab_type": "text"
      },
      "source": [
        "First step is to upload the data as .zip (colab doesn't allow to upload folders)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QVMFnsvEBiZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b979e16f-988b-4cea-8582-944dff3f3493"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "filename = '/content/documents_challenge.zip'\n",
        "\n",
        "with ZipFile(filename, 'r') as zip:\n",
        "  zip.extractall()\n",
        "print('Done')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56_m6_0FCksK",
        "colab_type": "text"
      },
      "source": [
        "Like we did in the first part, we will merge all the documents in the same dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP0XUSaeBXaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "f96183b6-0392-451e-d613-6e16ee1fe958"
      },
      "source": [
        "#Import some libraries\n",
        "import pandas as pd\n",
        "import os \n",
        "import sys\n",
        "from collections import defaultdict\n",
        "import re\n",
        "\n",
        "\n",
        "# Get all the url files in all the folders and append into a list\n",
        "data_folder = r'/content/documents_challenge'\n",
        "\n",
        "#we shall store all the file names in this list\n",
        "filelist = []\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk(data_folder):\n",
        "    for file in files:\n",
        "        #append the file name to the list\n",
        "        filelist.append(os.path.join(root,file))\n",
        "        #print(file)\n",
        "\n",
        "#Print the len of the data\n",
        "print(\"Lenght of file\", len(filelist))\n",
        "\n",
        "print(\"Example of data\")\n",
        "print(filelist[0:3])\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lenght of file 23128\n",
            "Example of data\n",
            "['/content/documents_challenge/Conference_papers/en/article-13-22-en.txt', '/content/documents_challenge/Conference_papers/en/article-20-2-en.txt', '/content/documents_challenge/Conference_papers/en/article-25-1-en.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzHPTDHjEloc",
        "colab_type": "text"
      },
      "source": [
        "Join again the dataset to work easy with the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xy_JPAQDKb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "34641a07-c109-4278-ae49-ade2e8fa0e5d"
      },
      "source": [
        "#Let's merge all the data in a dataframe with columns name \n",
        "\n",
        "#results = defaultdict(list)\n",
        "\n",
        "results = []\n",
        "\n",
        "for files in filelist:\n",
        "\n",
        "        #Amazon Reviews. \n",
        "        if('APR' in files):\n",
        "            #Create a column to put the type file, variable to predict.\n",
        "            type_file = 'APR'\n",
        "            lang = re.search(r'APR/(.*?)/apr-', files).group(1)\n",
        "\n",
        "        #Conference Papers.    \n",
        "        elif('Conference_papers' in files):\n",
        "           \n",
        "            type_file = 'Conference Paper'\n",
        "            lang = re.search(r'Conference_papers/(.*?)/article', files).group(1)\n",
        "        \n",
        "        #PAN 11\n",
        "        elif('PAN11' in files):\n",
        "            type_file = 'PAN11'\n",
        "            lang = re.search(r'PAN11/(.*?)/pan-', files).group(1)\n",
        "            #lang = lang.split(\"\\\\\" )[1]\n",
        "\n",
        "        #Wikipedia\n",
        "        else:\n",
        "            type_file = 'Wikipedia'\n",
        "            lang = re.search(r'Wikipedia/(.*?)/', files).group(1)\n",
        "    \n",
        "        try:\n",
        "            with open(files, \"r\",  encoding=\"UTF-8\") as file_open:\n",
        "\n",
        "                #results[\"file\"] = type_file\n",
        "                #results[\"lang\"] = lang\n",
        "                #results[\"text\"].append(file_open.read())\n",
        "                \n",
        "                results.append ([lang, type_file, file_open.read()])\n",
        "\n",
        "        except:\n",
        "            print(\"Error in file: \", file)\n",
        "\n",
        "#Create the DataFrame\n",
        "corpus_df = pd.DataFrame(results, columns=['Language', 'Category', 'Text'])\n",
        "\n",
        "#Print the 10 first values\n",
        "corpus_df.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Language</th>\n",
              "      <th>Category</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>DICOVALENCE, a valence dictionary of\\n French,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>DI-LSA\\n The technique proposed independently ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>The methodology consists in introducing semant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>In order to do so, we evaluate our approaches ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>These experiments show that it could be risky ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>For each EDU, annotators identify how outcomes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Abstract. In this article, we analyse the modi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>We also obtain a list of more than 200 multiwo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>When the configurator used is itself\\n object-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Let be C a finite set of n concepts, a concept...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Language          Category                                               Text\n",
              "0       en  Conference Paper  DICOVALENCE, a valence dictionary of\\n French,...\n",
              "1       en  Conference Paper  DI-LSA\\n The technique proposed independently ...\n",
              "2       en  Conference Paper  The methodology consists in introducing semant...\n",
              "3       en  Conference Paper  In order to do so, we evaluate our approaches ...\n",
              "4       en  Conference Paper  These experiments show that it could be risky ...\n",
              "5       en  Conference Paper  For each EDU, annotators identify how outcomes...\n",
              "6       en  Conference Paper  Abstract. In this article, we analyse the modi...\n",
              "7       en  Conference Paper  We also obtain a list of more than 200 multiwo...\n",
              "8       en  Conference Paper  When the configurator used is itself\\n object-...\n",
              "9       en  Conference Paper  Let be C a finite set of n concepts, a concept..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mqYuIhiEzGw",
        "colab_type": "text"
      },
      "source": [
        "Load some libraries for text pre-processing later. We will use spacy model for lemmatization.\n",
        "\n",
        "\n",
        "**Lemmatization means converting a word to its root word**. For example: the lemma of the word ‘machines’ is ‘machine’. Other example:, ‘walking’ –> ‘walk’, ‘mice’ –> ‘mouse’ and so on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_ZuZSuwAkBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "266a6f77-5367-4bf8-e0e7-cc3eedb7c58e"
      },
      "source": [
        "# Download NLTK stopwords\n",
        "import nltk\n",
        "\n",
        "\n",
        "#We will load the stopwords for the different languages which we have the data.\n",
        "nltk.download('stopwords')\n",
        "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
        "es_stop = set(nltk.corpus.stopwords.words('spanish'))\n",
        "fr_stop = set(nltk.corpus.stopwords.words('french'))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJPWbVb2u3p2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "25ac1945-8acd-4072-bb2f-3b00ffe6d463"
      },
      "source": [
        "#print an example of Spanish stopwords\n",
        "\n",
        "es_list = list(es_stop) \n",
        "es_list[0:15]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['todo',\n",
              " 'tenido',\n",
              " 'hubisteis',\n",
              " 'sin',\n",
              " 'estarás',\n",
              " 'haya',\n",
              " 'esté',\n",
              " 'tenía',\n",
              " 'del',\n",
              " 'hubieran',\n",
              " 'hay',\n",
              " 'esas',\n",
              " 'pero',\n",
              " 'mis',\n",
              " 'estuvieras']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUfHO2OTFaev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3261add7-ca00-4daa-cef5-abca67dc4bf4"
      },
      "source": [
        "#Download the data for lemmatization\n",
        "!python3 -m spacy download en\n",
        "!python3 -m spacy download es\n",
        "!python3 -m spacy download fr"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.6.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting es_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz (16.2MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2MB 697kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (49.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: es-core-news-sm\n",
            "  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.2.5-cp36-none-any.whl size=16172934 sha256=12b8eea84a412ab5ff00dae2f9da1536b8eb2e1836d7bc10b71d21803426e875\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c864mhto/wheels/05/4f/66/9d0c806f86de08e8645d67996798c49e1512f9c3a250d74242\n",
            "Successfully built es-core-news-sm\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/es_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/es\n",
            "You can now load the model via spacy.load('es')\n",
            "Collecting fr_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (49.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp36-none-any.whl size=14727027 sha256=9be3af5c5cfe095d45e6f2004453b38ab90dc17a3b03935f95bc615760c196b8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4mzhssuv/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/fr\n",
            "You can now load the model via spacy.load('fr')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N7z_s8tHyjt",
        "colab_type": "text"
      },
      "source": [
        "**Import Necessary Packages:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ_BM6gBHrkx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "51b819e3-a2d4-407e-cd72-198ce8e61404"
      },
      "source": [
        "# pyLDAvis is a package we will use for data visualization. We will explain more later\n",
        "\n",
        "!pip install pyLDAvis"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.35.1)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.0.5)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 17.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (20.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (49.6.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (8.4.0)\n",
            "Building wheels for collected packages: pyLDAvis, funcy\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=2e6105c34e2cb3d845b16914eff594285c18411b17c31b78bbd5e1f5bb66c10a\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=17bc5efb90173d938a86ab560d54fa75dfe805592182f743dcb0835a7a85d8e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
            "Successfully built pyLDAvis funcy\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.14 pyLDAvis-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xip4cz9GIGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "#Numpy and Pandas for data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis # Visualize the topics-keywords\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T8krzGhK61E",
        "colab_type": "text"
      },
      "source": [
        "### Split the Dataset per Language.\n",
        "\n",
        "To explain better the topic model analysis, we are going to split the dataset between French, Spanish and English documents. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa1GeGy8K4ws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "fd4f5a66-8465-44b8-a40b-875907559983"
      },
      "source": [
        "corpus_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Language</th>\n",
              "      <th>Category</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>The train/dev/test split is\\n the same as in (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Contribution of conceptual vectors to lexical ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>As it would not be then reasonable nor easy to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Interaction Grammars\\n We briefly introduce IG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>en</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>The latter, rather unusual,\\n test configurati...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Language          Category                                               Text\n",
              "0       en  Conference Paper  The train/dev/test split is\\n the same as in (...\n",
              "1       en  Conference Paper  Contribution of conceptual vectors to lexical ...\n",
              "2       en  Conference Paper  As it would not be then reasonable nor easy to...\n",
              "3       en  Conference Paper  Interaction Grammars\\n We briefly introduce IG...\n",
              "4       en  Conference Paper  The latter, rather unusual,\\n test configurati..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbBaDLzmILS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_df = corpus_df.loc[corpus_df['Language'] == 'en']\n",
        "spanish_df = corpus_df.loc[corpus_df['Language'] == 'es']\n",
        "french_df = corpus_df.loc[corpus_df['Language'] == 'fr']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhEKMe5cMycj",
        "colab_type": "text"
      },
      "source": [
        "Convert datasets to lists. Doing that we make easy to see the full content and clean them. Let's print some data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U39em8RoMwcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "16688aaf-852c-4016-9717-b88801746612"
      },
      "source": [
        "#Convert to list and print the 5 first and the 5 last results\n",
        "english = english_df.Text.values.tolist()\n",
        "\n",
        "print(\"First English results\")\n",
        "print(english[0:5])\n",
        "print(\"\\n\")\n",
        "print(\"Last English Results\")\n",
        "print(english[-5:])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First English results\n",
            "['DICOVALENCE, a valence dictionary of\\n French, formerly known as PROTON (van den\\n Eynde and Mertens, 2002), which has been\\n based on the pronominal approach. In version\\n 1.1, this dictionary details the subcategorization\\n frames of more than 3,700 verbs (table 1\\n gives an example of a DICOVALENCE entry).\\n We extracted the simple and multiword prepositions\\n it contains (i.e. more than 40), as well\\n as their associated semantic classes.', 'DI-LSA\\n The technique proposed independently by Bestgen\\n (2002), DI-LSA, is very similar to the one proposed by\\n Turney and Littman. The main difference is at the level\\n of the benchmarks used to evaluate a word. While\\n SO-LSA uses a few benchmarks selected a priori,\\n DI-LSA is based on lexicons that contain several\\n hundred words rated by judges on the\\n pleasant-unpleasant scale This kind of lexicon was\\n initially developed in the field of content analysis. As\\n early as 1965, Heise proposed to constitute a valence\\n dictionary by asking judges to rate a sample of the most\\n frequent English words on the pleasant-unpleasant scale.\\n Since then, lexicons for various languages have been\\n made up (Hogenraad et al., 1995; Whissell et al., 1986).\\n As an example, Table 2 shows the evaluation scores of\\n several words randomly extracted from the dictionary\\n and used in the present study (Hogenraad, Bestgen &\\n Nysten, 1995).\\n specific whole set of benchmarks is selected from the\\n lexicon. More precisely, the unknown valence of a word\\n corresponds to the average valence of its thirty closer\\n neighbours, neighbourhood being identified on the basis\\n of the cosine in the semantic space extracted by LSA. To\\n evaluate this index, Bestgen (2002) compared the\\n predicted values for words with their actual values\\n according to the dictionary and obtained correlations\\n ranging from 0.56 to 0.70.', 'The methodology consists in introducing semantic information\\n by using a class-based statistical language model for which\\n classes directly correspond to IF entries. With this new\\n Language Model, the ASR module can analyze into IF an\\n important amount of dialogue data: 35% dialogue words; 58%\\n speaker turns.', 'In order to do so, we evaluate our approaches according to precision and recall12\\n at different points in the n-best list or at different threshold values. We also\\n compute typical information retrieval measures to estimate the relevance of the\\n ranking: mean average precision (MAP), mean reciprocal rank (MRR).', 'These experiments show that it could be risky to rely on confidence or growth rate\\n values to make predictions since they do not capture the notion of robustness. The\\n stability of the MODL level is a sign of robustness; in the following experiments, we\\n show that patterns with negative level values are non-significant and the ones with\\n positive level values are patterns of interest.']\n",
            "\n",
            "\n",
            "Last English Results\n",
            "[' What would inexperienced\\nschool, just out of school, become head of household? Responded to their diligence, of his devotion,\\nbut not trusted in their abilities. He was encouraged to know that all Villaverde knew him,\\nthat there for some time now, all his considerations of the most deserved villaverdinos conspicuous.\\nHe was encouraged by this, but while it looked somewhat painful Value humiliation! God helps those\\nwho help.\\n\\nXI\\n\\nLeft me sad and dejected Andrew conversation. The generosity of that servant, faithful in all times\\nto their owners, filled me with admiration. Andrew had no family, never knew his parents; he was\\norphaned at an early age and spent her childhood in the countryside, playing rudísimas work, serving\\npeople who treated him badly.\\n\\nI used to remember the bitterness of that time, and had thoroughly their work and their sentences,\\nbut never heard him complain of the harshness their first masters,\\nand never let slip a word against them.\\n\\nMy father took the ranch where he lived, he took his service, and\\nsoon the boy was worthy of love from all of us.\\n\\nHe would not marry.\\n\\n- Why? - Answered .-- What? I do not need the family.\\n\\nYou are my family, You are everything to me!\\n\\nWhen the family came to less, and my aunt could no longer repay their services, Andrew be more useful\\nto us that wishes to thrive, we left and went to settle in a town nearby. With their savings\\ndepleted and having very secretly provide for the needs family, started\\na shop, where, through hard work and savings made a piquillo that\\n- as I said, - was enough to live and the ladies auxiliary.\\n\\nMy Aunt Carmen fell sick, and Andres said :--«¡ A Villaverde! I live not far from the family.\\nNow more than ever they need me. What good is going to see them from\\ntime to time?\\n\\n\"\\n\\nTransferred, cheapening the \"little shop\", rolled the mat, and came to Villaverde. In Pluviosilla\\nhad been better and would have thrived easily, but as his object\\nwas to live close to my aunts hesitate to move to the Buddhist city.\\n\\nWhile he lived in Santa Rosa came every week, without fail ever, and rain poured down. Between\\neight and nine in the morning, there was Andrew in his horse, heavily\\nladen with fruit, seeds, and poultry.\\n\\nUpon leaving, Sunday evening or very early Monday, leaving no to put in the dining room four or\\nfive dollars, perhaps much of their profits.\\n\\nFrom time to time at school I received a gift from Him: great fruit, mangos Cordovan AMATEC pineapples,\\noranges and limes. Sometimes money spent after harvest snuff and coffee. Upon receipt of the\\nten or twelve dollars :--«¡ Andrés told me money is!\\n\\n\"And I\\'m glad I for him and my aunts.\\n\\nOnce I got a box of cigars. I gave it Ricardo Tejeda.\\n\\nWithin the letter of Aunt Pepa came a strip of paper on which he wrote Andrew, that your letter\\nclumsy and awkward: \"So that\\'ll suck. Already a big boy, and you\\'ll like the good cigars.\\nSaid I love a good cigar conceals the arranquera swinging.\\n\\n\"\\n\\nSo I did not like snuff. Ricardo smoked all the cigars.\\n\\nOn Sunday I had made a dandy:\\n\\n- Rodolfo: give me one of those of our land!\\n\\nThe tobacco realized, he did not need to hide the arranquera.\\n\\nThe faithful servant, established in Villaverde, back in the neighborhood of San Antonio, in\\na store it was called \"legality\", was, as always, an order for aunts. Course decided that they\\nwill attend, and therefore paid more than fair.\\n\\n- That nothing is missing; - repeat - we will see how far reaching the pita!\\n\\nNone of this I said, I learned later from the lips of Aunt Pepa. The good old merely offer so\\nperhaps it was not possible to do - spend everything he had.\\n\\nNeither Andrew nor his health \"piquillo\" resist spending four years and four years, when least\\nwould be necessary for me to have a title and I might try to mate the Dr. Sarmiento or Mr. Castro\\nPerez.\\n\\nI had to settle for what the fate in store for me. I resigned myself to leave the books and give\\nto the joys of student life, to search Villaverde which may not be missing: a destinejo each\\nmonth to give me some hard.\\n\\nI relied on the kindness of my countrymen, in the benevolence of our friends, for whom was no\\nmystery the precarious situation of my aunts. I flattered myself that the idea were to cease\\nin that house embarrassments.\\n\\nPerhaps in the future, we would enjoy life so much easier; and, indeed, I was flattered to be\\nthe boss of the house. With more money the patient would be better served, we would see relief,\\nand perhaps regain health.\\n\\nNo one contacted my projects.\\n\\nI tried, not without difficulty, to see me happy and contented. I was embarrassed and sad. I think\\nI miss that house, and I felt degraded upon receipt of the elderly\\npoor as I needed, no, because filial affection I saw them, and motherly\\nlove you always treat me away from my mind the whole idea mean and\\nhumiliating every thought.\\n\\nFor several days I was miserable. For the night, good short hour, I shut myself up in my room,\\nmetíame in bed, and I started to read. I read pages and pages, without considering the concepts.\\nIn a very old cabinet I found myself several Books: A History of Napoleon, do not remember what\\nclassic warfare, and oh joy! two or three volumes of Walter Scott.\\n\\nI took one, \"The Bride of Lammermoor.\" In a few nights you gave purpose. After finishing the\\nlast page I noticed that this reading had been useless. My head it\\nwas not for novels.\\n\\nEarly, before they woke up my aunts, I went out to the patio. There I washed myself in a great basin\\nthat from the day before put to me on the edge of the source, among\\nthe pots flowering, under the canopy of an umbrella-shaped bell whose\\nsatin floripondio swung quickens the breath of morning winds, while\\nbranches in cages and the birds sang the incomparable autumn dawn.\\n\\nFrolicked in the water spout and overflow into the pylon fell. On the surface of liquid crystalline\\nrowed fallen petals and flowers at night. It I fancied skiff, rowed\\ngondolillas wonderful that invisible beings.\\n\\nI returned to my room. Soon Angelina was beginning his morning chore. Soon echoed in the corridor\\nthe sound of her broom.\\n\\nIn her lips whispered cheerful ditty like a soft echo, barely perceptible,\\nto which the winged musicians sang in his prison of reeds and the\\nglass of orange trees and adorned with yellow apples.\\n\\nUpon leaving I stopped to talk to the maid. Tratábala me as a favorite sister, and sought to inspire\\nconfidence, but she was always reserved and scary. No But I soon realize that breeze that hit\\nme so prudish in Angelina the first day, was just shy of kindness,\\ntoo, in harmony with nature and beauty, very natural in one who had\\nhad so much to mourn.\\n\\nThe talk, which began with a flattering phrase in praise of his diligence,\\nhe would soon entangled little, without knowing how, and more than\\nonce Pepilla aunt came to interrupt our conversation.\\n\\nThose sweet moments!\\n\\nAngelina, standing near the railing, wrapped in a shawl, fallen arms with pleasant indolence in\\nhis hands the broom lazy. I straddled a chair, or set foot on the crossbar. It, listen baby, I, bathed\\nin light of her wide eyes.\\n\\nAt the time, if we announced a noise coming Aunt Pepa, without reason, without knowing why, we said\\ngoodbye in a hurry, and I went out due to more distant neighborhoods.\\n\\nI returned to breakfast. And the house was ready, scanning the broker, arranged the living room,\\nprepared the table. The girl used to sit next to me. I attended and I served as a loving sister\\npreferred the little boy, ready to satisfy all my desires and whims,\\nread his thoughts.\\n\\nMy aunt seemed to revel in the sweet and simple fellowship. Anyone who saw us together the three,\\nwould have believed that we were two brothers, and that the old woman was our mother.\\n\\nBreakfast often lasted an hour. Aunt Pepa talking to your taste. Me and Angelina did not felt\\ntime pass.\\n\\nThe old lady got up to go about their business, and passing behind of us stopped and caressed\\nus, to me, shaking my head between her hands to her patting him on each cheek.\\n\\nA campanillazo used to terminate the conversation. Aunt Carmen was called.\\n\\n- Where is my Angelina? What does my Angelina does not come?\\n\\nXII\\n\\nThen would I greet the sick. The poor thing went very bad nights. He suffered from insomnia, seizure\\nattacks and was forced to leave the bed for a few hours and walk through the room, leaning\\non the arm of Angelina.\\n\\n- It gives me a Sister of Charity! - I said .-- Me Aunt Carmen has no poor thing restful sleep.\\n\\nAnd Angelina:\\n\\n- Poor you! You are very good, very good! What obligation to ensure\\nyou have my dream?\\n\\nIt gives me penalty call, yes, I\\'m sorry!\\n\\nIf I do it because I do not want to wake Pepa. The unfortunate falls\\nexhausted, and is no longer for that!\\n\\nWhile I was talking to the patient, the distant runner met the disciples: twenty or thirty little\\nchildren of the principal families of Villaverde, a mischievous cherub choir and pampered.\\n\\nSoon\\nechoed in the courtyard of the study gay rumor. The good lady was a lesson to each child, and\\nthen put to work in a long narrow table.\\n\\nMy aunt\\'s hands, clever by far, went all the bouquets that adorned\\nthe churches Villaverde.\\n\\nFlowers of all kinds, and colors. Some, fantastic, silver and gold paper; others, the most\\nbeautiful and well arranged so characteristic that, at some distance, no one would distinguish of\\nnatural. There, twisting wires, threading buds, petals Acoca, painting leaflets, my aunt spent\\nthe whole morning and all afternoon. Just dropping his efforts to address children and take\\ntheir lesson.\\n\\nThe young man came to the aid of the elderly. The maid was painted\\nfor those tasks.\\n\\nOf received flowers and bouquets hand finishing touch.\\n\\nWhat garlands and festoons what those were! Gallardos, loose, flexible, such as guides and cabrifollos\\nconvolvulus that shaded the source.\\n\\nRoses ... Ah! Roses! Beautiful and splendid out of the hands of the elderly, but Angelina embellished\\nto the touch. A drive shaft, a rebellious leaf, a petal without grace, received all of the\\nyoung singular beauty. It seemed that passed through the clusters a breath of spring flowers\\ngiving life and freshness.\\n\\nThe children, attracted by such beauty, left their seats and went step by step placing around the\\nflorist. With hands behind, hiding the book, long I stood there gawking and staring in front of\\nso many wonders.\\n\\nAt twelve concluded the task. The servants came by children, and it was time for the lesson. My\\naunt showed severe frown, scolded, threatened. The boys preferred Angelina will take the lesson.\\nShe, patient and kind, the children were getting attentive, and with a look or a touch put order\\nin the mob of imps blond silk dresses with skirts.\\n\\nAngelina was a very smart girl. He wrote with great delicacy. Linda his letter; Loose, italic,\\nelegant, without the grace of the strokes made him lose that softness female character is expressed\\nnot only in style, but transcends the form of letters, provided that\\nshe does not presume to know or like to draw attention.\\n\\nHardly you missed a misspelling.\\n\\nHe wrote as he spoke, with great naturalness and simplicity, without digging or dapper phrases,\\nfollowing the logical order of ideas, removed from the calculated involvement, which makes the\\nepistolary style unbearable and ridiculous thing. But why not fell in the extreme, ritual formulas\\nand the concepts of stamp. It was very given to books, but only read when it allowed her chores.\\nI read every night the \"Christian Year\", and knew by heart the lives of the saints.\\n\\nOne night I had to read the life of Santa Teresa.\\n\\n- Jesus! - I said .-- If you already know it by heart. I can repeat the pe to pa!\\nAnd Aunt Carmen doubted, Angelina spoke with very good agreement\\nand very gracefully, life mysticism.\\n\\nRare thing in a young, loved\\nto serious books and perished by the historical. There read three\\nor four times the \"History\" of Alamo, and I used to dare against the\\njudgments of famous writer, not without great displeasure of Aunt\\nPepa, for whom were those of Don Lucas a gospel.\\n\\nParental history\\nran very donosura, smiling, without fatuities or displays of knowledge.\\nIt would be worthwhile to record here the trial of Angelina on some\\nbooks. For her there had better novelist Fernán Caballero, or worse\\nEscrich novelist Perez.\\n\\n- Open a book of these, the \\'Adulterous Woman\\',\\nthe \\'wife Martha, \"and being sleepy is all one! \"Novels? Fernan Caballero.\\nHis characters seem Vivitar, flesh and blood. That yes it\\'s true!\\nEat, sleep .... If I find people who deal every day! I do not understand\\nthese things .... Fernán but I like books because life painting as\\nit is. Have you read \"The Seagull?\" \"\" Eli? \"\" Tears \"?\"\\n\\n- And Cervantes,\\nwhat about you, Angelina?\\n\\n- That is separate! \\'\"Don Quixote?\" It\\'s\\nsomething that seems novel and perhaps it is not ....\\n\\n- Well then\\n....\\n\\n- I fail to explain. If it is a novel, but there is something\\nin that book that puts you over of all novels.\\n\\nI spent long hours\\ntalking to Angelina. Despite the state of my mood and depression of\\nmy mind, when weaving with her live network talk, I recovered my good\\nmood another time, and I became happy and jolly, and I forgot that\\nthese enervating melancholy have been and perhaps still are, somber\\nnote of my character for this character my dreamer and languid, given\\nto laziness and daydreaming, vague delirium and meditation without\\nan object. Pernicious melancholy, perhaps born in my soul when I lived\\naway from my family, condemned to solitude a school whose dilapidated\\ncloisters darkened my spirit melancholy that draws me to the fields\\nand dense forests for long hours entranced by the spectacle glare\\non the shores of Lake dormant, hiding among the reeds, or engulfed\\nin contemplation of an unknown flower, modest and rustic beauty. Feeling\\nsad of nature that the world hated me loud and frivolous and the attractions\\nof a society vain; deep sense of the beauties of the physical world,\\nfeelings that develop in my Romantic poets and novelists. Fortunately\\nI redeemed a little of the concerns and false ideas of romanticism,\\nand though not entirely free of them because I still have in La Martine\\nyeast soul, I look at life differently, do not pretend that everything\\nis to my taste and as my desire, and live quietly as any good person\\nlive without torment me poetic aspirations, nor would I wander useless\\ndelusions or embitter me delicate sentimentality. \\n\\nXIII\\n\\nAt ten o\\'clock\\nI took my hat and went for a walk around the city. At first I preferred\\nthe suburbs, dark alleys, the picturesque banks of the Stony or squares\\nof the Alameda, a vast box of ashes strewn at the foot of the hill\\nof brushes; mall without flowers and without trees cornered, they\\nretreat so I was gentle and pleasing. In the shade of an orange, the\\nonly grown and lush, noisy and at the top nesting birds, I spent the\\nmorning. There, in a mossy seat and chipped, I gave myself to reading\\nof my favorite authors, there I read the \\'Atala\\' and \\'Renato\\', the\\n\\'Raphael\\' and \\'Grace\\', there I devoured the \"Count of Monte Cristo\"\\nand I went through, to my sorrow, some novels of George Sand, grieved\\nmy heart and my soul left in sediments of aloes. I tasted there\\'s\\npoetry Zorrilla. Zorrilla', \" He tried to go in hurry, but less than\\nhe wanted, because navichuelos followed him into the ground and threatened. At last they got\\nrid of another ship closer to land.\\n\\nDisplaying the Canaries could not catch him, they play to challenge, and trageron two shots, which\\nfired four times against the nearest ship. The first broke up a pot of water, arrobas four\\nor five, the second broke the last tree on the ship and the third was a large hole in the side, killing\\na man, and even missed the fourth, was very badly treated the ship.\\n\\nWas anchored in the harbor another captain who was to Mexico, and he ground with 150 men: which, having\\nlearned the robbery of the wife, sought peace between us and the city that were given D. Jorge\\nde Mendoza, the daughter and the maid, and having entered the master Peyne and the governor of the\\nisland in our ship to the agreement egecutar, D. Jorge said, that\\nthis was his wife, and her that her husband and to the point were\\nmarried with great pain and sadness the girl's father.\\n\\nCHAPTER III.\\n\\nOf navigation from palm to Green Island or Hesperides, which also call for Cape Verde.\\n\\nCaptain Don left Jorge on the ground with his wife, and repaired the\\nship as he could, sail to the island of Santiago, sugeta the King\\nof Portugal, who obey blacks, and far from the Palma 200 leagues.\\n\\nThere were five days, and provide new our ship of bread, meat, water\\nand other food, and necessities to the sailors.\\n\\nCHAPTER IV.\\n\\nOf navigation from Green Island to Brazil.\\n\\nThey returned to join the 14 ships of any navy, and began to sail, and after two months came to an\\nuninhabited island six miles wide and long, distant 500 miles from\\nSantiago, [2] they only had birds, but so many, that we killed sticks:\\nwe were in it three days.\\n\\nThere is in this sea flying fish, whales and others that are called\\nSchunbhut, [3] by a large circle that is about the head with that\\nmuch damage to fish with whom Fight: is big fish, a lot of strength,\\nand easily irritated.\\n\\nThere is also this sea swordfish, which have in the way to muzzle\\na bone knife, saw fish, which have manner of a saw and several other\\nmajor genres.\\n\\nCHAPTER V.\\n\\nDel Rio called Janero.\\n\\nWe arrived at a certain island named after Rio Janero, where the French settled in the year of 1555\\n(Then and now, the King of Portugal). Far from the first 200 miles: call to his Indian Sliding.\\nHere were 14 days, and then our General, D. Pedro de Mendoza, being continuously sick, shriveled\\nand weak nerves, appointed by his lieutenant to John Osorio, [4]\\nhis brother.\\n\\nBut shortly after accepting the position, was accused of rebellion\\nagainst Mendoza by which, ordered four captains, who were: Juan de\\nOyola, Juan Salazar, Jorge Lujan and Lazaro Salazar, stab and kill\\nhim to save him at the plaza, so that all might see him dead a traitor,\\nand published side with death, that no one gets excited because of\\nOsorio, because the same thing would happen to him.\\n\\nIn which it was conducted without good cause, because Osorio was\\ngood, honest, strong soldier, informal, liberal and very beloved by\\nhis peers.\\n\\nCHAPTER VI.\\n\\nDel Rio de la Plata or Paraná, the port of San Gabriel and Charrúas.\\n\\nFrom here we set out to find the Rio de la Plata [5], and we reached another river, sweet, called\\nParaná-wolf: far east of the mouth that falls into the sea, and is 42 miles wide. From the Rio Janero\\nto him there are 215 leagues. Here we arrive at the port of San Gabriel, the 14 ships anchored\\nin the Parana River, and because they were distant shot bullet sent\\nthe General D. Pedro de Mendoza, saliésemos that soldiers and other\\npeople on shore, in boats prevented this effect.\\n\\nSo we happily to the Rio de la Plata in 1535, and found there an\\nIndian village of which 2.000 had called Charrúas, which have no more\\nfood than hunting and fishing, and walk all naked.\\n\\nThe women bring only thin cotton cloth from the waist to the knees.\\n\\nAll fled when they saw us, with their wives and children, and we were to embark sent Mendoza\\nto move to the other side of the river, there had not more than eight miles wide.\\n\\nCHAPTER VII.\\n\\nIn the city of Buenos Aires and Indians Querandíes.\\nOn this site we did a city, we call Buenos Aires, [6] as healthy\\nthere were those who ran. We find in this land of nearly 3,000 other\\nIndian people called Querandíes, with their wives and children who\\nwalk as Charrúas: they brought us meat and fish. These Querandíes\\nno fixed abode; roam the earth as Gypsies. When you walk in summer\\n(usually more than 30 leagues), but are water, or the root of thistles,\\nbut food quenches thirst, kill the deer or the wild animal they encounter,\\nand drink the blood, and it did, perhaps die of thirst\", ' \\n\\nThe abbey was very rich and famous, rich valleys of the Fertiliser in outline the monks had\\ncleared, cultivated with care and collecting them abundant harvests; and famous, it was about\\nhome education, where many young men from all over France and Spain Christian who remained came\\nto be instructed in arms and letters. Among the monks had wise philosophers and theologians\\nand not a few who had fought with glory in his youth before withdraw from the world.', ' Four centuries of tyranny, intolerance and errors\\nunheard, have left behind them a people who, if he had been ruled as England from 1688, today\\nwould be the first people in the world. Despite that, the Spain of today is very distant greatly\\nfrom that of 1825, visible progress, and in just five years after the passing quasi-revolution\\nof 1854, has made great strides.\\n\\nPerhaps will say: \"If the majority of Spanish people have such good\\ncharacter traits, Why is let evil rule and does not change your situation?\\n', ' \\n\\nDon Mateo, decrepit old man, not only spoiled by the years, but by a multitude of ailments acquired\\na life of dissipation sick, was the joy of the town of Sarrió. No party any private or public\\nrejoicing in the village was done without your intervention']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BjBQujXMNm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "708623e1-02ea-4370-f335-ee3c40f72538"
      },
      "source": [
        "#Convert to list and print the 5 first and the 5 last results\n",
        "spanish = spanish_df.Text.values.tolist()\n",
        "\n",
        "print(\"First spanish results\")\n",
        "print(spanish[0:2])\n",
        "print(\"\\n\")\n",
        "print(\"Last spanish Results\")\n",
        "print(spanish[-2:])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First spanish results\n",
            "[' |fecha de defunción = |lugar de defunción = |otros nombres = |cónyuge = |hijos = |sitio web = |premios óscar = |premios globo de oro = |premios bafta = |premios emmy = |premios sag = |premios tony = |premios grammy = |premios cannes = |premios san sebastian = |premios goya = |premios cesar = |premios ariel = |premios condor = |otros premios = |imdb = 0156940 Dominic Chianese (nacido el 24 de febrero o el 2 de septiembre de 1931)http://www.filmreference.com/film/36/Dominic-Chianese.html&lt;/ref&gt; es un actor Italo-Americano quizás más conocido por su papel de Junior Soprano en la serie de HBO TV, Los Soprano, un papel que le concedió dos nominaciones a a los premios Emmy.BiografíaChianese nació en el municipio del Bronx, en Nueva York, hijo de un albañil. Se graduó en la prestigiosa Bronx High School of Science en 1948. Trabajó como albañil con su padre y asistía a la escuela nocturna durante la década de 1950, consiguiendo su licenciatura en teatro y declamación en el Brooklyn College en 1961. Su primer trabajo en el escenario fue en 1952, en una compañía de cantantes, actores y músicos llamada The American Savoyards, haciendo un repertorio de Gilbert y Sullivan, bajo la dirección de Dorothy Raedler.Después de una década de teatro universitario y en el off-broadway, Chianese asistió a su primera clase profesional de actuación en los HB Studios de Manhattan, con el renombrado maestro Walt Witcover.El Teatro dramático y musical se conviertieron en la pasión de Chianese. Su primer espectáculo en Broadway fue Oliver! en 1965. Continuó sus actuaciones en teatros de Broadway , off-Broadway, y teatros provinciales. Para complementar sus ingresos durante los periodos de sequía, tocaba la guitarra rítmica y cantaba en tabernas y restaurantes. Su primera aparición en televisión ocurrió cuando George C. Scott le recomendó para un papel en la aclamada serie East Side, West Side. En 1974, Francis Ford Coppola eligió a Chianese como Johnny Ola en El Padrino, Parte II, lo que despertó su carrera cinematográfica, que culminó en varias películas junto a Al Pacino.Antes de recibir la llamada para El Padrino, Parte II, Chianese trabajó para la Comisión de Drogas del Estado de New York, como monitor sociocultural en un centro de rehabilitarción. Enseñaba a tocar la guitarra a mujeres que habían estado envueltas en crímenes relacionados con las drogas.AparicionesChianese ha aparecido en cuatro películas junto a su amigo Al Pacino:El padrino,Parte II (1974) - como Johnny OlaTarde de perros (1975) - como el padre de SonnyJusticia para todos (1979) - como Carl TraversBuscando a Richard (1996) - como el mismoChianese es músico, ha editado un CD (apropiadamente llamado Hits) en 2000, en el que canta canciones Americanas e Italianas. Incluso interpretó el clásico sentimental de Salvatore Cardillo Core \\'ngrato (\"Corazón ingrato\") al final de la tercera temporada de Los Soprano.Su manager es Brian Liebman, que también representa a la estrella de las comedias televisivas Mark Consuelos. Su hijo Dominic Chianese Jr. también es actor y aparece en la temporada final de Los Soprano como un miembro de la familia Lupertazzi.Referencias Categoría:Ítalo-estadounidensesde:Dominic Chianese en:Dominic Chianese fr:Dominic Chianese it:Dominic Chianese nl:Dominic Chianese no:Dominic Chianese pl:Dominic Chianese sv:Dominic Chianese', \" 250px|thumb|right|''Ninfas y [[sátiro'' de William Adolphe Bouguereau (1873)]]En la mitología griega, una ninfa es cualquier miembro de un gran grupo de espíritus femeninos de la naturaleza, a veces unidos a un lugar u orografía particular. Las ninfas solían acompañar a varios dioses y diosas, y eran con frecuencia el objetivo de sátiros lujuriosos.Las ninfas son las personificaciones de las actividades creativas y alentadoras de la naturaleza. La palabra griega νύμφη significa ‘novia’ y ‘velado’ entre otras cosas; es decir, una mujer casada y, en general, una en edad casadera. Otros hacen referencia a esta palabra (y también a la latina nubere y a la alemana Knospe) como una raíz que expresa la idea de ‘crecer’ (según Hesiquio de Alejandría, uno de los significados de νύμφη es ‘capullo de rosa’). El hogar de las ninfas está en las montañas y arboledas, en los manantiales y ríos, en los valles y las frías grutas. Con frecuencia son el séquito de divinidades superiores: de Artemisa la cazadora, de Apolo el profeta, del juerguista y dios de los árboles Dioniso, y también de dioses rústicos como Pan y Hermes, dios de los pastores.Clasificación de las ninfasLas diferentes especies de ninfas se distinguen según las diferentes esferas de la naturaleza con las que están conectadas.Ninfas terrestres («Epigeas»)Agrónomos (campos)Alseides (flores)Antríades (cuevas)Auloníades (pastizales)Corícides o coricias (cuevas, son las musas clásicas)Dríades (bosques)Hamadríades (árboles)Melíades o melias (fresnos)Hespérides (jardines y del ocaso)Híades (lluvia)Limónides o hénides (prados)Napeas (valles de montañas, cañadas)Oréades u orestíades (montañas, montes; forman el cortejo de Diana)Ninfas de las aguas («Efidríades»)Oceánides (hijas de Océano; cualquier agua, normalmente salada)Nereidas (hijas de Nereo; del mar Mediterráneo)Náyades (normalmente al agua dulce)Creneas o crénides (fuentes)Limnátides o limníades (lagos)Pegeas (manantiales)Potámides (ríos)OtrasPerimélides (ninfas del ganado menor)Epimélides (ninfas de las ovejas)Trías (ninfas proféticas de la miel)Uranias (ninfas celestes)Adaptaciones extranjerasLas ninfas griegas, tras la introducción de su culto en el Lacio, absorbieron gradualmente en sus categorías a las divinidades indígenas italianas de los manantiales y los cursos de agua (Juturna, Egeria, Cavmentis, Fonto), mientras que las Linfas (originalmente Lumpae) o diosas del agua italianas, debido a la similitud fortuita de su nombre, fueron identificadas con las ninfas griegas. Entre los romanos su esfera de influencia fue reducida, y aparecen casi exclusivamente como divinidades del medio acuático.Véase tambiénMitología griegaHadaEnlaces externosLos epítetos de las Ninfas en la épica griega arcaicaNINFAS (Νύμφαι), el nombre de una numerosa clase de deidades femeninas inferiores, aunque eran designadas por el título de olímpicas, convocadas a las reuniones de los dioses en el Olimpo y descritas como hijas de Zeus. Pero se creía que moraban en la tierra: en arboledas, en la cima de montañas, en ríos, arroyos, cañadas y grutas.Hom. Od. vi.123 y sig., xii.318, Il. xx.8, xxiv. 615 Homero las describe con más detalle presidiendo sobre los juegos, acompañando a Artemisa, bailando con ella, tejiendo en sus cuevas prendas púrpuras y vigilando amablemente el destino de los mortales.Hom. Od. vi.105, ix.154, xiii.107, 356, xvii.243, Il. vi.420, xxiv.616 Los hombres les ofrecían sacrificios en solitario o junto con otros dioses, como por ejemplo Hermes.Hom. Od. xiii.350, xvii.211, 240, xiv.435 Según el lugar que habiten, se les llama ἀγρονόμοι,Hom. Od. vi.105 ὀρεστιάδεςHom. Il. vi.420 y νηϊάδες.Hom. Od. xiii.104Todas las ninfas, cuyo número es casi infinito, pueden ser divididas en dos grandes clases. La primera abarca todas aquellas que pueden ser consideradas como un tipo de divinidad inferior, reconocida en el culto de la naturaleza. Los griegos antiguos veían en todos los fenómenos ordinarios de la naturaleza alguna manifestación de la divinidad. Fuentes, ríos, grutas, árboles y montañas: todos les parecían cargados de vida, y no eran más que las encarnaciones visibles de otros tantos agentes divinos. Los saludables y beneficiosos poderes de la naturaleza eran pues personificaciones y considerados otras tantas divinidades, y las sensaciones producidas en el hombre por la contemplación de la naturaleza (sobrecogimiento, terror, alegría, placer) se atribuían a la acción de diversas deidades de la naturaleza. La segunda clase de ninfas son personificaciones de tribus, razas y estados, tales como Cirene y otras.Las ninfas de la primera clase deben ser de nuevo divididas en varias especies, según las diferentes partes de la naturaleza de las que sean representativas:Ninfas del elemento acuático. Aquí debemos mencionar primero a las ninfas del océano, Ὠκεανῖναι u Ὠκεανίδες, νύμφαι ἅλιαι, que son consideradas hijas de Océano,Hes. Teog. 346 y sig.; Esquilo Prom.; Calímaco Himno a Diana 13; Apolonio de Rodas iv.141; Sófocles Filoctetes 1470 y a continuación a las ninfas del Mediterráneo o del mar interior, que son consideradas hijas de Nereo, por lo que son llamadas Nereidas (Νηρεΐδες).Hes. Teog. 240 y sig. Los ríos eran representados por las Potámides (Ποταμηΐδες), quienes, como divinidades locales, eran bautizadas según sus ríos como Aqueloides, Anígrides, Amnisíades o Pactólides.Apolonio Rodio iii.1219; Virg. Eneida viii. 70; Paus. v.5 §6, i.31 § 2; Calímaco Himno a Diana 15; Ov. Met. vi. 16; Estéfano de Bizancio s. v. Ἀμνισός Pero las ninfas del agua dulce, ya sea de ríos, lagos, arroyos o pozos, son también designadas por el nombre general de Náyades, Νηΐδες, aunque tengan además sus nombres específicos, como Κρηναῖαι, Πηγαῖαι, Ἑλειονόμοι, Λιμνατίδες o Λιμνάδες.Hom. Od. xvii.240; Apolonio Rodio iii.1219; Teócrito v.17; Orfeo Himnos 50.6, Argon. 644 Incluso los ríos de las regiones inferiores (el inframundo) se describen con sus ninfas, de ahí las Nymphae infernae paludis y las Avernales.Ov. Met. v.540, Fast. ii. 610 Muchas de estas ninfas presidían sobre las aguas o las fuentes, de las que se creía que inspiraban a aquellos de bebían de ellas, por lo que se creía que las propias ninfas estaban dotadas de poderes proféticos u oraculares y los inspiraban a los hombres, así como que les otorgaban el don de la poesía.Paus. iv.27 §2, ix.3 §5, 34 §3; Plut. Aristid. 11; Teócrito vii. 92; véase también «Musas» Los adivinos o sacerdotes inspirados eran por esto llamados a veces νυμφύληπτοι.Platón, Fedro p.421, e. Sus poderes, sin embargo, varían con los de la fuente sobre la que presiden, considerándose así que algunas tenían el poder de devolver la salud a las personas enfermas,Pind. Ol. xii.26; Paus. v.5 §6, vi.22 §4 y como el agua es necesaria para alimentar a la vegetación así como a todos los seres vivos, las ninfas acuáticas (ἱδριάδες) eran también adoradas junto con Dioniso y Deméter como dadoras de vida y bendición a todas las criaturas, y este atributo es expresado por una variedad de epítetos, tales como καρποτρόφοι, αἰπολικαί, νόμιαι, κουροτρόφοι y otros. Como su influencia era de esta forma ejercitada en todas las secciones de la naturaleza, aparecen con frecuencia relacionadas con divinidades superiores, como por ejemplo con Apolo, el dios profético y protector de las manadas y rebaños,Apolonio Rodio iv.1218 con Artemisa, la cazadora y protectora del juego, pues ella misma fue originalmente una ninfa arcadia,Apolonio Rodio i.1225, iii.881; Paus. iii.10 §8 con Hermes, el fructífero dios de los rebaños,Homero, Himno a Afrodita 262 con DionisoOrfeo Himnos 52; Horacio Carmina i.1.31, ii.19.3 y con Pan, los Silenos y los Sátiros, a quienes se unían deleites y bailes báquicos.Ninfas de las montañas y las grutas, llamadas Ὀροδεμνιάδες y Ὀρειάδες, pero a veces también por nombres derivados de las montañas concretas que habitaban, como Κιθαιρωνίδες, Πηλιάδες, Κορύκιαι, etcétera.Teócrito vii. 137; Virgilio Eneida i. 168, 500; Paus. v.5 §6, ix.3 §5, x.32 §5; Apolonio Rodio i.550, ii.711; Ovidio Her. xx.221; Virg. Eclog. vi. 56Ninfas de los bosques, arboledas y praderas, donde se creía que a veces se aparecían y asustaban a los viajeros solitarios. Eran designadas por los nombres Ἀλσηΐδες, Ὑληωροί, Αὐλωνιάδες y Ναπαῖαι.Apolonio Rodio i.1066, 1227; Orfeo Himnos 50.7; Teócrito xiii.44; Ovidio Met. xv.490; Virg. Georg. iv. 535Ninfas de los árboles, de las que se creía que morían junto con los árboles en los que vivía y con los que habían llegado a existir. Eran llamadas Δρυάδες, Ἁμαδρυάδες o Ἀδρυάδες, de δρῦς, que significa no sólo ‘roble’ sino también cualquier árbol silvestre que crece majestuoso. Las ninfas de los árboles frutales eran llamadas Μηλίδες, Μηλιάδες, Ἐπιμηλίδες o Ἁμαμηλίδες. Parecen ser de origen arcadio y nunca aparecen junto con los grandes dioses.Paus. viii.4 §2; Apolonio Rodio ii.477 y sig.; Anton. Lib. 31, 32; Hom. Hymn. in Ven. 259 y sig.La segunda clase de ninfas, que estaban relacionadas con ciertas razas o localidades (Νύμφαι χθόνιαιApolonio Rodio ii.504), tienen normalmente un nombre derivado de los lugares con los que estaban asociadas, como Nisíadas, Dodónidas o Lemnias.Ov. Fast. iii.769, Met. v.412, ix.651; Apolodoro iii.4 §3; Schol. ad Pind. Ol. xiii.74Los sacrificios ofrecidos a las ninfas solían consistir en cabras, corderos, leche y aceites, pero nunca vino.Teócrito v.12, 53, 139, 149; Serv. ad Virg. Georg. iv.380, Eclog. v.74 Eran adoradas y honradas con santuarios en muchas partes de Grecia, especialmente cerca de las fuentes, arboledas y grutas, como por ejemplo cerca de una fuente en Cyrtones,Paus. ix.24 §4 en Ática,Paus. i.31 §2 en Olimpia,Paus. v.15 §4, vi.22 §4 en Mégara,Paus. i.40 §1 entre Sición y FlioPaus. ii.11 §3 y en otros lugares. Las ninfas se representan en obras de arte como hermosas doncellas, desnudas o semidesnudas. Poetas posteriores las describen a veces con cabellos del color del mar.Ov. Met. v.432-NINFAS (correctamente ‘las doncellas jóvenes’), divinidades inferiores de la naturaleza que moran en arboledas, bosques y cuevas, junto a manantiales, arroyos y ríos; en algunos casos también en islas solitarias, como Calipso y Circe. Las ninfas de los montes, los bosques, los prados y las fuentes (llamadas por Homero hijas de Zeus, aunque Hesíodo hace a las ninfas de las colinas y los bosques junto a las propias colinas y bosques hijos de Gaia) aparecen como los espíritus benevolentes de estos lugares, y llevan una vida de libertad, a veces tejiendo en grutas, a veces bailando y cantando, a veces cantando con Artemisa o deleitándose con Dioniso. Aparte de estas deidades son especialmente Apolo, Hermes y Pan quienes están dedicados a ellas y buscan su amor, mientras los lascivos sátiros están también continuamente a su espera. Están bien predispuestas hacia los mortales y listas para ayudarlos, a veces incluso casándose con ellos. Según las diversas provincias de la naturaleza se distinguen varias clases de ninfas: las de los ríos y fuentes, las Náyades, con quienes las Oceánides y Nereidas están estrechamente relacionadas; las de las colinas, Oréades; las de los bosques y árboles, Dríades o Hamadríades; además de éstos reciben a menudo nombres especiales por ciertos lugares, colinas, fuentes y grutas. Las Náyades, como diosas del agua nutricia y fructífera, eran especialmente pródigas en favores, haciendo crecer y prosperar a plantas, ganado y mortales. De ahí que también fueran consideradas como las diosas guardianas del matrimonio, y el rociado de la novia con agua de manantial era uno de los ritos indispensables de la ceremonia. En el mismo principio, las tradiciones legendarias las representan amamantando y criando a los hijos de los dioses, como por ejemplo a Zeus y Dioniso. Más aún, debido al poder curativo e inspirador de muchas fuentes, pertenecen a las divinidades de la curación y la profecía, y pueden incluso llevar a los hombres a raptos de inspiración profética y poética. Las propias Musas son en su origen ninfas de las fuentes. La creencia popular asignaba a las ninfas en general una vida extremadamente larga, sin inmortalidad real. La existencia de las Dríades, se suponía, estaba estrechamente relacionada con el origen y la descomposición del árbol en el que moraban. Gozaban de honores divinos desde los tiempos más remotos, originalmente en los lugares en los que tenían poder: fuentes, arboledas y grutas. En épocas posteriores se les construyeron templos propios llamados Nymphæa, incluso en las ciudades. Éstos llegaron finalmente a ser edificios magníficos, en los que se acostumbraba a celebrar bodas. Se les ofrecía cabras, corderos, leche y aceite. En las obras de arte eran representadas con la forma de doncellas encantadoras, ligeras de ropa o desnudas, con flores y guirnaldas, las Náyades sacando agua o llevándola en una urna de oro.ReferenciasBibliografíaCategoría:Ninfasan:Ninfa ar:حورية (ميثولوجيا إغريقية) ast:Ninfa bg:Нимфа br:Nimfezed ca:Nimfa cs:Nymfy da:Nymfe (mytologi) de:Nymphe el:Νύμφες en:Nymph eo:Nimfoj fi:Nymfit fr:Nymphe (mythologie) he:נימפה hr:Nimfa hu:Nimfa (mitológia) id:Nymph it:Ninfa (mitologia) ja:ニュンペー ko:님프 lb:Nymph lt:Nimfa mk:Нимфа nl:Nimf (mythologie) nn:Nymfe no:Nymfe (mytologi) pl:Nimfa (mitologia) pt:Ninfa (mitologia) ro:Nimfe ru:Нимфы scn:Ninfa (mituluggìa) sk:Nymfa (mytológia) sl:Nimfa sr:Нимфа sv:Nymf th:นิมฟ์ tr:Nemf uk:Німфи zh:宁芙\"]\n",
            "\n",
            "\n",
            "Last spanish Results\n",
            "['\\n\\nII\\n\\nDesde la mona catarrinia hasta la elegante y hermosa Helena y desde los antropiscos alalos\\nque salieron de la Lemuria y se esparcieron en manadas y aullando por todo el mundo, hasta\\nel hombre que compuso la Iliada y los que la entendían y gozaban leyéndola, hay progreso tan\\npasmoso que, aun suponiendo millares de siglos para realizarle, todavía nos parece inverosímil\\ny punto menos que imposible. Acaso sea todo ello ensueño ingenioso de los sabios que se dedican\\na la Prehistoria.\\n', ' A la puesta del Sol, por vnos llanos, i entre\\nvnas Sierras mui grandes, que alli se hacen, alli hallamos vna Gente, que la tercera parte\\ndel Año no comen sino vnos Polvos de Paja; i por ser aquel tiempo, quando nosotros por alli\\ncaminamos, hovimoslo tambien de comer, hasta que acabadas estas jornadas, hallamos Casas de\\nasiento adonde havia mucho Maìz allegado, i de ello, i de su Harina nos dieron mucha cantidad,\\ni de Calabaças, i Frisoles, i Mantas de Algodon, i de todo cargamos à los que alli nos havian\\ntraìdo, i con esto se bolvieron los mas contentos del Mundo. Entre estas Casas havia algunas\\nde ellas, que eran de Tierra, i las otras todas son de Estera de Cañas; i de aqui pasamos mas\\nde cien leguas de Tierra, i siempre hallamos Casas de asiento, i mucho mantenimiento de Maìz,\\ni Frisoles, i dabannos muchos Venados, i muchas Mantas de Algodon, mejores que las de la Nueva-España.\\nEntre estos vimos las Mugeres mas honestamente tratadas que à ninguna parte de Indias que hoviesemos\\nvisto. Acontecia muchas veces, que de las Mugeres que con nosotros iban, parian algunas, i\\nluego en nasciendo nos traìan la criatura à que la santiguasemos, i tocasemos. Acompañabannos\\nsiempre, hasta dexarnos entregados à otros; i entre todas estas Gentes se tenia por mui cierto,\\nque veniamos del Cielo. Entretanto que con estos anduvimos, caminamos todo el dia sin comer\\nhasta la noche; i comiamos tan poco, que ellos se espantaban de verlo. Nunca nos sintieron\\ncansancio; i à la verdad nosotros estabamos tan hechos al trabajo, que tampoco lo sentiamos.\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY3uMw1cMO3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "112e7e04-3cbf-45ca-dd34-2ac7c82a6d2e"
      },
      "source": [
        "#Convert to list and print the 5 first and the 5 last results\n",
        "french = french_df.Text.values.tolist()\n",
        "\n",
        "print(\"First french results\")\n",
        "print(french[0:2])\n",
        "print(\"\\n\")\n",
        "print(\"Last french Results\")\n",
        "print(french[-2:])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First french results\n",
            "['Un exemple de conjonction entre préférences est Pourrais-je avoir un petit déjeuner et un repas végétarien\\n ? où l’agent exprime deux préférences qu’il souhaite satisfaire et il aimerait en avoir\\n au moins une des deux s’il ne peut pas les avoir toutes. La sémantique des disjonctions est une\\n modalité de choix libre. Par exemple, Je suis libre lundi ou mardi signifie que lundi ou mardi\\n est un jour possible pour se rencontrer et que l’agent est indifférent entre les deux.', 'Puisque la liste des termes associés à chaque concept de notre ontologie est\\n courte, ce trait aide à retrouver des lexicalisations supplémentaires ; (2) le segment contient\\n une disjonction ou une conjonction ; (3) le GN est dans la portée d’une négation, d’un modal ou\\n d’un verbe d’action du domaine (se rencontrer, réserver). La portée des négations et des modaux\\n est résolue de manière simplifiée en utilisant l’arbre syntaxique de l’UD; (4) le segment contient\\n un mot d’opinion (bon, mauvais, OK, etc.), un mot de politesse ou un mot qui introduit des\\n préférences (préférer, favori, choix, trop, etc.) ; (5) le segment contient une référence à l’autre\\n agent.']\n",
            "\n",
            "\n",
            "Last french Results\n",
            "[\"  | région=Valais | lien région=Canton | subdivision=Rarogne occidental, Viège | lien subdivision=Districts | première ascension= par Leslie Stephen | voie=Versant WSW | âge= | roches= | type=pic pyramidal | géolocalisation=Suisse Le Bietschhorn, surnommé «\\xa0le Roi du Valais », est un sommet du massif des Alpes bernoises à  d'altitude, dans le canton du Valais en Suisse.Une partie du sommet est classée dans le patrimoine mondial de l'UNESCO.AnnexesArticles connexesAlpes suisses Jungfrau-AletschLiens externes Photos du Bietschhorn Catégorie:Sommet des Alpes suisses Catégorie:Alpes bernoises Catégorie:Montagne du canton du Valaisda:Bietschhorn de:Bietschhorn en:Bietschhorn eo:Bietschhorn es:Bietschhorn he:ביטשהורן it:Bietschhorn nl:Bietschhorn pl:Bietschhorn zh:比奇峰\", \"  EISA signifie Extended Industry Standard Architecture. C'est une évolution du bus ISA avec une compatibilité descendante théorique. La vitesse de 8,33 MHz gardée, le bus de transfert de données prend une largeur de 32 bits, soit le double que la dernière génération du bus ISA. Il ajoute 90 nouvelles connexions à un connecteur classique ISA avec pour avantages la facilité d'installation et de configuration par logiciels des cartes installées dans les plots d'expansion et la possibilité de partage d’une IRQ par plusieurs périphériques.HistoriqueLe bus EISA est apparu en septembre 1988 comme une réponse à l’introduction du bus MCA par IBM et la manière dont il comptait s’en servir. Neuf constructeurs sont à l’origine du bus EISA (AST Research, Compaq, Epson, Hewlett-Packard, NEC, Olivetti, Tandy, WYSE et Zenith Data Systems).Voir aussiBus informatiqueBus ISACatégorie:Bus informatique Catégorie:Connectiquebs:EISA da:Extended Industry Standard Architecture de:Extended ISA en:Extended Industry Standard Architecture es:Extended Industry Standard Architecture fi:EISA he:EISA hr:EISA id:Bus EISA ja:Extended Industry Standard Architecture ko:EISA nl:Extended Industry Standard Architecture pl:EISA pt:EISA ru:EISA uk:EISA\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kczi8cD7PD9n",
        "colab_type": "text"
      },
      "source": [
        "## 3 Clean the Data\n",
        "\n",
        "\n",
        "As we can see, there is a lot of special characters and information that can add unnecesary noise to the topic model analysis. The more complicated documents are those ones  **coming from wikipedia**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28DUAu_1Rezn",
        "colab_type": "text"
      },
      "source": [
        "If we see deep in the wikipedia data, we can see there is html code like **&ndash** or extensions files like **.jpg** (this is to load picture. It could add noise in our topic analysis model).\n",
        "\n",
        "Other expressions to remove are:\n",
        "\n",
        "* & *word_between* ;\n",
        "* < *word_between* >\n",
        "* urls\n",
        "* Remove betwen [[ and ]]. Everything inside double squarebracket is part of Wiki markup. It could add unnecesary words to find hidden topics.\n",
        "* **jpg** files\n",
        "* special characters like '|' or @ are not so important, because **it's gonna be removed from the analysis during tokenization.**\n",
        "\n",
        "\n",
        "\n",
        "Here are some functions to clean data. Also is important to **remove the accents in French and Spanish.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIBPoGaeEOZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b54ee32d-7242-4cbe-e9ce-bcf82efac3ed"
      },
      "source": [
        "#This is an example of text with a lot of unnecesary data.\n",
        "\n",
        "textc = ['[[Imagen:RoyalAcademy20040807 CopyrightKaihsuTai.jpg|thumb|right|250px|\\'Real Academia de Arte\\', Londres]] La Royal Academy of Arts es una institución artística con sede en Piccadilly, @hola.jpg Londres.La Real Academia surgió a partir de una disputa en la Sociedad de Artistas, por el liderazgo, entre dos arquitectos, Sir William Chambers y James Paine. Paine ganó, pero Chambers juró venganza y usó sus conexiones con el rey para crear una nueva institución artística, la Real Academia, en 1768. Los cuarenta fundadores fueron admitidos el 10 de diciembre de 1768. Sir Joshua Reynolds fue el primer presidente, y Benjamin West el segundo.La Real Academia no recibe apoyo financiero del estado ni de la Corona. Obtiene ingresos de sus exposiciones y de donaciones. La Academia dirige una escuela de arte para postgraduados, con sede en Burlington House. Los alumnos suelen hacer dos exposiciones al año.El número de académicos está limitado a 80. Se busca el equilibrio entre las distintas disciplinas, y así, se suele exigir que haya, por ejemplo, al menos 14 escultores y 12 arquitectos. Además de los miembros de la academia (R.A.), existen asociados (A.R.A.), pero no es requisito previo para ser académico.La elección como Presidente de la Real Academia (P.R.A.) suele garantizar ser nombrado caballero, si es que el presidente no ostenta ya tal rango.Los miembros del público pueden unirse a la Academia como \"Amigos\", haciendo donaciones, lo cual es otra de las fuentes de financiación.Lista de principales académicosThomas Gainsborough (1768)William Hunter (1768; primer académico profesor de anatomía)Angelica Kauffmann (1768)Sir Joshua Reynolds (1768; Presidente 1768&ndash;1792)Benjamin West (1768; Presidente 1792&ndash;1805, 1806&ndash;1820)Sir Thomas Lawrence (1794; Presidente 1820&ndash;1830)John Flaxman (1800; Profesor de Escultura 1810&ndash;1826)Sir John Soane (1802; Profesor de la Academia, de arquitectura 1806&ndash;1837)J. M. W. Turner (1802)John Constable (1829)William Dyce (1848)John Everett Millais (1863; Presidente 1896)Alfred Waterhouse (1885)John William Waterhouse (1895)George Frederic Watts (1897)Sir Aston Webb (1903)Eduardo Paolozzi (1979)Peter Blake (1981)David Hockney (1991)PresidentesPresidenteMandatoSir Joshua Reynolds1768&ndash;1792Benjamin West1792&ndash;1805James Wyatt1805&ndash;1806Benjamin West1806&ndash;1820Sir Thomas Lawrence1820&ndash;1830Sir Martin Archer Shee1830&ndash;1850Sir Charles Lock Eastlake1850&ndash;1865Sir Francis Grant1866&ndash;1878Frederic Leighton, Lord Leighton1878&ndash;1896Sir John Everett MillaisFebrero&ndash;agosto 1896Sir Edward Poynter1896&ndash;1918Sir Aston Webb1919&ndash;1924Sir Frank Dicksee1924&ndash;1928Sir William Llewellyn1928&ndash;1938Sir Edwin Lutyens1938&ndash;1944Sir Alfred Munnings1944&ndash;1949Sir Gerald Kelly1949&ndash;1954Sir Albert Richardson1954&ndash;1956Sir Charles Wheeler1956&ndash;1966Sir Thomas Monnington1966&ndash;1976Sir Hugh Casson1976&ndash;1984Sir Roger de Grey1984&ndash;1993Sir Philip Dowson1993&ndash;1999Phillip King1999&ndash;2004Sir Nicholas Grimshaw2004&ndash;actualidadDirecciónRoyal Academy of Arts. Burlington House. Piccadilly. London W1J 0BDEnlaces externosPágina oficial de la Royal AcademyCategory:Museos de Londresar:الأكاديمية الملكية للفنون ca:Royal Academy of Arts cs:Royal Academy of Arts de:Royal Academy of Arts en:Royal Academy fr:Royal Academy he:האקדמיה המלכותית לאמנויות hu:Királyi Művészeti Akadémia it:Royal Academy of Arts ja:ロイヤル・アカデミー・オブ・アーツ nl:Royal Academy of Arts no:Royal Academy pl:Royal Academy pt:Academia Real Inglesa ru:Королевская Академия художеств simple:Royal Academy of Arts', ' thumb|right|200px| Basílica de San Andrea Vercelli (Vërsèj en piamontés) es una ciudad de Italia en la región del Piamonte, provincia de Vercelli. Tiene unos 60.000 habitantes y está situada a la orilla derecha del río Sesia. Se encuentra en medio de una gran llanura, entre Milán y Turín, muy bien irrigada y rodeada de campos de arroz, producto del que exporta a todo el mundo y del que es uno de los mayores mercados europeos. Su nombre deriva del celta Wercel, (Guardia de los celtas).HistoriaFue la capital de los Libiquis (Oppidium Vercellae) y formó parte de la Galia Cisalpina. En el 101&amp;nbsp;a.&amp;nbsp;C. se libró una batalla en sus alededores entre los romanos dirigidos por el cónsul Cayo Mario contra los Cimbrios, que fueron derrotados en la Batalla de Vercelae. En el 89&amp;nbsp;a.&amp;nbsp;C. la ciudad va a recibir el derecho romano. En tiempos de Estrabón era una villa fortificada, pero después se va a convertir en municipio (42&nbsp;a.&nbsp;C.)']\n",
        "textc "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[[Imagen:RoyalAcademy20040807 CopyrightKaihsuTai.jpg|thumb|right|250px|\\'Real Academia de Arte\\', Londres]] La Royal Academy of Arts es una institución artística con sede en Piccadilly, @hola.jpg Londres.La Real Academia surgió a partir de una disputa en la Sociedad de Artistas, por el liderazgo, entre dos arquitectos, Sir William Chambers y James Paine. Paine ganó, pero Chambers juró venganza y usó sus conexiones con el rey para crear una nueva institución artística, la Real Academia, en 1768. Los cuarenta fundadores fueron admitidos el 10 de diciembre de 1768. Sir Joshua Reynolds fue el primer presidente, y Benjamin West el segundo.La Real Academia no recibe apoyo financiero del estado ni de la Corona. Obtiene ingresos de sus exposiciones y de donaciones. La Academia dirige una escuela de arte para postgraduados, con sede en Burlington House. Los alumnos suelen hacer dos exposiciones al año.El número de académicos está limitado a 80. Se busca el equilibrio entre las distintas disciplinas, y así, se suele exigir que haya, por ejemplo, al menos 14 escultores y 12 arquitectos. Además de los miembros de la academia (R.A.), existen asociados (A.R.A.), pero no es requisito previo para ser académico.La elección como Presidente de la Real Academia (P.R.A.) suele garantizar ser nombrado caballero, si es que el presidente no ostenta ya tal rango.Los miembros del público pueden unirse a la Academia como \"Amigos\", haciendo donaciones, lo cual es otra de las fuentes de financiación.Lista de principales académicosThomas Gainsborough (1768)William Hunter (1768; primer académico profesor de anatomía)Angelica Kauffmann (1768)Sir Joshua Reynolds (1768; Presidente 1768&ndash;1792)Benjamin West (1768; Presidente 1792&ndash;1805, 1806&ndash;1820)Sir Thomas Lawrence (1794; Presidente 1820&ndash;1830)John Flaxman (1800; Profesor de Escultura 1810&ndash;1826)Sir John Soane (1802; Profesor de la Academia, de arquitectura 1806&ndash;1837)J. M. W. Turner (1802)John Constable (1829)William Dyce (1848)John Everett Millais (1863; Presidente 1896)Alfred Waterhouse (1885)John William Waterhouse (1895)George Frederic Watts (1897)Sir Aston Webb (1903)Eduardo Paolozzi (1979)Peter Blake (1981)David Hockney (1991)PresidentesPresidenteMandatoSir Joshua Reynolds1768&ndash;1792Benjamin West1792&ndash;1805James Wyatt1805&ndash;1806Benjamin West1806&ndash;1820Sir Thomas Lawrence1820&ndash;1830Sir Martin Archer Shee1830&ndash;1850Sir Charles Lock Eastlake1850&ndash;1865Sir Francis Grant1866&ndash;1878Frederic Leighton, Lord Leighton1878&ndash;1896Sir John Everett MillaisFebrero&ndash;agosto 1896Sir Edward Poynter1896&ndash;1918Sir Aston Webb1919&ndash;1924Sir Frank Dicksee1924&ndash;1928Sir William Llewellyn1928&ndash;1938Sir Edwin Lutyens1938&ndash;1944Sir Alfred Munnings1944&ndash;1949Sir Gerald Kelly1949&ndash;1954Sir Albert Richardson1954&ndash;1956Sir Charles Wheeler1956&ndash;1966Sir Thomas Monnington1966&ndash;1976Sir Hugh Casson1976&ndash;1984Sir Roger de Grey1984&ndash;1993Sir Philip Dowson1993&ndash;1999Phillip King1999&ndash;2004Sir Nicholas Grimshaw2004&ndash;actualidadDirecciónRoyal Academy of Arts. Burlington House. Piccadilly. London W1J 0BDEnlaces externosPágina oficial de la Royal AcademyCategory:Museos de Londresar:الأكاديمية الملكية للفنون ca:Royal Academy of Arts cs:Royal Academy of Arts de:Royal Academy of Arts en:Royal Academy fr:Royal Academy he:האקדמיה המלכותית לאמנויות hu:Királyi Művészeti Akadémia it:Royal Academy of Arts ja:ロイヤル・アカデミー・オブ・アーツ nl:Royal Academy of Arts no:Royal Academy pl:Royal Academy pt:Academia Real Inglesa ru:Королевская Академия художеств simple:Royal Academy of Arts',\n",
              " ' thumb|right|200px| Basílica de San Andrea Vercelli (Vërsèj en piamontés) es una ciudad de Italia en la región del Piamonte, provincia de Vercelli. Tiene unos 60.000 habitantes y está situada a la orilla derecha del río Sesia. Se encuentra en medio de una gran llanura, entre Milán y Turín, muy bien irrigada y rodeada de campos de arroz, producto del que exporta a todo el mundo y del que es uno de los mayores mercados europeos. Su nombre deriva del celta Wercel, (Guardia de los celtas).HistoriaFue la capital de los Libiquis (Oppidium Vercellae) y formó parte de la Galia Cisalpina. En el 101&amp;nbsp;a.&amp;nbsp;C. se libró una batalla en sus alededores entre los romanos dirigidos por el cónsul Cayo Mario contra los Cimbrios, que fueron derrotados en la Batalla de Vercelae. En el 89&amp;nbsp;a.&amp;nbsp;C. la ciudad va a recibir el derecho romano. En tiempos de Estrabón era una villa fortificada, pero después se va a convertir en municipio (42&nbsp;a.&nbsp;C.)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inn6qY34EMTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a function to remove\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "\n",
        "\n",
        "def clean_characters(lst):\n",
        "\n",
        "   \"\"\"\n",
        "   Remove Special Characters\n",
        "   \"\"\"\n",
        "   lst = [sent.replace('\\s', ' ') for sent in lst] # Replace \\s\n",
        "   lst = [sent.replace( '\\n', ' ') for sent in lst] # Replace \\n\n",
        "   lst = [re.sub('&.*?;', ' ', sent) for sent in lst] #Replace between &marks;\n",
        "   lst = [re.sub('\\[[^\\]]*\\].', ' ', sent) for sent in lst] #Replace between Square brackets\n",
        "   lst = [sent.replace('jpg', '') for sent in lst] # Replace \\s\n",
        "\n",
        "   return lst\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaQSAM8VLdVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a3ba4b5c-c5f5-4208-99d8-c5ed37e3b082"
      },
      "source": [
        "#Let's see the text after the cleaning\n",
        "clean_characters(textc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  La Royal Academy of Arts es una institución artística con sede en Piccadilly, @hola. Londres.La Real Academia surgió a partir de una disputa en la Sociedad de Artistas, por el liderazgo, entre dos arquitectos, Sir William Chambers y James Paine. Paine ganó, pero Chambers juró venganza y usó sus conexiones con el rey para crear una nueva institución artística, la Real Academia, en 1768. Los cuarenta fundadores fueron admitidos el 10 de diciembre de 1768. Sir Joshua Reynolds fue el primer presidente, y Benjamin West el segundo.La Real Academia no recibe apoyo financiero del estado ni de la Corona. Obtiene ingresos de sus exposiciones y de donaciones. La Academia dirige una escuela de arte para postgraduados, con sede en Burlington House. Los alumnos suelen hacer dos exposiciones al año.El número de académicos está limitado a 80. Se busca el equilibrio entre las distintas disciplinas, y así, se suele exigir que haya, por ejemplo, al menos 14 escultores y 12 arquitectos. Además de los miembros de la academia (R.A.), existen asociados (A.R.A.), pero no es requisito previo para ser académico.La elección como Presidente de la Real Academia (P.R.A.) suele garantizar ser nombrado caballero, si es que el presidente no ostenta ya tal rango.Los miembros del público pueden unirse a la Academia como \"Amigos\", haciendo donaciones, lo cual es otra de las fuentes de financiación.Lista de principales académicosThomas Gainsborough (1768)William Hunter (1768; primer académico profesor de anatomía)Angelica Kauffmann (1768)Sir Joshua Reynolds (1768; Presidente 1768 1792)Benjamin West (1768; Presidente 1792 1805, 1806 1820)Sir Thomas Lawrence (1794; Presidente 1820 1830)John Flaxman (1800; Profesor de Escultura 1810 1826)Sir John Soane (1802; Profesor de la Academia, de arquitectura 1806 1837)J. M. W. Turner (1802)John Constable (1829)William Dyce (1848)John Everett Millais (1863; Presidente 1896)Alfred Waterhouse (1885)John William Waterhouse (1895)George Frederic Watts (1897)Sir Aston Webb (1903)Eduardo Paolozzi (1979)Peter Blake (1981)David Hockney (1991)PresidentesPresidenteMandatoSir Joshua Reynolds1768 1792Benjamin West1792 1805James Wyatt1805 1806Benjamin West1806 1820Sir Thomas Lawrence1820 1830Sir Martin Archer Shee1830 1850Sir Charles Lock Eastlake1850 1865Sir Francis Grant1866 1878Frederic Leighton, Lord Leighton1878 1896Sir John Everett MillaisFebrero agosto 1896Sir Edward Poynter1896 1918Sir Aston Webb1919 1924Sir Frank Dicksee1924 1928Sir William Llewellyn1928 1938Sir Edwin Lutyens1938 1944Sir Alfred Munnings1944 1949Sir Gerald Kelly1949 1954Sir Albert Richardson1954 1956Sir Charles Wheeler1956 1966Sir Thomas Monnington1966 1976Sir Hugh Casson1976 1984Sir Roger de Grey1984 1993Sir Philip Dowson1993 1999Phillip King1999 2004Sir Nicholas Grimshaw2004 actualidadDirecciónRoyal Academy of Arts. Burlington House. Piccadilly. London W1J 0BDEnlaces externosPágina oficial de la Royal AcademyCategory:Museos de Londresar:الأكاديمية الملكية للفنون ca:Royal Academy of Arts cs:Royal Academy of Arts de:Royal Academy of Arts en:Royal Academy fr:Royal Academy he:האקדמיה המלכותית לאמנויות hu:Királyi Művészeti Akadémia it:Royal Academy of Arts ja:ロイヤル・アカデミー・オブ・アーツ nl:Royal Academy of Arts no:Royal Academy pl:Royal Academy pt:Academia Real Inglesa ru:Королевская Академия художеств simple:Royal Academy of Arts',\n",
              " ' thumb|right|200px| Basílica de San Andrea Vercelli (Vërsèj en piamontés) es una ciudad de Italia en la región del Piamonte, provincia de Vercelli. Tiene unos 60.000 habitantes y está situada a la orilla derecha del río Sesia. Se encuentra en medio de una gran llanura, entre Milán y Turín, muy bien irrigada y rodeada de campos de arroz, producto del que exporta a todo el mundo y del que es uno de los mayores mercados europeos. Su nombre deriva del celta Wercel, (Guardia de los celtas).HistoriaFue la capital de los Libiquis (Oppidium Vercellae) y formó parte de la Galia Cisalpina. En el 101 nbsp;a. nbsp;C. se libró una batalla en sus alededores entre los romanos dirigidos por el cónsul Cayo Mario contra los Cimbrios, que fueron derrotados en la Batalla de Vercelae. En el 89 nbsp;a. nbsp;C. la ciudad va a recibir el derecho romano. En tiempos de Estrabón era una villa fortificada, pero después se va a convertir en municipio (42 a. C.)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iie_3kS7H8-h",
        "colab_type": "text"
      },
      "source": [
        "At the moment is fine, other special characters that aren't necessary and the punctuation will be removed in the tokenization part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgMbHqYlLx9v",
        "colab_type": "text"
      },
      "source": [
        "## 4 Tokenize Words and Clean Up Text\n",
        "\n",
        "\n",
        "Tokenization is breaking the raw text into small chunks. Tokenization breaks the raw text into words, sentences called **tokens**. These tokens help in understanding the context or developing the model for the NLP. The tokenization helps in interpreting the meaning of the text by analyzing the sequence of the words.  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NtCnFidI3hm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Gensim’s **simple_preprocess()** is great for tokenization. Additionally I have set **deacc=True** to remove the punctuations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg8uaPYMuNBS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "41e4a2b1-2711-463f-947a-e1f5b03fc85a"
      },
      "source": [
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(textc))\n",
        "\n",
        "#Print an example of tokenization using the example above\n",
        "print(data_words[:1])\n",
        "  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['imagen', 'royalacademy', 'jpg', 'thumb', 'right', 'px', 'real', 'academia', 'de', 'arte', 'londres', 'la', 'royal', 'academy', 'of', 'arts', 'es', 'una', 'institucion', 'artistica', 'con', 'sede', 'en', 'piccadilly', 'hola', 'jpg', 'londres', 'la', 'real', 'academia', 'surgio', 'partir', 'de', 'una', 'disputa', 'en', 'la', 'sociedad', 'de', 'artistas', 'por', 'el', 'liderazgo', 'entre', 'dos', 'arquitectos', 'sir', 'william', 'chambers', 'james', 'paine', 'paine', 'gano', 'pero', 'chambers', 'juro', 'venganza', 'uso', 'sus', 'conexiones', 'con', 'el', 'rey', 'para', 'crear', 'una', 'nueva', 'institucion', 'artistica', 'la', 'real', 'academia', 'en', 'los', 'cuarenta', 'fundadores', 'fueron', 'admitidos', 'el', 'de', 'diciembre', 'de', 'sir', 'joshua', 'reynolds', 'fue', 'el', 'primer', 'presidente', 'benjamin', 'west', 'el', 'segundo', 'la', 'real', 'academia', 'no', 'recibe', 'apoyo', 'financiero', 'del', 'estado', 'ni', 'de', 'la', 'corona', 'obtiene', 'ingresos', 'de', 'sus', 'exposiciones', 'de', 'donaciones', 'la', 'academia', 'dirige', 'una', 'escuela', 'de', 'arte', 'para', 'postgraduados', 'con', 'sede', 'en', 'burlington', 'house', 'los', 'alumnos', 'suelen', 'hacer', 'dos', 'exposiciones', 'al', 'ano', 'el', 'numero', 'de', 'academicos', 'esta', 'limitado', 'se', 'busca', 'el', 'equilibrio', 'entre', 'las', 'distintas', 'disciplinas', 'asi', 'se', 'suele', 'exigir', 'que', 'haya', 'por', 'ejemplo', 'al', 'menos', 'escultores', 'arquitectos', 'ademas', 'de', 'los', 'miembros', 'de', 'la', 'academia', 'existen', 'asociados', 'pero', 'no', 'es', 'requisito', 'previo', 'para', 'ser', 'academico', 'la', 'eleccion', 'como', 'presidente', 'de', 'la', 'real', 'academia', 'suele', 'garantizar', 'ser', 'nombrado', 'caballero', 'si', 'es', 'que', 'el', 'presidente', 'no', 'ostenta', 'ya', 'tal', 'rango', 'los', 'miembros', 'del', 'publico', 'pueden', 'unirse', 'la', 'academia', 'como', 'amigos', 'haciendo', 'donaciones', 'lo', 'cual', 'es', 'otra', 'de', 'las', 'fuentes', 'de', 'financiacion', 'lista', 'de', 'principales', 'gainsborough', 'william', 'hunter', 'primer', 'academico', 'profesor', 'de', 'anatomia', 'angelica', 'kauffmann', 'sir', 'joshua', 'reynolds', 'presidente', 'ndash', 'benjamin', 'west', 'presidente', 'ndash', 'ndash', 'sir', 'thomas', 'lawrence', 'presidente', 'ndash', 'john', 'flaxman', 'profesor', 'de', 'escultura', 'ndash', 'sir', 'john', 'soane', 'profesor', 'de', 'la', 'academia', 'de', 'arquitectura', 'ndash', 'turner', 'john', 'constable', 'william', 'dyce', 'john', 'everett', 'millais', 'presidente', 'alfred', 'waterhouse', 'john', 'william', 'waterhouse', 'george', 'frederic', 'watts', 'sir', 'aston', 'webb', 'eduardo', 'paolozzi', 'peter', 'blake', 'david', 'hockney', 'joshua', 'reynolds', 'ndash', 'benjamin', 'west', 'ndash', 'james', 'wyatt', 'ndash', 'benjamin', 'west', 'ndash', 'sir', 'thomas', 'lawrence', 'ndash', 'sir', 'martin', 'archer', 'shee', 'ndash', 'sir', 'charles', 'lock', 'eastlake', 'ndash', 'sir', 'francis', 'grant', 'ndash', 'frederic', 'leighton', 'lord', 'leighton', 'ndash', 'sir', 'john', 'everett', 'millaisfebrero', 'ndash', 'agosto', 'sir', 'edward', 'poynter', 'ndash', 'sir', 'aston', 'webb', 'ndash', 'sir', 'frank', 'dicksee', 'ndash', 'sir', 'william', 'llewellyn', 'ndash', 'sir', 'edwin', 'lutyens', 'ndash', 'sir', 'alfred', 'munnings', 'ndash', 'sir', 'gerald', 'kelly', 'ndash', 'sir', 'albert', 'richardson', 'ndash', 'sir', 'charles', 'wheeler', 'ndash', 'sir', 'thomas', 'monnington', 'ndash', 'sir', 'hugh', 'casson', 'ndash', 'sir', 'roger', 'de', 'grey', 'ndash', 'sir', 'philip', 'dowson', 'ndash', 'phillip', 'king', 'ndash', 'sir', 'nicholas', 'grimshaw', 'ndash', 'academy', 'of', 'arts', 'burlington', 'house', 'piccadilly', 'london', 'bdenlaces', 'externospagina', 'oficial', 'de', 'la', 'royal', 'academycategory', 'museos', 'de', 'londresar', 'الاكاديمية', 'الملكية', 'للفنون', 'ca', 'royal', 'academy', 'of', 'arts', 'cs', 'royal', 'academy', 'of', 'arts', 'de', 'royal', 'academy', 'of', 'arts', 'en', 'royal', 'academy', 'fr', 'royal', 'academy', 'he', 'האקדמיה', 'המלכותית', 'לאמנויות', 'hu', 'kiralyi', 'muveszeti', 'akademia', 'it', 'royal', 'academy', 'of', 'arts', 'ja', 'ロイヤル', 'アカテミー', 'オフ', 'アーツ', 'nl', 'royal', 'academy', 'of', 'arts', 'no', 'royal', 'academy', 'pl', 'royal', 'academy', 'pt', 'academia', 'real', 'inglesa', 'ru', 'королевская', 'академия', 'художеств', 'simple', 'royal', 'academy', 'of', 'arts']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUU0Udje-fFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert the 3 different datafrae to lists\n",
        "\n",
        "english_list = english_df.Text.values.tolist()\n",
        "spanish_list = spanish_df.Text.values.tolist()\n",
        "french_list = french_df.Text.values.tolist()\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc47THABunLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Apply the function clean_characters to the different languages\n",
        "\n",
        "english_list = clean_characters(english_list)\n",
        "spanish_list = clean_characters(spanish_list)\n",
        "french_list = clean_characters(french_list)\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62f2x_xdNAPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Apply the function sent_to_words to get the tokenization arrays\n",
        "\n",
        "english_words = list(sent_to_words(english_list))\n",
        "french_words = list(sent_to_words(french_list))\n",
        "spanish_words = list(sent_to_words(spanish_list))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR_6ge7FPUzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqLgSFT9OJn5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## 5  Creating Bigram and Tirgram Models\n",
        "\n",
        "**Bigrams** are two words frequently occurring together in the document. \n",
        "\n",
        "\n",
        "  **Trigrams** are 3 words frequently occurring.  \n",
        "    \n",
        "      \n",
        "        \n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDqZLcT9PH5v",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**Gensim’s Phrases** model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are **min_count** and **threshold**. The higher the values of these param, the harder it is for words to be combined to bigrams.   \n",
        "\n",
        "\n",
        "    \n",
        "      \n",
        "             \n",
        "    \n",
        "   \n",
        "\n",
        "Some examples in our data are *defuncion_lugar*, *premios_oscar_premios_globo* or *otros_nombres_conyuge*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZXFVGs4N99D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f7f484be-246c-487d-c409-f2c1a0168b0c"
      },
      "source": [
        "# Build the bigram and trigram models\n",
        "\n",
        "# ENGLISH\n",
        "bigram_en = gensim.models.Phrases(english_words, min_count=4, threshold=80) # higher threshold fewer phrases.\n",
        "trigram_en = gensim.models.Phrases(bigram_en[english_words], threshold=80)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod_en = gensim.models.phrases.Phraser(bigram_en)\n",
        "trigram_mod_en = gensim.models.phrases.Phraser(trigram_en)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx-LJApVQTQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7a17b8d6-4214-433e-d11d-bfc89a4236fb"
      },
      "source": [
        "# See trigram example in English\n",
        "print(trigram_mod_en[bigram_mod_en[english_words[0]]])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dicovalence', 'valence', 'dictionary', 'of', 'french', 'formerly', 'known', 'as', 'proton', 'van_den', 'eynde', 'and', 'mertens', 'which', 'has', 'been', 'based', 'on', 'the', 'pronominal', 'approach', 'in', 'version', 'this', 'dictionary', 'details', 'the', 'frames', 'of', 'more', 'than', 'verbs', 'table', 'gives', 'an', 'example', 'of', 'dicovalence', 'entry', 'we', 'extracted', 'the', 'simple', 'and', 'multiword_prepositions', 'it', 'contains', 'more', 'than', 'as', 'well', 'as', 'their', 'associated', 'semantic', 'classes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW8CwHtDRYtm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "af40ad5c-4e5f-4b90-bfcc-de20b1a18bfc"
      },
      "source": [
        "# SPANISH\n",
        "bigram_es = gensim.models.Phrases(spanish_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram_es = gensim.models.Phrases(bigram_es[spanish_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod_es = gensim.models.phrases.Phraser(bigram_es)\n",
        "trigram_mod_es = gensim.models.phrases.Phraser(trigram_es)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB2Kk_4dRnAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3f53ea99-696f-4d01-e371-89b1a6271c9d"
      },
      "source": [
        " # See trigram example in Spanish\n",
        "print(trigram_mod_es[bigram_mod_es[spanish_words[0]]])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fecha', 'de', 'defuncion_lugar', 'de', 'defuncion', 'otros_nombres_conyuge', 'hijos_sitio_web', 'premios_oscar_premios_globo', 'de', 'oro_premios_bafta', 'premios_emmy_premios_sag', 'premios_tony_premios_grammy', 'premios_cannes_premios', 'san_sebastian_premios_goya', 'premios_cesar_premios_ariel', 'premios_condor_otros', 'premios_imdb', 'dominic_chianese', 'nacido', 'el', 'de', 'febrero', 'el', 'de', 'septiembre', 'de', 'http_www', 'filmreference', 'com', 'film', 'dominic_chianese', 'html_ref', 'es', 'un', 'actor', 'italo', 'americano', 'quizas', 'mas', 'conocido', 'por', 'su', 'papel', 'de', 'junior', 'soprano', 'en', 'la', 'serie', 'de', 'hbo', 'tv', 'los', 'soprano', 'un', 'papel', 'que', 'le', 'concedio', 'dos', 'nominaciones', 'los', 'premios_emmy', 'nacio', 'en', 'el', 'municipio', 'del', 'bronx', 'en', 'nueva_york', 'hijo', 'de', 'un', 'albanil', 'se', 'graduo', 'en', 'la', 'prestigiosa', 'bronx', 'high_school', 'of', 'science', 'en', 'trabajo', 'como', 'albanil', 'con', 'su', 'padre', 'asistia', 'la', 'escuela', 'nocturna', 'durante', 'la', 'decada', 'de', 'consiguiendo', 'su', 'licenciatura', 'en', 'teatro', 'declamacion', 'en', 'el', 'brooklyn', 'college', 'en', 'su', 'primer', 'trabajo', 'en', 'el', 'escenario', 'fue', 'en', 'en', 'una', 'compania', 'de', 'cantantes', 'actores', 'musicos', 'llamada', 'the', 'american', 'savoyards', 'haciendo', 'un', 'repertorio', 'de', 'gilbert', 'sullivan', 'bajo', 'la', 'direccion', 'de', 'dorothy', 'raedler', 'despues', 'de', 'una', 'decada', 'de', 'teatro', 'universitario', 'en', 'el', 'off_broadway', 'chianese', 'asistio', 'su', 'primera', 'clase', 'profesional', 'de', 'actuacion', 'en', 'los', 'hb', 'studios', 'de', 'manhattan', 'con', 'el', 'renombrado', 'maestro', 'walt', 'witcover', 'el', 'teatro', 'dramatico', 'musical', 'se', 'conviertieron', 'en', 'la', 'pasion', 'de', 'chianese', 'su', 'primer', 'espectaculo', 'en', 'broadway', 'fue', 'oliver', 'en', 'continuo', 'sus', 'actuaciones', 'en', 'teatros', 'de', 'broadway', 'off_broadway', 'teatros', 'provinciales', 'para', 'complementar', 'sus', 'ingresos', 'durante', 'los', 'periodos', 'de', 'sequia', 'tocaba', 'la', 'guitarra', 'ritmica', 'cantaba', 'en', 'tabernas', 'restaurantes', 'su', 'primera', 'aparicion', 'en', 'television', 'ocurrio', 'cuando', 'george', 'scott', 'le', 'recomendo', 'para', 'un', 'papel', 'en', 'la', 'aclamada', 'serie', 'east', 'side', 'west', 'side', 'en', 'francis_ford_coppola', 'eligio', 'chianese', 'como', 'johnny', 'ola', 'en', 'el', 'padrino', 'parte', 'ii', 'lo', 'que', 'desperto', 'su', 'carrera_cinematografica', 'que', 'culmino', 'en', 'varias', 'peliculas', 'junto', 'al', 'pacino', 'antes', 'de', 'recibir', 'la', 'llamada', 'para', 'el', 'padrino', 'parte', 'ii', 'chianese', 'trabajo', 'para', 'la', 'comision', 'de', 'drogas', 'del', 'estado', 'de', 'new_york', 'como', 'monitor', 'sociocultural', 'en', 'un', 'centro', 'de', 'rehabilitarcion', 'ensenaba', 'tocar', 'la', 'guitarra', 'mujeres', 'que', 'habian', 'estado', 'envueltas', 'en', 'crimenes', 'relacionados', 'con', 'las', 'drogas', 'ha_aparecido', 'en', 'cuatro', 'peliculas', 'junto', 'su', 'amigo', 'al', 'pacino', 'el', 'padrino', 'parte', 'ii', 'como', 'johnny', 'olatarde', 'de', 'perros', 'como', 'el', 'padre', 'de', 'sonnyjusticia', 'para', 'todos', 'como', 'carl', 'traversbuscando', 'richard', 'como', 'el', 'mismochianese', 'es', 'musico', 'ha', 'editado', 'un', 'cd', 'apropiadamente', 'llamado', 'hits', 'en', 'en', 'el', 'que', 'canta', 'canciones', 'americanas', 'italianas', 'incluso', 'interpreto', 'el', 'clasico', 'sentimental', 'de', 'salvatore', 'cardillo', 'core', 'ngrato', 'corazon', 'ingrato', 'al', 'final', 'de', 'la', 'tercera', 'temporada', 'de', 'los', 'soprano', 'su', 'manager', 'es', 'brian', 'liebman', 'que', 'tambien', 'representa', 'la', 'estrella', 'de', 'las', 'comedias', 'televisivas', 'mark', 'consuelos', 'su', 'hijo', 'dominic_chianese', 'jr', 'tambien', 'es', 'actor', 'aparece', 'en', 'la', 'temporada', 'final', 'de', 'los', 'soprano', 'como', 'un', 'miembro', 'de', 'la', 'familia', 'lupertazzi', 'referencias', 'categoria', 'italo', 'dominic_chianese', 'en', 'dominic_chianese', 'fr', 'dominic_chianese', 'it', 'dominic_chianese', 'nl', 'dominic_chianese', 'no', 'dominic_chianese', 'pl', 'dominic_chianese', 'sv', 'dominic_chianese']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S0-JtB3Ruhm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "24cbc3f5-faba-4309-fcf4-bb907c5e02f3"
      },
      "source": [
        "# FRENCh\n",
        "bigram_fr = gensim.models.Phrases(french_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram_fr = gensim.models.Phrases(bigram_fr[french_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod_fr = gensim.models.phrases.Phraser(bigram_fr)\n",
        "trigram_mod_fr = gensim.models.phrases.Phraser(trigram_fr)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee22fqIASNQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "27c71fa1-830a-4e98-887a-fd6d3e16f930"
      },
      "source": [
        "# See trigram example in Spanish\n",
        "print(trigram_mod_fr[bigram_mod_fr[french_words[0]]])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['un', 'exemple', 'de', 'conjonction', 'entre', 'preferences', 'est', 'pourrais', 'je', 'avoir', 'un', 'petit_dejeuner', 'et', 'un', 'repas', 'vegetarien', 'ou', 'agent', 'exprime', 'deux', 'preferences', 'qu', 'il', 'souhaite', 'satisfaire', 'et', 'il', 'aimerait', 'en', 'avoir', 'au', 'moins', 'une', 'des', 'deux', 'il', 'ne', 'peut', 'pas', 'les', 'avoir', 'toutes', 'la', 'semantique', 'des', 'disjonctions', 'est', 'une', 'modalite', 'de', 'choix', 'libre', 'par', 'exemple', 'je_suis', 'libre', 'lundi', 'ou', 'mardi', 'signifie', 'que', 'lundi', 'ou', 'mardi', 'est', 'un', 'jour', 'possible', 'pour', 'se', 'rencontrer', 'et', 'que', 'agent', 'est', 'indifferent', 'entre', 'les', 'deux']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpfS15l8Tbz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "48885872-d397-4220-d8a7-3c645d451a87"
      },
      "source": [
        "print(\"Num of English Trigrams\", len(trigram_mod_en[bigram_mod_en[english_words[0]]]))\n",
        "print(\"Num of Spanish Trigrams\", len(trigram_mod_es[bigram_mod_es[spanish_words[0]]]))\n",
        "print(\"Num of French Trigrams\", len(trigram_mod_fr[bigram_mod_fr[french_words[0]]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of English Trigrams 20\n",
            "Num of Spanish Trigrams 3806\n",
            "Num of French Trigrams 46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4amjwoQSgm1",
        "colab_type": "text"
      },
      "source": [
        "In the examples above, we can see how the words frequently ocurring together in the different languages.  \n",
        "\n",
        "It's interesting to see how the spanish has many more trigrams compared to English or French. Before give some conclusions, let's **remove Stop Words**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GW4S8PLUi7p",
        "colab_type": "text"
      },
      "source": [
        " ## 6 Remove Stopwords, Make Bigrams and Lemmatize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa1tqafLUs2J",
        "colab_type": "text"
      },
      "source": [
        "The bigrams model is ready. Let’s define the functions to remove the stopwords, make bigrams and lemmatization and call them sequentially."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXYS-GpWPiVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words_en = stopwords.words('english')\n",
        "stop_words_fr = stopwords.words('french')\n",
        "stop_words_es = stopwords.words('spanish')\n",
        "\n",
        "#Let's extend the stopwords with some unnecesary words coming from wikipedia corpus\n",
        "stop_words_en.extend(['jpg', 'thumbs', 'px'])\n",
        "stop_words_fr.extend(['jpg', 'thumbs', 'px'])\n",
        "stop_words_es.extend(['jpg', 'thumbs', 'px'])\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CT-kqw1vha0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts, stop_words):\n",
        "  \n",
        "  # Pass a stop words dictionary and a corpus of texts\n",
        "  return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "\n",
        "\n",
        "def make_bigrams(texts, lang):\n",
        "\n",
        "  #English Bigram by default\n",
        "\n",
        "  #Spanish Bigram\n",
        "  if lang == 'es':\n",
        "    return [bigram_mod_es[doc] for doc in texts]\n",
        "  \n",
        "  #French Bigram\n",
        "  elif lang == 'fr':\n",
        "    return [bigram_mod_fr[doc] for doc in texts]\n",
        "  \n",
        "  return [bigram_mod_en[doc] for doc in texts]\n",
        "  \n",
        "def make_trigrams(texts, lang):\n",
        "\n",
        "\n",
        "  if lang=='es':\n",
        "     return [trigram_mod_es[bigram_mod_es[doc]] for doc in texts]\n",
        "  #Spanish Trigram\n",
        "  elif lang == 'fr':\n",
        "    return [trigram_mod_fr[bigram_mod_fr[doc]] for doc in texts]\n",
        "\n",
        "  #English Trigram\n",
        "  return [trigram_mod_en[bigram_mod_en[doc]] for doc in texts]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1qnceZ_WHZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define Lemmatization function\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqIOGJfzZlmd",
        "colab_type": "text"
      },
      "source": [
        "Let’s call the functions- Once per language\n",
        "\n",
        "1. English\n",
        "2. Spanish\n",
        "3. French\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0kDc6UwZo4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUW6FbRX0mpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0535eb5e-eede-4b8a-9f8b-b7ec7bdeedd7"
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops_en = remove_stopwords(english_words,stop_words_en)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams_en = make_bigrams(data_words_nostops_en, 'en')\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams_en, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['valence', 'formerly', 'know', 'base', 'pronominal', 'version', 'detail', 'frame', 'verb', 'table', 'give', 'example', 'dicovalence', 'entry', 'extract', 'simple', 'multiword_preposition', 'contain', 'well', 'associated', 'semantic', 'class']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtCk9uRhavVu",
        "colab_type": "text"
      },
      "source": [
        "Let's Work in Spanish Language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DxOozZmasCb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "276ecf84-d50b-4a77-b905-a71734b686ce"
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops_es = remove_stopwords(spanish_words,stop_words_es)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams_es = make_bigrams(data_words_nostops_es, 'es')\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "nlp_es = spacy.load('es', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized_es = lemmatization(data_words_bigrams_es, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized_es[:1])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['oro', 'premios_bafta', 'premios_emmy', 'premios_sag', 'premio', 'premios_cesar', 'premios_imdb', 'nacido', 'febrero', 'septiembre', 'http_www', 'filmreference', 'actor', 'nacio', 'actore', 'gilbert', 'direccion', 'raedler', 'despue', 'pasion', 'teatros', 'provinciale', 'restaurante', 'primera', 'television', 'monitor', 'sociocultural', 'amigo', 'hit', 'cancione', 'final', 'actor', 'final', 'lupertazzi', 'dominic_chianese', 'dominic_chianese']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5gIvuBocQVn",
        "colab_type": "text"
      },
      "source": [
        "Let's Work in French Language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HCNXSBhcPAb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8a2d7697-afe3-487f-e9e2-df6237fdee7d"
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops_fr = remove_stopwords(french_words,fr_stop)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams_fr = make_bigrams(data_words_nostops_fr, 'fr')\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "nlp_fr = spacy.load('fr', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized_fr = lemmatization(data_words_bigrams_fr, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized_fr[:1])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['preference', 'repa', 'preference', 'aimerait', 'moin', 'semantique', 'disjonction', 'modalite', 'libre', 'possible', 'agent']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knt05dhMc17L",
        "colab_type": "text"
      },
      "source": [
        "## 7 Create the Dictionary and Corpus needed for Topic Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkzmuHuEdK-C",
        "colab_type": "text"
      },
      "source": [
        "The two main inputs to the LDA topic model are the dictionary(**id2word**) and the **corpus**. Let’s create them.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtE9ebBjvyqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a8ebd3e8-c113-48e8-a69a-e61dd3606929"
      },
      "source": [
        "# Create Dictionary. One for each language\n",
        "id2word_en = corpora.Dictionary(data_lemmatized)\n",
        "id2word_es = corpora.Dictionary(data_lemmatized_es)\n",
        "id2word_fr = corpora.Dictionary(data_lemmatized_fr)\n",
        "\n",
        "\n",
        "# Create Corpus. One for each Language\n",
        "texts_en = data_lemmatized\n",
        "texts_es = data_lemmatized_es\n",
        "texts_fr = data_lemmatized_fr\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus_en = [id2word_en.doc2bow(text) for text in texts_en]\n",
        "corpus_es = [id2word_es.doc2bow(text) for text in texts_es]\n",
        "corpus_fr = [id2word_fr.doc2bow(text) for text in texts_fr]\n",
        "\n",
        "# Print an example\n",
        "print(corpus_fr[:1])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6ji5aKTgaGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8002aa84-74b0-470e-e4ae-7891e08c7dfc"
      },
      "source": [
        "print(corpus_es[:1])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlfGEDiDeAJT",
        "colab_type": "text"
      },
      "source": [
        "Gensim creates a unique id for each word in the document. The produced corpus shown above is a **mapping of (word_id, word_frequency).**  \n",
        "  \n",
        "  For example, (0,2) above implies, word id 0 occurs once in the first document. Likewise, word id 1 occurs twice and so on.  \n",
        "  \n",
        "\n",
        " This is used as the **input by the LDA model**.  \n",
        "   \n",
        "\n",
        "If you want to see what word a given id corresponds to, pass the id as a **key to the dictionary.**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfwmKZjjd2e5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7afc667f-d282-4edc-faed-0d950b8c3b48"
      },
      "source": [
        "id2word_es[2]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'amigo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoU1jhfjfYfI",
        "colab_type": "text"
      },
      "source": [
        "Or we can see a term-frequenct of one document\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-VgElAqfUT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "b0846f60-cb84-49e5-a0af-f39a4713cf8f"
      },
      "source": [
        "[[(id2word_es[id], freq) for id, freq in cp] for cp in corpus_es[:1]]\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('actor', 2),\n",
              "  ('actore', 1),\n",
              "  ('amigo', 1),\n",
              "  ('cancione', 1),\n",
              "  ('despue', 1),\n",
              "  ('direccion', 1),\n",
              "  ('dominic_chianese', 2),\n",
              "  ('febrero', 1),\n",
              "  ('filmreference', 1),\n",
              "  ('final', 2),\n",
              "  ('gilbert', 1),\n",
              "  ('hit', 1),\n",
              "  ('http_www', 1),\n",
              "  ('lupertazzi', 1),\n",
              "  ('monitor', 1),\n",
              "  ('nacido', 1),\n",
              "  ('nacio', 1),\n",
              "  ('oro', 1),\n",
              "  ('pasion', 1),\n",
              "  ('premio', 1),\n",
              "  ('premios_bafta', 1),\n",
              "  ('premios_cesar', 1),\n",
              "  ('premios_emmy', 1),\n",
              "  ('premios_imdb', 1),\n",
              "  ('premios_sag', 1),\n",
              "  ('primera', 1),\n",
              "  ('provinciale', 1),\n",
              "  ('raedler', 1),\n",
              "  ('restaurante', 1),\n",
              "  ('septiembre', 1),\n",
              "  ('sociocultural', 1),\n",
              "  ('teatros', 1),\n",
              "  ('television', 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5_0kc06fxqb",
        "colab_type": "text"
      },
      "source": [
        "##8 Building the Topic Model\n",
        "\n",
        "Now, we are ready and we have everything to train our LDA model. Furthermore to corpus and the dictionary, we need to provide a number of topics.\n",
        "\n",
        "Apart from that, **alpha** and **eta** are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior.\n",
        "\n",
        "**chunksize** is the number of documents to be used in each training chunk. update_every **determines** how often the model parameters should be updated and passes is the total number of training passes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByISZKX-hDIb",
        "colab_type": "text"
      },
      "source": [
        "### 8.1 Working only with the Spanish Language\n",
        "\n",
        "As seen in the above results, Spanish is the Language with larger number of results in terms of Bigram and Trigram. There is no a specific reason for that, but \n",
        "\n",
        "We will discuss later, the different reasons why the Spanish give better results things we could improve on this model. To simplify the notebook,hereinafter **we will continue only in one language** (Spanish, as we said). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13VjDqNZhCbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build LDA model\n",
        "lda_model_es = gensim.models.ldamodel.LdaModel(corpus=corpus_es,\n",
        "                                           id2word=id2word_es,\n",
        "                                           num_topics=20, \n",
        "                                           random_state=42,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipWL5qtIicjb",
        "colab_type": "text"
      },
      "source": [
        "## 8 View the Topics in LDA Model\n",
        "\n",
        "The above LDA model is built with 20 different topics where each topic is a combination of keywords and each keyword gives a certain weight to the topic.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFNLcOllfw9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d074ac3a-23b2-42b5-ea92-83dbb64f6f71"
      },
      "source": [
        "# Print the Keyword in the topics\n",
        "pprint(lda_model_es.print_topics()) #Pprtin produces nice and aestetical pleasing views of data structures\n",
        "doc_lda = lda_model_es[corpus_es]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.053*\"sabe\" + 0.018*\"irresistible\" + 0.017*\"horrible\" + 0.016*\"morale\" + '\n",
            "  '0.015*\"desagradable\" + 0.014*\"pariente\" + 0.012*\"debe\" + 0.012*\"conocer\" + '\n",
            "  '0.012*\"loco\" + 0.009*\"presento\"'),\n",
            " (1,\n",
            "  '0.037*\"extension\" + 0.028*\"brazo\" + 0.017*\"chiste\" + 0.010*\"cancer\" + '\n",
            "  '0.008*\"trato\" + 0.008*\"exteriore\" + 0.008*\"singular\" + 0.008*\"indios\" + '\n",
            "  '0.007*\"solitario\" + 0.007*\"vino\"'),\n",
            " (2,\n",
            "  '0.086*\"usted\" + 0.027*\"palabra\" + 0.014*\"sere\" + 0.013*\"idea\" + '\n",
            "  '0.013*\"amigo\" + 0.012*\"siempre\" + 0.011*\"imposible\" + 0.010*\"corte\" + '\n",
            "  '0.009*\"sabio\" + 0.009*\"instante\"'),\n",
            " (3,\n",
            "  '0.093*\"voz\" + 0.040*\"espanole\" + 0.013*\"despue\" + 0.010*\"vox\" + '\n",
            "  '0.010*\"ustede\" + 0.010*\"felice\" + 0.009*\"conmigo\" + 0.009*\"prosiguio\" + '\n",
            "  '0.008*\"leer\" + 0.008*\"cancione\"'),\n",
            " (4,\n",
            "  '0.033*\"despue\" + 0.018*\"noche\" + 0.017*\"tenia\" + 0.017*\"iban\" + '\n",
            "  '0.016*\"call\" + 0.013*\"nuevo\" + 0.009*\"francese\" + 0.009*\"creia\" + '\n",
            "  '0.009*\"breve\" + 0.009*\"enorme\"'),\n",
            " (5,\n",
            "  '0.076*\"pue\" + 0.037*\"tre\" + 0.036*\"entonce\" + 0.029*\"despue\" + 0.019*\"sino\" '\n",
            "  '+ 0.016*\"vece\" + 0.015*\"toda\" + 0.014*\"mujere\" + 0.014*\"posible\" + '\n",
            "  '0.012*\"tiempo\"'),\n",
            " (6,\n",
            "  '0.026*\"ingle\" + 0.025*\"paise\" + 0.018*\"obra\" + 0.016*\"senor\" + '\n",
            "  '0.016*\"simple\" + 0.016*\"would\" + 0.015*\"ca\" + 0.014*\"trave\" + '\n",
            "  '0.012*\"importante\" + 0.012*\"corriente\"'),\n",
            " (7,\n",
            "  '0.031*\"dolore\" + 0.025*\"gente\" + 0.015*\"flore\" + 0.011*\"sublime\" + '\n",
            "  '0.009*\"prisionero\" + 0.009*\"ansi\" + 0.008*\"echar\" + 0.008*\"placere\" + '\n",
            "  '0.008*\"siguio\" + 0.007*\"obra\"'),\n",
            " (8,\n",
            "  '0.045*\"habitante\" + 0.033*\"poblacion\" + 0.032*\"ciudade\" + 0.021*\"indio\" + '\n",
            "  '0.014*\"region\" + 0.014*\"interese\" + 0.014*\"costumbre\" + 0.013*\"provincia\" + '\n",
            "  '0.011*\"atencion\" + 0.010*\"monte\"'),\n",
            " (9,\n",
            "  '0.033*\"pie\" + 0.024*\"cabeza\" + 0.020*\"color\" + 0.018*\"animale\" + '\n",
            "  '0.017*\"labio\" + 0.015*\"real\" + 0.013*\"hace\" + 0.011*\"tampoco\" + '\n",
            "  '0.011*\"dice\" + 0.010*\"diente\"'),\n",
            " (10,\n",
            "  '0.033*\"conversacion\" + 0.032*\"tristeza\" + 0.024*\"merce\" + 0.023*\"humor\" + '\n",
            "  '0.016*\"voy\" + 0.015*\"diamante\" + 0.014*\"imaginacion\" + 0.013*\"semejante\" + '\n",
            "  '0.010*\"hallo\" + 0.009*\"imaginarse\"'),\n",
            " (11,\n",
            "  '0.262*\"uste\" + 0.020*\"doctor\" + 0.017*\"replico\" + 0.016*\"dona_luz\" + '\n",
            "  '0.009*\"pliegue\" + 0.009*\"liberale\" + 0.007*\"insensible\" + 0.005*\"ver\" + '\n",
            "  '0.004*\"ascension\" + 0.004*\"revolucion\"'),\n",
            " (12,\n",
            "  '0.018*\"llave\" + 0.017*\"suave\" + 0.013*\"aire\" + 0.013*\"agradable\" + '\n",
            "  '0.013*\"grandeza\" + 0.012*\"afeccione\" + 0.011*\"dosis\" + 0.011*\"enfermedade\" '\n",
            "  '+ 0.011*\"elegante\" + 0.009*\"tale\"'),\n",
            " (13,\n",
            "  '0.021*\"vestir\" + 0.021*\"satisfaccion\" + 0.017*\"verdad\" + 0.014*\"alli\" + '\n",
            "  '0.014*\"inexplicable\" + 0.009*\"almacene\" + 0.009*\"guante\" + '\n",
            "  '0.009*\"procesion\" + 0.008*\"hiciese\" + 0.008*\"final\"'),\n",
            " (14,\n",
            "  '0.038*\"amore\" + 0.017*\"coche\" + 0.014*\"comune\" + 0.013*\"version\" + '\n",
            "  '0.012*\"ladrone\" + 0.011*\"utilidade\" + 0.009*\"hablo\" + 0.008*\"profusion\" + '\n",
            "  '0.007*\"corporale\" + 0.007*\"elogio\"'),\n",
            " (15,\n",
            "  '0.092*\"dio\" + 0.026*\"frase\" + 0.021*\"religion\" + 0.013*\"diose\" + '\n",
            "  '0.013*\"costumbre\" + 0.012*\"progreso\" + 0.012*\"carne\" + 0.012*\"luce\" + '\n",
            "  '0.008*\"sensacion\" + 0.008*\"virtude\"'),\n",
            " (16,\n",
            "  '0.015*\"voce\" + 0.011*\"indudable\" + 0.011*\"vehemente\" + 0.010*\"perfume\" + '\n",
            "  '0.009*\"compone\" + 0.007*\"sono\" + 0.006*\"toca\" + 0.006*\"love\" + 0.006*\"blue\" '\n",
            "  '+ 0.006*\"life\"'),\n",
            " (17,\n",
            "  '0.026*\"quiere\" + 0.015*\"medio\" + 0.015*\"particulare\" + 0.015*\"pobre\" + '\n",
            "  '0.013*\"puso\" + 0.011*\"espectadore\" + 0.011*\"educacion\" + 0.010*\"pie\" + '\n",
            "  '0.010*\"adio\" + 0.009*\"intencion\"'),\n",
            " (18,\n",
            "  '0.027*\"terrible\" + 0.023*\"triste\" + 0.018*\"despue\" + 0.013*\"caballo\" + '\n",
            "  '0.012*\"verde\" + 0.012*\"alegre\" + 0.011*\"inglese\" + 0.011*\"senore\" + '\n",
            "  '0.010*\"rebelde\" + 0.009*\"senora\"'),\n",
            " (19,\n",
            "  '0.022*\"trate\" + 0.016*\"oriente\" + 0.014*\"apacible\" + 0.011*\"quehacere\" + '\n",
            "  '0.011*\"catorce\" + 0.010*\"ermitano\" + 0.008*\"posesion\" + 0.007*\"ocho\" + '\n",
            "  '0.007*\"coro\" + 0.006*\"go\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKHAa8arjYvT",
        "colab_type": "text"
      },
      "source": [
        "### 8.1 Interpret the data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Topic 0 is a represented as  0.053 *  *sabe* + 0.018 * *irresistible* + 0.017 * *horrible* + 0.016 * *morale* + 0.015 * *desagradable* + 0.014 * *pariente* + 0.012 * *debe* + 0.012 * *conocer* + 0.012 * *loco* + 0.00 9*\"presento\"') ....  \n",
        "  \n",
        "\n",
        "It means, the top 10 keywords in this topic are:\n",
        "\n",
        "Sabe, irresistible,horrible , desagradable, pariente, emitir, and so on....\n",
        "\n",
        " 0.053 is the weight the word \"sabe\" has in the topic\n",
        "\n",
        "**The greater the weight, the most important the keyword in the topic**  \n",
        "\n",
        "\n",
        "\n",
        "| Weight in Topic | Word |\n",
        "|-------|-----------|\n",
        "| 0.053 | sabe  |\n",
        "| 0.018 | irresistible  |\n",
        "| 0.017 | horrible       |\n",
        "| 0.016 | desagradable       |\n",
        "| 0.014 | pariente     |\n",
        "| 0.012 | emitir    |\n",
        "| 0.012 | debe      |\n",
        "| 0.012 | conocer    |\n",
        "| 0.012 | loco     |\n",
        "| 0.009 | presento     |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsCz3oL2a4xc",
        "colab_type": "text"
      },
      "source": [
        "It means the top 10 keywords that contribute to this topic are: sabe, irresistible, ‘light’.. and so on and the weight of ‘car’ on topic 0 is 0.016."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8KCQ_yUbUXh",
        "colab_type": "text"
      },
      "source": [
        "##9 Compute Model Perplexity and Coherence Score\n",
        "\n",
        "Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is.   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3vAzsZeeuU7",
        "colab_type": "text"
      },
      "source": [
        "  \n",
        "  **Perplexity** In general, perplexity is a measurement of **how well a probability model predicts a sample**. In the context of Natural Language Processing, perplexity is one way to **evaluate language models**.\n",
        "\n",
        " The best language model is one that best predicts an unseen test set. Perplexity is the inverse probability of the test set, normalized by the number of words. [Detailed info and formulas](https://towardsdatascience.com/perplexity-intuition-and-derivation-105dd481c8f3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9tfsqhef0zz",
        "colab_type": "text"
      },
      "source": [
        "**Coherence Score**. Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUvahXXIhUCk",
        "colab_type": "text"
      },
      "source": [
        "The coherence measure we will use is c_v. C_v measure is based on a sliding window, one-set segmentation of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo3l3UtrbTzB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "7b8d72aa-4fd2-46b9-90fd-fef75030d4f3"
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model_es.log_perplexity(corpus_es))  # a measure of how good the model is. The lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model_es, texts=data_lemmatized_es, dictionary=id2word_es, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -10.698730047120495\n",
            "\n",
            "Coherence Score:  0.42470641754696103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg911Po3lWw7",
        "colab_type": "text"
      },
      "source": [
        "##9 Visualize the topics-keywords\n",
        "\n",
        "Now that the LDA model is built, the next step is to examine the produced topics and the associated keywords. There is no better tool than pyLDAvis package’s interactive chart and is designed to work well with interactive notebooks.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V96HCktflWGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "edbfd31c-6b59-44a5-a9ed-e695bc5eccce"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model_es, corpus_es, id2word_es)\n",
        "vis\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1031397348214231684366523049\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1031397348214231684366523049_data = {\"mdsDat\": {\"x\": [0.35228786104286736, 0.12290144254362911, 0.20290505480204324, 0.13432821624179153, 0.018285774752834865, 0.0922558123804141, -0.0008287359671826947, 0.01010456392348945, 0.024287783433363856, -0.11909269033278784, 0.020209235450968456, -0.05427600810751749, -0.09386916924959371, -0.07079218811417526, -0.09708219780141704, -0.08453742278853135, -0.10855435501211406, -0.10544935425677841, -0.12098359215755827, -0.12210003078374511], \"y\": [-0.09934918574285635, 0.06251121319593589, -0.1376661678739221, 0.2925099500142934, -0.06885814315520006, -0.09146048957154769, 0.00858631195245529, 0.15285637228722138, 0.1242319514827914, -0.03489404679381566, -0.04425699018667638, 0.009985979092325351, -0.012385979588706908, -0.00551048420576846, -0.023182657520536325, -0.019646036726012315, -0.026044717610637067, -0.03345982483518492, -0.025660263328015506, -0.028306790886143157], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [16.291345596313477, 10.576419830322266, 7.791522026062012, 7.116216659545898, 6.056928634643555, 5.299421787261963, 5.297818183898926, 4.771352767944336, 4.456505298614502, 4.284841537475586, 4.244612216949463, 3.8208513259887695, 3.077479362487793, 2.728738784790039, 2.725170135498047, 2.560807466506958, 2.554565668106079, 2.3905208110809326, 2.2293522357940674, 1.7255293130874634]}, \"tinfo\": {\"Term\": [\"uste\", \"pue\", \"voz\", \"dio\", \"usted\", \"despue\", \"entonce\", \"tre\", \"habitante\", \"espanole\", \"pie\", \"paise\", \"sino\", \"ingle\", \"sabe\", \"poblacion\", \"ciudade\", \"cabeza\", \"toda\", \"obra\", \"terrible\", \"mujere\", \"extension\", \"amore\", \"vece\", \"frase\", \"senor\", \"quiere\", \"palabra\", \"color\", \"pue\", \"sino\", \"toda\", \"mujere\", \"espiritu\", \"hombre\", \"reale\", \"tenian\", \"comun\", \"riqueza\", \"hacer\", \"pare\", \"mayore\", \"falta\", \"razone\", \"creyo\", \"podian\", \"meno\", \"belleza\", \"nave\", \"decir\", \"caractere\", \"virtud\", \"vera\", \"considerable\", \"comer\", \"cabo\", \"mugere\", \"sacerdote\", \"viage\", \"opinion\", \"mismo\", \"poder\", \"fin\", \"libre\", \"tre\", \"vece\", \"entonce\", \"posible\", \"cuale\", \"tiempo\", \"pueblo\", \"fuerte\", \"despue\", \"aunque\", \"segun\", \"idea\", \"part\", \"hora\", \"ocasion\", \"situacion\", \"paise\", \"senor\", \"sombra\", \"enlace\", \"moral\", \"cura\", \"puente\", \"millare\", \"sentir\", \"sensible\", \"londre\", \"sociedade\", \"base\", \"lengua\", \"trabajadore\", \"pece\", \"salud\", \"libertade\", \"industriale\", \"organizacion\", \"autor\", \"corriente\", \"would\", \"administracion\", \"intere\", \"division\", \"fiebre\", \"traduccion\", \"crear\", \"majestad\", \"ca\", \"ingle\", \"estudio\", \"derechos\", \"simple\", \"produccion\", \"importante\", \"obra\", \"siguiente\", \"trave\", \"principio\", \"principal\", \"france\", \"vario\", \"diferente\", \"servicio\", \"anteriore\", \"primera\", \"inter\", \"noche\", \"iban\", \"call\", \"creia\", \"combate\", \"impulso\", \"pormenore\", \"canton\", \"espalda\", \"enemigo\", \"venian\", \"principale\", \"honor\", \"billet\", \"miserable\", \"pedir\", \"plane\", \"capitane\", \"poseia\", \"trance\", \"deseo\", \"terreno\", \"pendiente\", \"salon\", \"buque\", \"me\", \"increible\", \"blanco\", \"seguia\", \"permanecer\", \"francese\", \"volvio\", \"papele\", \"tenia\", \"breve\", \"nuevo\", \"padre\", \"despue\", \"enorme\", \"grande\", \"detra\", \"france\", \"inter\", \"oficiale\", \"entonce\", \"nunca\", \"vario\", \"tre\", \"cabeza\", \"color\", \"animale\", \"labio\", \"hace\", \"dice\", \"diente\", \"admirable\", \"arbole\", \"especie\", \"amable\", \"valle\", \"bastante\", \"ave\", \"sensacione\", \"abrigo\", \"dinero\", \"iguale\", \"cualidade\", \"tener\", \"primore\", \"confederacion\", \"nube\", \"azule\", \"pura\", \"indispensable\", \"sujeto\", \"capace\", \"volver\", \"madre\", \"real\", \"favor\", \"pie\", \"tampoco\", \"naturaleza\", \"expresion\", \"tierra\", \"solo\", \"enorme\", \"diferente\", \"cuya\", \"cuyas\", \"voz\", \"espanole\", \"vox\", \"ustede\", \"felice\", \"conmigo\", \"prosiguio\", \"cancione\", \"interminable\", \"peore\", \"emocione\", \"oposicion\", \"echo\", \"cruel\", \"premio\", \"anselmo\", \"actore\", \"feliz\", \"mejor\", \"drama\", \"peor\", \"diario\", \"siento\", \"dejando\", \"oyente\", \"ponerse\", \"inspiracion\", \"episodio\", \"tocaban\", \"television\", \"actor\", \"come\", \"leer\", \"publico\", \"despue\", \"original\", \"mese\", \"director\", \"terrible\", \"triste\", \"caballo\", \"verde\", \"alegre\", \"inglese\", \"senore\", \"rebelde\", \"senora\", \"grave\", \"desnoyer\", \"dificultade\", \"pase\", \"centenare\", \"edificios\", \"sala\", \"edificio\", \"bote\", \"venerable\", \"miseria\", \"darle\", \"transeunte\", \"respetable\", \"faltaban\", \"fisonomia\", \"sangre\", \"inocente\", \"asunto\", \"lance\", \"flande\", \"militare\", \"tomo\", \"despue\", \"cuyas\", \"inter\", \"habitante\", \"poblacion\", \"indio\", \"interese\", \"provincia\", \"atencion\", \"monte\", \"capital\", \"resistir\", \"regione\", \"portuguese\", \"baure\", \"sabian\", \"mamore\", \"gigante\", \"doce\", \"brasil\", \"india\", \"situada\", \"barrio\", \"llevaban\", \"caudale\", \"calle\", \"provincias\", \"timbue\", \"pudiera\", \"salvage\", \"vaud\", \"corredore\", \"hotele\", \"region\", \"ciudade\", \"costumbre\", \"actual\", \"comercio\", \"direccion\", \"lugare\", \"importante\", \"total\", \"area\", \"medio\", \"agradable\", \"dio\", \"frase\", \"diose\", \"progreso\", \"carne\", \"luce\", \"sensacion\", \"virtude\", \"fiele\", \"si\", \"cristiano\", \"espiritual\", \"contigo\", \"criatura\", \"continuo\", \"sacrificio\", \"consideracione\", \"senal\", \"dependiente\", \"invisible\", \"inefable\", \"bueno\", \"verse\", \"insignificante\", \"facile\", \"razonable\", \"situacione\", \"oracion\", \"infatigable\", \"escritore\", \"propio\", \"religion\", \"vision\", \"costumbre\", \"senale\", \"expresion\", \"quiere\", \"naturaleza\", \"imposible\", \"tale\", \"padre\", \"usted\", \"palabra\", \"sere\", \"siempre\", \"corte\", \"sabio\", \"instante\", \"dulce\", \"amor\", \"desesperacion\", \"observacion\", \"pretexto\", \"onda\", \"firmeza\", \"diciendo\", \"impresion\", \"parecer\", \"incomprensible\", \"comprender\", \"colmo\", \"ulise\", \"compasion\", \"llevo\", \"nino\", \"sudore\", \"intelectual\", \"viveza\", \"delicadeza\", \"ponen\", \"pregunto\", \"hecho\", \"amigo\", \"resolucion\", \"imposible\", \"pasion\", \"sentimiento\", \"idea\", \"voce\", \"indudable\", \"vehemente\", \"perfume\", \"compone\", \"sono\", \"toca\", \"life\", \"empleado\", \"mate\", \"muelle\", \"bad\", \"king\", \"banda\", \"say\", \"sone\", \"piano\", \"continue\", \"jazz\", \"face\", \"oops_did\", \"take\", \"aparecio\", \"comunidad\", \"metro\", \"guitarra\", \"oscuridad\", \"death\", \"fall\", \"rise\", \"blue\", \"love\", \"time\", \"pepe\", \"man\", \"high\", \"particulare\", \"puso\", \"espectadore\", \"educacion\", \"adio\", \"intencion\", \"mano\", \"dia\", \"ejecucion\", \"sera\", \"tonele\", \"suelo\", \"observo\", \"tarde\", \"rubio\", \"retiro\", \"ideal\", \"tall\", \"andre\", \"triunfo\", \"noble\", \"pinto\", \"sola\", \"calidade\", \"extraneza\", \"nueve\", \"admiracion\", \"infante\", \"hermana\", \"paseo\", \"quiere\", \"pobre\", \"medio\", \"brillante\", \"detra\", \"perdio\", \"pie\", \"participacion\", \"final\", \"posicion\", \"entonce\", \"llave\", \"suave\", \"aire\", \"grandeza\", \"afeccione\", \"dosis\", \"enfermedade\", \"elegante\", \"hacian\", \"princesa\", \"hizo\", \"tension\", \"pensar\", \"supo\", \"rayo\", \"accidente\", \"inconveniente\", \"eminente\", \"gala\", \"felipe\", \"rev\", \"relieve\", \"materiale\", \"precaucion\", \"severidad\", \"gas\", \"estrenimiento\", \"separacion\", \"nervio\", \"convulsione\", \"propiedade\", \"agradable\", \"accion\", \"tale\", \"factor\", \"so\", \"leve\", \"amore\", \"coche\", \"ladrone\", \"utilidade\", \"hablo\", \"profusion\", \"corporale\", \"elogio\", \"brutale\", \"software\", \"tour\", \"polvo\", \"inutile\", \"lamentable\", \"editor\", \"saber\", \"muchacha\", \"novio\", \"paquete\", \"pasar\", \"conversacione\", \"tenor\", \"viene\", \"denominacion\", \"virus\", \"peligroso\", \"altar\", \"duro\", \"conductore\", \"picante\", \"comune\", \"version\", \"permite\", \"presente\", \"uste\", \"doctor\", \"replico\", \"dona_luz\", \"pliegue\", \"liberale\", \"insensible\", \"ascension\", \"revolucion\", \"adorable\", \"se\", \"crimene\", \"tesoro\", \"case\", \"incansable\", \"oradore\", \"pide\", \"basis\", \"contemplacion\", \"holande\", \"achaque\", \"pustula\", \"digna\", \"incurable\", \"proponer\", \"profesion\", \"sonreia\", \"ese\", \"reia\", \"tertulia\", \"espuma\", \"ver\", \"respecto\", \"senale\", \"right\", \"funcione\", \"leave\", \"entonce\", \"sabe\", \"irresistible\", \"horrible\", \"morale\", \"desagradable\", \"pariente\", \"debe\", \"conocer\", \"loco\", \"ejercicio\", \"poner\", \"intelectuale\", \"ninos\", \"ardiente\", \"incomparable\", \"vicio\", \"beso\", \"discusion\", \"beneficio\", \"toma\", \"sainete\", \"ibid\", \"male\", \"curioso\", \"note\", \"atroce\", \"quinone\", \"film\", \"die\", \"conducir\", \"presento\", \"respecto\", \"pobre\", \"empieza\", \"dolore\", \"gente\", \"flore\", \"sublime\", \"prisionero\", \"ansi\", \"echar\", \"placere\", \"siguio\", \"papa\", \"tentacion\", \"ribera\", \"prodigio\", \"misterio\", \"sutile\", \"horrore\", \"cespe\", \"pintore\", \"nina\", \"perfeccion\", \"pretendiente\", \"ambicion\", \"alba\", \"ignorante\", \"lleven\", \"seculare\", \"canonigo\", \"espirituale\", \"pace\", \"rogo\", \"catedral\", \"leve\", \"obra\", \"conversacion\", \"tristeza\", \"merce\", \"humor\", \"voy\", \"diamante\", \"imaginacion\", \"semejante\", \"hallo\", \"imaginarse\", \"confusa\", \"moradore\", \"revolver\", \"defpue\", \"qual\", \"visto\", \"reflexion\", \"anadio\", \"resulta\", \"hallase\", \"consideracion\", \"discreta\", \"repitio\", \"callejon\", \"sosten\", \"cohete\", \"sencillez\", \"chriftianos\", \"permiso\", \"numero\", \"vestir\", \"satisfaccion\", \"verdad\", \"alli\", \"inexplicable\", \"almacene\", \"guante\", \"procesion\", \"hiciese\", \"partidos\", \"campana\", \"image\", \"horizonte\", \"estadio\", \"culpable\", \"apunte\", \"africanos\", \"ganado\", \"seleccion\", \"verla\", \"bosque\", \"escaparate\", \"dude\", \"queda\", \"atributo\", \"desigual\", \"carecer\", \"haberme\", \"dama\", \"ramillete\", \"final\", \"nacional\", \"colore\", \"brazo\", \"chiste\", \"trato\", \"exteriore\", \"singular\", \"indios\", \"solitario\", \"vino\", \"mortale\", \"vio\", \"system\", \"negacion\", \"dolor\", \"tiradore\", \"adela\", \"tripulacion\", \"prevision\", \"negarse\", \"albane\", \"serio\", \"usada\", \"insomnio\", \"marca\", \"cruele\", \"ultimamente\", \"open\", \"cancer\", \"pasan\", \"playoff\", \"emplear\", \"extension\", \"radio\", \"trate\", \"oriente\", \"apacible\", \"quehacere\", \"catorce\", \"ermitano\", \"posesion\", \"ocho\", \"coro\", \"go\", \"invitacion\", \"merece\", \"costa\", \"esclava\", \"constelacion\", \"arrojo\", \"sk\", \"sesion\", \"ferrocarrile\", \"firm\", \"sant\", \"home\", \"doliente\", \"girl\", \"ofreci\", \"constituye\", \"adversario\", \"reconocian\", \"sevre\", \"atribucione\", \"localidade\", \"ver\"], \"Freq\": [2553.0, 4416.0, 2021.0, 1565.0, 1367.0, 3228.0, 2450.0, 2448.0, 857.0, 872.0, 992.0, 961.0, 1108.0, 1046.0, 513.0, 619.0, 656.0, 604.0, 865.0, 975.0, 515.0, 833.0, 444.0, 418.0, 1042.0, 444.0, 605.0, 502.0, 426.0, 500.0, 4415.7802734375, 1107.1427001953125, 864.4404907226562, 832.8616943359375, 639.3272094726562, 636.6007080078125, 424.2084655761719, 385.20623779296875, 366.3594970703125, 347.78021240234375, 250.9955596923828, 250.15016174316406, 245.61573791503906, 231.12136840820312, 225.93287658691406, 199.21563720703125, 198.9739532470703, 196.77589416503906, 196.71778869628906, 188.9562530517578, 184.2643280029297, 175.96697998046875, 164.51031494140625, 157.76148986816406, 154.84121704101562, 152.76841735839844, 150.44146728515625, 146.4406280517578, 145.09471130371094, 131.66172790527344, 275.0953369140625, 359.4554748535156, 565.4443969726562, 462.642333984375, 224.6218719482422, 2140.740234375, 944.2371826171875, 2099.815185546875, 811.3641967773438, 647.7730102539062, 724.334228515625, 373.1679382324219, 263.98138427734375, 1681.2998046875, 416.0000915527344, 346.2630615234375, 388.0709533691406, 323.4676818847656, 303.6292724609375, 301.6042175292969, 262.9777526855469, 960.5323486328125, 604.7028198242188, 358.0302734375, 291.57196044921875, 288.1551818847656, 245.7791290283203, 234.67076110839844, 223.2625274658203, 221.67788696289062, 201.29754638671875, 196.14891052246094, 180.14376831054688, 179.2548828125, 177.0887908935547, 175.21165466308594, 153.19886779785156, 153.1605682373047, 153.11947631835938, 150.9278564453125, 143.9192657470703, 140.1273193359375, 439.78076171875, 593.9973754882812, 129.2809600830078, 125.97589111328125, 125.19009399414062, 120.86089324951172, 120.73167419433594, 117.34021759033203, 115.76286315917969, 552.0374145507812, 979.6646118164062, 431.342041015625, 282.2218933105469, 601.0524291992188, 367.0688171386719, 469.6622009277344, 673.2167358398438, 283.3151550292969, 522.2501220703125, 334.1148681640625, 316.6270446777344, 304.58343505859375, 342.1440734863281, 371.47723388671875, 270.0629577636719, 234.48452758789062, 239.92214965820312, 262.7481994628906, 512.9183959960938, 459.4698486328125, 445.2103271484375, 241.2111358642578, 206.8789520263672, 198.540771484375, 197.2347412109375, 172.5918731689453, 169.89669799804688, 160.6107635498047, 156.14195251464844, 153.45071411132812, 145.138427734375, 140.44491577148438, 138.08326721191406, 132.83099365234375, 129.17526245117188, 128.67227172851562, 123.14029693603516, 116.89695739746094, 113.03372955322266, 111.73147583007812, 110.23817443847656, 105.8399429321289, 104.28591918945312, 99.93305969238281, 99.31678771972656, 93.42849731445312, 89.14859008789062, 86.9266128540039, 250.05282592773438, 176.59451293945312, 184.95803833007812, 481.086181640625, 240.6729736328125, 354.8525085449219, 226.56613159179688, 917.346435546875, 239.71844482421875, 165.2396697998047, 191.81590270996094, 192.1127166748047, 207.26373291015625, 149.1621856689453, 208.16943359375, 140.51480102539062, 146.63446044921875, 152.01300048828125, 603.8441162109375, 499.4332580566406, 456.1505126953125, 442.3507995605469, 329.2798767089844, 268.7355041503906, 265.9549865722656, 259.9507141113281, 242.26919555664062, 210.35772705078125, 191.0252227783203, 166.24342346191406, 160.01925659179688, 148.96176147460938, 145.1683349609375, 143.89222717285156, 136.2218475341797, 134.72695922851562, 128.28366088867188, 114.81222534179688, 113.08953857421875, 111.31493377685547, 106.50938415527344, 102.86898803710938, 101.3536376953125, 96.98191833496094, 93.31871032714844, 90.62639617919922, 86.87837982177734, 86.4083023071289, 382.7001037597656, 226.020263671875, 834.7672119140625, 285.9346618652344, 260.0203857421875, 158.551513671875, 137.8032684326172, 167.31236267089844, 168.2153778076172, 189.7682342529297, 138.89779663085938, 131.3619842529297, 2020.311767578125, 871.3817749023438, 220.25697326660156, 218.55438232421875, 218.3133087158203, 201.24607849121094, 197.78341674804688, 167.88145446777344, 137.57162475585938, 136.81285095214844, 136.4136199951172, 132.512451171875, 132.09263610839844, 123.00596618652344, 118.65542602539062, 114.72113800048828, 116.7257080078125, 107.36112213134766, 103.50545501708984, 103.40791320800781, 97.04566192626953, 94.3182601928711, 87.52552032470703, 86.55400848388672, 85.52581787109375, 84.0492935180664, 80.77364349365234, 79.17948150634766, 77.13756561279297, 76.3963623046875, 94.9351577758789, 149.60845947265625, 173.81951904296875, 142.7819366455078, 276.3881530761719, 122.39920043945312, 114.76460266113281, 89.89515686035156, 514.102783203125, 441.4078674316406, 244.1240692138672, 232.6563720703125, 229.77685546875, 202.00035095214844, 200.146728515625, 183.39707946777344, 163.21131896972656, 157.4610595703125, 154.6118621826172, 151.51060485839844, 147.22804260253906, 138.8602752685547, 120.36965942382812, 117.73661041259766, 98.20457458496094, 96.1878890991211, 95.49382781982422, 91.5134506225586, 90.13549041748047, 82.35816192626953, 82.11604309082031, 81.11829376220703, 79.211669921875, 74.64391326904297, 72.78945922851562, 72.74232482910156, 72.4091567993164, 70.85813903808594, 140.42800903320312, 107.5791244506836, 338.12353515625, 108.58038330078125, 91.08314514160156, 856.1036987304688, 618.362060546875, 388.3036193847656, 264.6584167480469, 244.72325134277344, 207.3551788330078, 183.30519104003906, 129.2312774658203, 117.66661834716797, 107.89923095703125, 101.48625183105469, 97.27830505371094, 86.67440032958984, 74.11414337158203, 72.99451446533203, 71.78331756591797, 71.5197525024414, 69.86542510986328, 69.53766632080078, 69.17951202392578, 68.71380615234375, 67.80292510986328, 67.47376251220703, 66.16392517089844, 64.68984985351562, 59.958499908447266, 58.88064956665039, 58.76172637939453, 57.05588912963867, 55.73106002807617, 268.1318359375, 607.8263549804688, 257.8235778808594, 120.73067474365234, 83.82986450195312, 119.27800750732422, 125.79488372802734, 132.66122436523438, 82.78466033935547, 74.73583221435547, 79.34967803955078, 73.15336608886719, 1564.3736572265625, 443.8092346191406, 225.18626403808594, 210.48025512695312, 210.2420196533203, 209.30494689941406, 141.8253631591797, 130.96836853027344, 126.76427459716797, 113.70030212402344, 105.4065170288086, 101.68647003173828, 100.3240966796875, 92.897705078125, 92.12904357910156, 90.0694808959961, 86.85877990722656, 84.8817138671875, 82.16852569580078, 78.98741912841797, 73.04627227783203, 70.86670684814453, 70.48480224609375, 69.92341613769531, 67.8757553100586, 67.48104858398438, 65.19929504394531, 63.823768615722656, 59.49998474121094, 56.79344940185547, 111.38839721679688, 359.7380676269531, 111.35272216796875, 216.72837829589844, 99.26966094970703, 102.5436782836914, 108.35324096679688, 113.43173217773438, 87.05317687988281, 85.04350280761719, 86.3200454711914, 1366.0706787109375, 425.1368408203125, 225.5163116455078, 189.07933044433594, 153.6736297607422, 140.47962951660156, 136.9564208984375, 126.1172103881836, 112.11942291259766, 95.0727310180664, 94.3202896118164, 88.31350708007812, 86.09327697753906, 85.29166412353516, 84.12067413330078, 81.15038299560547, 78.3653564453125, 76.16980743408203, 71.49978637695312, 66.60298156738281, 66.39091491699219, 65.06123352050781, 64.90058898925781, 63.38919448852539, 61.46734619140625, 61.42778778076172, 61.24260330200195, 60.89210891723633, 58.31299591064453, 58.2729606628418, 108.7585220336914, 201.55287170410156, 108.16960906982422, 177.51217651367188, 112.08675384521484, 87.28919982910156, 203.5393829345703, 232.74903869628906, 175.54965209960938, 160.69827270507812, 148.92141723632812, 141.61639404296875, 105.82636260986328, 96.52738189697266, 93.06443786621094, 86.69068145751953, 76.9916000366211, 74.56585693359375, 69.956787109375, 69.0105209350586, 67.15071868896484, 65.20863342285156, 62.952781677246094, 62.94834518432617, 61.500267028808594, 59.04112243652344, 53.268882751464844, 51.87022399902344, 51.67988204956055, 48.372188568115234, 46.8980827331543, 44.348995208740234, 42.88208770751953, 41.452457427978516, 40.46464920043945, 40.330013275146484, 40.31122970581055, 93.49222564697266, 93.60568237304688, 72.13188171386719, 90.17559814453125, 64.54222869873047, 50.621482849121094, 224.57359313964844, 199.77716064453125, 166.89659118652344, 164.7269287109375, 148.24606323242188, 142.2269287109375, 131.3398895263672, 124.33267974853516, 116.63664245605469, 110.63710021972656, 102.72850799560547, 98.25521850585938, 95.14767456054688, 91.27979278564453, 90.2056884765625, 89.44171142578125, 88.24725341796875, 80.8594741821289, 80.81100463867188, 76.22441864013672, 75.43667602539062, 74.30892944335938, 73.49993133544922, 71.47419738769531, 70.70604705810547, 70.12562561035156, 65.6899642944336, 64.19977569580078, 63.425724029541016, 57.6064338684082, 393.1826477050781, 220.94317626953125, 224.6131591796875, 82.75715637207031, 131.04049682617188, 91.33202362060547, 156.52853393554688, 78.11151885986328, 90.38005065917969, 80.10084533691406, 100.78729248046875, 239.04782104492188, 232.34616088867188, 177.64990234375, 176.35296630859375, 157.2753448486328, 156.19500732421875, 153.62368774414062, 149.04327392578125, 119.56314086914062, 117.7018814086914, 116.71882629394531, 101.07789611816406, 97.10579681396484, 91.7817153930664, 91.08460998535156, 88.21898651123047, 79.6438980102539, 76.88251495361328, 72.09906768798828, 71.24934387207031, 67.62996673583984, 65.68084716796875, 64.52043914794922, 64.1584701538086, 59.74018859863281, 57.5831413269043, 56.11487579345703, 55.29057693481445, 54.65956497192383, 54.14781951904297, 91.97396850585938, 176.73886108398438, 98.93994140625, 127.0685043334961, 109.54441833496094, 61.250057220458984, 63.790977478027344, 417.9551086425781, 189.28445434570312, 134.18576049804688, 118.48800659179688, 94.36030578613281, 91.66985321044922, 81.08580017089844, 78.74037170410156, 78.73087310791016, 73.76117706298828, 72.38792419433594, 67.78044891357422, 66.7529296875, 65.24242401123047, 64.85650634765625, 64.20941162109375, 61.813072204589844, 61.08548355102539, 60.09410095214844, 59.809600830078125, 57.96480941772461, 53.76655578613281, 53.38140106201172, 52.76839828491211, 51.38275146484375, 50.972801208496094, 48.219635009765625, 44.35092544555664, 42.73324966430664, 41.91526794433594, 158.15403747558594, 143.02772521972656, 74.56206512451172, 53.059974670410156, 2552.545166015625, 191.69546508789062, 166.3282012939453, 157.3082275390625, 90.53919219970703, 84.81053161621094, 69.54185485839844, 41.25187683105469, 40.07649612426758, 39.54267883300781, 36.341793060302734, 35.53913879394531, 35.4538688659668, 30.581623077392578, 29.781641006469727, 29.728168487548828, 29.296716690063477, 29.226301193237305, 28.653419494628906, 25.965158462524414, 24.251934051513672, 23.681852340698242, 23.135005950927734, 20.57554817199707, 20.56787872314453, 20.422311782836914, 20.32477378845215, 20.124588012695312, 19.828195571899414, 18.8529052734375, 19.96290397644043, 44.965030670166016, 32.02949905395508, 35.4686164855957, 26.978641510009766, 26.408401489257812, 22.4567813873291, 21.618576049804688, 512.1461181640625, 177.615966796875, 168.3829345703125, 157.1393585205078, 146.60354614257812, 139.1156768798828, 119.0647964477539, 118.24862670898438, 113.37437438964844, 90.95805358886719, 79.42925262451172, 74.54830169677734, 73.58528137207031, 72.72382354736328, 71.84794616699219, 62.988224029541016, 50.06193161010742, 48.121009826660156, 44.395565032958984, 42.96999740600586, 42.86124038696289, 42.716094970703125, 41.161800384521484, 40.38492202758789, 39.306419372558594, 33.611419677734375, 33.24931716918945, 32.45389175415039, 31.958633422851562, 29.988330841064453, 91.40974426269531, 54.95293426513672, 53.094505310058594, 36.0942497253418, 285.4964294433594, 224.19598388671875, 138.58499145507812, 99.85003662109375, 81.6787109375, 78.83020782470703, 76.55359649658203, 76.26753997802734, 75.60774993896484, 63.34321212768555, 61.42724609375, 59.22310256958008, 57.49203872680664, 52.762699127197266, 49.80009841918945, 49.09115219116211, 47.090370178222656, 46.1714973449707, 45.352901458740234, 44.48994445800781, 42.278594970703125, 40.85783004760742, 38.15782928466797, 37.96942138671875, 35.726158142089844, 35.02783966064453, 34.51028060913086, 32.74398422241211, 32.55031204223633, 32.42048263549805, 66.44404602050781, 55.67962646484375, 67.92572021484375, 301.5308837890625, 295.5118408203125, 218.8501739501953, 209.06085205078125, 148.4801788330078, 137.40052795410156, 124.54094696044922, 118.35041809082031, 89.85917663574219, 85.17950439453125, 82.49545288085938, 75.36866760253906, 50.31692886352539, 49.2612190246582, 42.78409194946289, 42.23814010620117, 41.27571105957031, 38.80267333984375, 37.90092468261719, 34.380924224853516, 33.251312255859375, 33.10616683959961, 32.02927017211914, 29.044301986694336, 27.686161041259766, 26.071138381958008, 25.191862106323242, 24.592411041259766, 23.916568756103516, 23.91312026977539, 182.9324951171875, 175.97976684570312, 149.09793090820312, 119.7790756225586, 115.61278533935547, 78.08793640136719, 76.96709442138672, 75.47441101074219, 66.95831298828125, 64.05142211914062, 63.24052810668945, 62.48289489746094, 61.64325714111328, 58.413856506347656, 53.257877349853516, 48.51412582397461, 48.050743103027344, 44.612464904785156, 44.284427642822266, 43.77785873413086, 43.704586029052734, 43.06782150268555, 42.08162307739258, 41.056671142578125, 38.906707763671875, 36.82688903808594, 34.95753860473633, 34.44156265258789, 34.394893646240234, 32.31396484375, 64.43964385986328, 41.802120208740234, 35.03323745727539, 223.78016662597656, 138.91464233398438, 66.14146423339844, 63.737953186035156, 63.16863250732422, 61.20370864868164, 59.5205078125, 59.0920295715332, 50.2137336730957, 49.116737365722656, 46.9686164855957, 45.3751220703125, 43.82134246826172, 41.87800216674805, 41.78824996948242, 40.621498107910156, 40.5513801574707, 39.39980697631836, 37.23013687133789, 36.78758239746094, 35.60262680053711, 32.788230895996094, 31.14459228515625, 29.291610717773438, 27.403301239013672, 26.39598274230957, 83.20828247070312, 26.130998611450195, 25.70562171936035, 25.2896785736084, 295.3044738769531, 39.567134857177734, 136.42079162597656, 101.06683349609375, 87.21573638916016, 66.9570083618164, 65.21475982666016, 63.560943603515625, 52.001953125, 44.001976013183594, 40.8621826171875, 35.65544128417969, 34.53134536743164, 33.51125717163086, 33.062103271484375, 31.868408203125, 29.43752098083496, 29.07379722595215, 27.98994255065918, 27.430681228637695, 26.0594425201416, 20.86505699157715, 20.82803726196289, 20.69119644165039, 20.55901527404785, 19.32239532470703, 18.148422241210938, 16.35805320739746, 16.317968368530273, 16.28056526184082, 16.092811584472656, 16.061416625976562, 17.74532127380371, 17.13081932067871], \"Total\": [2553.0, 4416.0, 2021.0, 1565.0, 1367.0, 3228.0, 2450.0, 2448.0, 857.0, 872.0, 992.0, 961.0, 1108.0, 1046.0, 513.0, 619.0, 656.0, 604.0, 865.0, 975.0, 515.0, 833.0, 444.0, 418.0, 1042.0, 444.0, 605.0, 502.0, 426.0, 500.0, 4416.7109375, 1108.0726318359375, 865.3701782226562, 833.7913818359375, 640.2568969726562, 637.5303955078125, 425.13818359375, 386.1359558105469, 367.2892150878906, 348.7099304199219, 251.92529296875, 251.07989501953125, 246.54547119140625, 232.0511016845703, 226.86260986328125, 200.14537048339844, 199.9036865234375, 197.70562744140625, 197.64752197265625, 189.885986328125, 185.19406127929688, 176.89671325683594, 165.44004821777344, 158.69122314453125, 155.7709503173828, 153.69815063476562, 151.37120056152344, 147.370361328125, 146.02444458007812, 132.59146118164062, 278.5540771484375, 367.1755676269531, 582.9571533203125, 478.87005615234375, 229.45213317871094, 2448.01806640625, 1042.1766357421875, 2450.564453125, 896.6773071289062, 712.35400390625, 811.83447265625, 428.0122375488281, 287.1612548828125, 3228.421875, 535.4088745117188, 435.7903747558594, 592.5103149414062, 449.9576721191406, 436.40325927734375, 464.80755615234375, 371.4373779296875, 961.4168090820312, 605.5872802734375, 358.9147644042969, 292.4564514160156, 289.0396728515625, 246.66363525390625, 235.55526733398438, 224.14703369140625, 222.56239318847656, 202.1820526123047, 197.03341674804688, 181.0282745361328, 180.13938903808594, 177.97329711914062, 176.09616088867188, 154.0833740234375, 154.04507446289062, 154.0039825439453, 151.81236267089844, 144.80377197265625, 141.01182556152344, 442.6221618652344, 597.9212646484375, 130.16546630859375, 126.86038970947266, 126.07459259033203, 121.74539184570312, 121.61617279052734, 118.2247543334961, 116.6473617553711, 557.5160522460938, 1046.23876953125, 456.0054931640625, 304.84063720703125, 697.15087890625, 426.6642761230469, 624.3432006835938, 975.0608520507812, 345.62274169921875, 807.2739868164062, 510.0215759277344, 508.3232727050781, 497.5403137207031, 658.167236328125, 789.1436767578125, 430.8568115234375, 320.25006103515625, 403.019287109375, 648.1683959960938, 513.8399658203125, 460.3914489746094, 446.1319274902344, 242.13275146484375, 207.80056762695312, 199.46238708496094, 198.15635681152344, 173.51348876953125, 170.8183135986328, 161.53237915039062, 157.06356811523438, 154.37232971191406, 146.06004333496094, 141.3665313720703, 139.0048828125, 133.7526092529297, 130.0968780517578, 129.59388732910156, 124.06190490722656, 117.81856536865234, 113.95533752441406, 112.65308380126953, 111.15978240966797, 106.76155090332031, 105.20752716064453, 100.85466766357422, 100.23839569091797, 94.35010528564453, 90.07019805908203, 87.84822082519531, 253.16551208496094, 184.56922912597656, 195.650390625, 570.2115478515625, 309.256591796875, 508.7898864746094, 346.7897033691406, 3228.421875, 408.8169250488281, 235.00120544433594, 351.8883056640625, 497.5403137207031, 648.1683959960938, 228.43067932128906, 2450.564453125, 203.96824645996094, 658.167236328125, 2448.01806640625, 604.7675170898438, 500.42999267578125, 457.0739440917969, 443.27423095703125, 330.20330810546875, 269.658935546875, 266.87841796875, 260.8741455078125, 243.19264221191406, 211.2811737060547, 191.94866943359375, 167.1668701171875, 160.9427032470703, 149.8852081298828, 146.09178161621094, 144.815673828125, 137.14529418945312, 135.65040588378906, 129.2071075439453, 115.73565673828125, 114.01296997070312, 112.23836517333984, 107.43281555175781, 103.79241943359375, 102.27706909179688, 97.90534973144531, 94.24214172363281, 91.5498275756836, 87.80181121826172, 87.33173370361328, 390.36846923828125, 243.44256591796875, 992.1792602539062, 328.8097229003906, 631.7398071289062, 261.9789123535156, 211.40321350097656, 354.0899353027344, 408.8169250488281, 789.1436767578125, 296.2544250488281, 240.8323516845703, 2021.212890625, 872.2827758789062, 221.1580047607422, 219.45541381835938, 219.21434020996094, 202.14710998535156, 198.6844482421875, 168.78248596191406, 138.47265625, 137.71388244628906, 137.3146514892578, 133.41348266601562, 132.99366760253906, 123.906982421875, 119.55644226074219, 115.62215423583984, 117.64923858642578, 108.26213836669922, 104.4064712524414, 104.30892944335938, 97.9466781616211, 95.21927642822266, 88.4265365600586, 87.45502471923828, 86.42683410644531, 84.95030975341797, 81.6746597290039, 80.08049774169922, 78.03858184814453, 77.29737854003906, 97.64120483398438, 162.84100341796875, 213.04998779296875, 177.1939697265625, 3228.421875, 328.506591796875, 320.1271667480469, 112.81835174560547, 515.03125, 442.33636474609375, 245.05258178710938, 233.5848846435547, 230.7053680419922, 202.92886352539062, 201.0752410888672, 184.32559204101562, 164.13983154296875, 158.3895721435547, 155.54037475585938, 152.4391326904297, 148.15655517578125, 139.78878784179688, 121.29815673828125, 118.66510772705078, 99.13307189941406, 97.11638641357422, 96.42232513427734, 92.44194793701172, 91.0639877319336, 83.28665924072266, 83.04454040527344, 82.04679107666016, 80.14016723632812, 75.5724105834961, 73.71795654296875, 73.67082214355469, 73.33765411376953, 71.78663635253906, 187.36065673828125, 145.86219787597656, 3228.421875, 240.8323516845703, 648.1683959960938, 857.0145874023438, 619.27294921875, 389.2155456542969, 265.5692443847656, 245.6341094970703, 208.2660369873047, 184.21604919433594, 130.1421356201172, 118.57746887207031, 108.8100814819336, 102.39710235595703, 98.18915557861328, 87.58525085449219, 75.02499389648438, 73.90536499023438, 72.69416809082031, 72.43060302734375, 70.77627563476562, 70.44851684570312, 70.09036254882812, 69.6246566772461, 68.71377563476562, 68.38461303710938, 67.07477569580078, 65.60070037841797, 60.869361877441406, 59.7915153503418, 59.67258834838867, 57.96675109863281, 56.64192199707031, 277.25836181640625, 656.80615234375, 475.423095703125, 239.28158569335938, 120.67544555664062, 361.6419677734375, 431.3305358886719, 624.3432006835938, 271.81256103515625, 152.492431640625, 304.8338623046875, 250.76072692871094, 1565.2958984375, 444.7314758300781, 226.10853576660156, 211.40252685546875, 211.16429138183594, 210.2272186279297, 142.7476348876953, 131.89064025878906, 127.6865234375, 114.62255096435547, 106.32876586914062, 102.60871887207031, 101.24634552001953, 93.81995391845703, 93.0512924194336, 90.99172973632812, 87.7810287475586, 85.80396270751953, 83.09077453613281, 79.90966796875, 73.96852111816406, 71.78895568847656, 71.40705108642578, 70.84566497802734, 68.79800415039062, 68.4032974243164, 66.12154388427734, 64.74601745605469, 60.4222412109375, 57.71570587158203, 116.9876937866211, 438.6571350097656, 150.77650451660156, 475.423095703125, 135.62612915039062, 261.9789123535156, 502.4183044433594, 631.7398071289062, 265.4578552246094, 228.84751892089844, 346.7897033691406, 1367.0029296875, 426.0690612792969, 226.44854736328125, 190.01156616210938, 154.60586547851562, 141.411865234375, 137.88865661621094, 127.04942321777344, 113.0516357421875, 96.00494384765625, 95.25250244140625, 89.24571990966797, 87.0254898071289, 86.223876953125, 85.05288696289062, 82.08259582519531, 79.29756927490234, 77.10202026367188, 72.43199920654297, 67.53519439697266, 67.32312774658203, 65.99344635009766, 65.83280181884766, 64.32141876220703, 62.39957046508789, 62.36001205444336, 62.174827575683594, 61.82433319091797, 59.24522018432617, 59.20518493652344, 118.80614471435547, 290.68939208984375, 132.19235229492188, 265.4578552246094, 150.12693786621094, 104.31282806396484, 592.5103149414062, 233.61363220214844, 176.41424560546875, 161.5628662109375, 149.7860107421875, 142.48098754882812, 106.69093322753906, 97.39195251464844, 93.92900848388672, 87.55525207519531, 77.85617065429688, 75.43042755126953, 70.82135772705078, 69.87509155273438, 68.01528930664062, 66.07320404052734, 63.817359924316406, 63.812923431396484, 62.36484146118164, 59.905696868896484, 54.13345718383789, 52.734798431396484, 52.544456481933594, 49.23676681518555, 47.76266098022461, 45.21357345581055, 43.74666213989258, 42.31703567504883, 41.3292236328125, 41.19458770751953, 41.175804138183594, 112.65620422363281, 113.25765228271484, 86.81330108642578, 124.52152252197266, 83.27084350585938, 66.06982421875, 225.49574279785156, 200.69931030273438, 167.81874084472656, 165.64907836914062, 149.168212890625, 143.14907836914062, 132.2620391845703, 125.25480651855469, 117.55876922607422, 111.5592269897461, 103.650634765625, 99.1773452758789, 96.0698013305664, 92.20191955566406, 91.12781524658203, 90.36383819580078, 89.16938018798828, 81.78160095214844, 81.7331314086914, 77.14654541015625, 76.35880279541016, 75.2310562133789, 74.42205810546875, 72.39632415771484, 71.628173828125, 71.0477523803711, 66.61209106445312, 65.12190246582031, 64.34785461425781, 58.528564453125, 502.4183044433594, 274.9172058105469, 304.8338623046875, 91.36968994140625, 351.8883056640625, 152.74900817871094, 992.1792602539062, 100.87943267822266, 261.3364562988281, 121.06280517578125, 2450.564453125, 239.96742248535156, 233.26576232910156, 178.5695037841797, 177.27256774902344, 158.1949462890625, 157.11460876464844, 154.54345703125, 149.96287536621094, 120.48272705078125, 118.62146759033203, 117.63841247558594, 101.99748229980469, 98.02538299560547, 92.70130157470703, 92.00419616699219, 89.1385726928711, 80.56348419189453, 77.8021011352539, 73.0186538696289, 72.16893005371094, 68.54955291748047, 66.60043334960938, 65.44002532958984, 65.07805633544922, 60.65978240966797, 58.50273513793945, 57.03446960449219, 56.21017074584961, 55.579158782958984, 55.067413330078125, 101.4453353881836, 250.76072692871094, 129.95303344726562, 228.84751892089844, 184.05966186523438, 70.94786071777344, 120.3512954711914, 418.8595886230469, 190.1889190673828, 135.09022521972656, 119.39246368408203, 95.26476287841797, 92.57431030273438, 81.9902572631836, 79.64482879638672, 79.63533020019531, 74.66563415527344, 73.2923812866211, 68.68490600585938, 67.65738677978516, 66.14688110351562, 65.7609634399414, 65.1138687133789, 62.717529296875, 61.98994064331055, 60.998558044433594, 60.71405792236328, 58.869266510009766, 54.67101287841797, 54.285858154296875, 53.672855377197266, 52.287208557128906, 51.87725830078125, 49.12409210205078, 45.2553825378418, 43.6377067565918, 42.819725036621094, 190.95387268066406, 221.2635955810547, 144.90577697753906, 125.53683471679688, 2553.472900390625, 192.62301635742188, 167.25575256347656, 158.23577880859375, 91.46674346923828, 85.73808288574219, 70.46940612792969, 42.17942810058594, 41.00404739379883, 40.47023010253906, 37.269344329833984, 36.46669006347656, 36.38142013549805, 31.509174346923828, 30.709192276000977, 30.65572166442871, 30.224267959594727, 30.153852462768555, 29.58097267150879, 26.892709732055664, 25.179487228393555, 24.609405517578125, 24.062559127807617, 21.50309944152832, 21.495431900024414, 21.349863052368164, 21.252347946166992, 21.052141189575195, 20.755748748779297, 19.780460357666016, 20.972673416137695, 75.55787658691406, 89.15489959716797, 135.62612915039062, 68.32662963867188, 118.08259582519531, 87.85897827148438, 2450.564453125, 513.0654296875, 178.5353240966797, 169.3022918701172, 158.0587158203125, 147.5229034423828, 140.0350341796875, 119.98413848876953, 119.16796875, 114.29371643066406, 91.87739562988281, 80.34859466552734, 75.46764373779297, 74.50462341308594, 73.6431655883789, 72.76728820800781, 63.90756607055664, 50.98127365112305, 49.04035186767578, 45.31490707397461, 43.889339447021484, 43.78099822998047, 43.63543701171875, 42.08114242553711, 41.304264068603516, 40.22576141357422, 34.53076171875, 34.16865921020508, 33.373233795166016, 32.87797546386719, 30.907676696777344, 103.14437103271484, 89.15489959716797, 274.9172058105469, 60.84667205810547, 286.41949462890625, 225.1190643310547, 139.50807189941406, 100.77310180664062, 82.60177612304688, 79.7532730102539, 77.4766616821289, 77.19060516357422, 76.53081512451172, 64.26628112792969, 62.350318908691406, 60.146175384521484, 58.41511154174805, 53.68577194213867, 50.72317123413086, 50.014225006103516, 48.01344299316406, 47.09457015991211, 46.27597427368164, 45.41301727294922, 43.20166778564453, 41.78090286254883, 39.080902099609375, 38.892494201660156, 36.64923095703125, 35.95091247558594, 35.433353424072266, 33.667057037353516, 33.473384857177734, 33.34355545043945, 132.0018310546875, 120.3512954711914, 975.0608520507812, 302.44482421875, 296.42578125, 219.76409912109375, 209.9747772216797, 149.39410400390625, 138.314453125, 125.45487213134766, 119.26434326171875, 90.77310180664062, 86.09342956542969, 83.40937805175781, 76.2825927734375, 51.230857849121094, 50.175148010253906, 43.698020935058594, 43.152069091796875, 42.189640045166016, 39.71660232543945, 38.81485366821289, 35.29487991333008, 34.16524124145508, 34.02009582519531, 32.943199157714844, 29.958297729492188, 28.600088119506836, 26.985065460205078, 26.105789184570312, 25.506343841552734, 24.830495834350586, 24.82704734802246, 183.8414306640625, 176.88870239257812, 150.00686645507812, 120.68800354003906, 116.52171325683594, 78.99686431884766, 77.87602233886719, 76.38333892822266, 67.86724090576172, 64.9603500366211, 64.14945983886719, 63.391822814941406, 62.55218505859375, 59.32668685913086, 54.166805267333984, 49.42305374145508, 48.95967102050781, 45.521392822265625, 45.193355560302734, 44.68678665161133, 44.6135139465332, 43.976749420166016, 42.99055099487305, 41.965599060058594, 39.815635681152344, 37.735816955566406, 35.8664665222168, 35.350502014160156, 35.3038215637207, 33.22289276123047, 261.3364562988281, 90.89814758300781, 163.11399841308594, 224.68463134765625, 139.81910705566406, 67.04592895507812, 64.64241790771484, 64.0730972290039, 62.10817337036133, 60.42497253417969, 59.99649429321289, 51.11819839477539, 50.021202087402344, 47.87308120727539, 46.27958679199219, 44.725807189941406, 42.782466888427734, 42.69271469116211, 41.525962829589844, 41.45584487915039, 40.30427169799805, 38.13460159301758, 37.692047119140625, 36.5070915222168, 33.69269561767578, 32.04905700683594, 30.196075439453125, 28.30776596069336, 27.300447463989258, 86.08240509033203, 27.035463333129883, 26.61008644104004, 26.194143295288086, 444.0223388671875, 61.60763168334961, 137.33584594726562, 101.98189544677734, 88.13079833984375, 67.8720703125, 66.12982177734375, 64.47600555419922, 52.91701126098633, 44.91703414916992, 41.77724075317383, 36.570499420166016, 35.44640350341797, 34.42631530761719, 33.9771614074707, 32.78346633911133, 30.352581024169922, 29.98885726928711, 28.90500259399414, 28.345741271972656, 26.974502563476562, 21.78011703491211, 21.74309730529785, 21.60625648498535, 21.475866317749023, 20.237455368041992, 19.063528060913086, 17.273113250732422, 17.233028411865234, 17.19562530517578, 17.007871627807617, 16.976476669311523, 82.52981567382812, 75.55787658691406], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.577699899673462, -3.9611001014709473, -4.208600044250488, -4.245800018310547, -4.510300159454346, -4.514500141143799, -4.920499801635742, -5.016900062561035, -5.0671000480651855, -5.119100093841553, -5.445199966430664, -5.448599815368652, -5.466899871826172, -5.527699947357178, -5.5503997802734375, -5.676300048828125, -5.677499771118164, -5.688600063323975, -5.688899993896484, -5.7291998863220215, -5.754300117492676, -5.8003997802734375, -5.867700099945068, -5.909599781036377, -5.928299903869629, -5.941800117492676, -5.957099914550781, -5.984099864959717, -5.993299961090088, -6.090400218963623, -5.353600025177002, -5.086100101470947, -4.6331000328063965, -4.833700180053711, -5.556300163269043, -3.301800012588501, -4.120299816131592, -3.3210999965667725, -4.271999835968018, -4.497099876403809, -4.38539981842041, -5.048600196838379, -5.394800186157227, -3.5434000492095947, -4.940000057220459, -5.123499870300293, -5.009500026702881, -5.1915998458862305, -5.254899978637695, -5.261600017547607, -5.398600101470947, -3.6712000370025635, -4.133900165557861, -4.658100128173828, -4.863399982452393, -4.875199794769287, -5.034200191497803, -5.08050012588501, -5.130300045013428, -5.137400150299072, -5.23390007019043, -5.259799957275391, -5.344900131225586, -5.349899768829346, -5.361999988555908, -5.372700214385986, -5.506899833679199, -5.507199764251709, -5.507400035858154, -5.521900177001953, -5.569399833679199, -5.596099853515625, -4.452400207519531, -4.151800155639648, -5.676700115203857, -5.702600002288818, -5.708799839019775, -5.74399995803833, -5.745100021362305, -5.773600101470947, -5.787099838256836, -4.225100040435791, -3.6514999866485596, -4.471799850463867, -4.895999908447266, -4.139999866485596, -4.6331000328063965, -4.38670015335083, -4.026599884033203, -4.892099857330322, -4.2804999351501465, -4.727200031280518, -4.780900001525879, -4.819699764251709, -4.703400135040283, -4.621200084686279, -4.940000057220459, -5.081299781799316, -5.0584001541137695, -4.96750020980835, -3.993000030517578, -4.103000164031982, -4.134500026702881, -4.747399806976318, -4.900899887084961, -4.9421000480651855, -4.948699951171875, -5.082099914550781, -5.097899913787842, -5.154099941253662, -5.182300090789795, -5.199699878692627, -5.25540018081665, -5.288300037384033, -5.305200099945068, -5.343999862670898, -5.3719000816345215, -5.375800132751465, -5.4197998046875, -5.471799850463867, -5.50540018081665, -5.517000198364258, -5.530399799346924, -5.571100234985352, -5.585899829864502, -5.628600120544434, -5.634799957275391, -5.695899963378906, -5.742800235748291, -5.76800012588501, -4.711400032043457, -5.059199810028076, -5.012899875640869, -4.057000160217285, -4.749599933624268, -4.361400127410889, -4.809999942779541, -3.411600112915039, -4.753600120544434, -5.125699996948242, -4.976500034332275, -4.974999904632568, -4.899099826812744, -5.228000164031982, -4.894700050354004, -5.287799835205078, -5.245100021362305, -5.209099769592285, -3.7390999794006348, -3.9289000034332275, -4.019599914550781, -4.050300121307373, -4.3454999923706055, -4.548699855804443, -4.559100151062012, -4.581900119781494, -4.652400016784668, -4.793600082397461, -4.889999866485596, -5.0289998054504395, -5.0671000480651855, -5.138700008392334, -5.1645002365112305, -5.173399925231934, -5.228099822998047, -5.239200115203857, -5.2881999015808105, -5.399099826812744, -5.4141998291015625, -5.430099964141846, -5.4741997718811035, -5.508999824523926, -5.523799896240234, -5.56790018081665, -5.606400012969971, -5.635700225830078, -5.6778998374938965, -5.683300018310547, -4.195199966430664, -4.721799850463867, -3.415299892425537, -4.486700057983398, -4.581699848175049, -5.076300144195557, -5.216599941253662, -5.022600173950195, -5.017199993133545, -4.896599769592285, -5.208700180053711, -5.264500141143799, -2.3701999187469482, -3.211199998855591, -4.586400032043457, -4.594200134277344, -4.595300197601318, -4.676700115203857, -4.6940999031066895, -4.857999801635742, -5.05709981918335, -5.062600135803223, -5.0655999183654785, -5.094600200653076, -5.097700119018555, -5.169000148773193, -5.204999923706055, -5.238699913024902, -5.221399784088135, -5.304999828338623, -5.341599941253662, -5.342599868774414, -5.406099796295166, -5.434599876403809, -5.509300231933594, -5.520500183105469, -5.532400131225586, -5.549799919128418, -5.589600086212158, -5.609499931335449, -5.635700225830078, -5.645299911499023, -5.427999973297119, -4.973199844360352, -4.823200225830078, -5.019899845123291, -4.359399795532227, -5.173999786376953, -5.238399982452393, -5.482600212097168, -3.6052000522613525, -3.757699966430664, -4.349999904632568, -4.398099899291992, -4.4105000495910645, -4.539400100708008, -4.548600196838379, -4.636000156402588, -4.752600193023682, -4.78849983215332, -4.806700229644775, -4.827000141143799, -4.8557000160217285, -4.9141998291015625, -5.05709981918335, -5.07919979095459, -5.2606000900268555, -5.281300067901611, -5.288599967956543, -5.331200122833252, -5.34630012512207, -5.436600208282471, -5.439499855041504, -5.451700210571289, -5.475500106811523, -5.534900188446045, -5.560100078582764, -5.560699939727783, -5.565299987792969, -5.586999893188477, -4.902900218963623, -5.169400215148926, -4.024199962615967, -5.160099983215332, -5.335899829864502, -3.094899892807007, -3.420300006866455, -3.885499954223633, -4.268899917602539, -4.3471999168396, -4.512899875640869, -4.636199951171875, -4.9857001304626465, -5.079500198364258, -5.166100025177002, -5.227399826049805, -5.269800186157227, -5.385200023651123, -5.5416998863220215, -5.557000160217285, -5.573699951171875, -5.577400207519531, -5.600800037384033, -5.605500221252441, -5.610599994659424, -5.617400169372559, -5.63070011138916, -5.6356000900268555, -5.655200004577637, -5.677700042724609, -5.753699779510498, -5.7718000411987305, -5.773799896240234, -5.803299903869629, -5.8267998695373535, -4.255899906158447, -3.4374001026153564, -4.295100212097168, -5.053800106048584, -5.418499946594238, -5.065899848937988, -5.012700080871582, -4.959499835968018, -5.431099891662598, -5.533400058746338, -5.473499774932861, -5.554800033569336, -2.387399911880493, -3.6473000049591064, -4.325699806213379, -4.3933000564575195, -4.394400119781494, -4.398900032043457, -4.788099765777588, -4.867700099945068, -4.900300025939941, -5.009099960327148, -5.084799766540527, -5.120800018310547, -5.134300231933594, -5.21120023727417, -5.2195000648498535, -5.242099761962891, -5.27839994430542, -5.301400184631348, -5.333899974822998, -5.3734002113342285, -5.451600074768066, -5.481900215148926, -5.487299919128418, -5.495299816131592, -5.525000095367432, -5.530799865722656, -5.565199851989746, -5.58650016784668, -5.656700134277344, -5.703199863433838, -5.029600143432617, -3.857300043106079, -5.03000020980835, -4.363999843597412, -5.144800186157227, -5.112400054931641, -5.057300090789795, -5.011499881744385, -5.276199817657471, -5.299499988555908, -5.284599781036377, -2.454699993133545, -3.621999979019165, -4.25600004196167, -4.432199954986572, -4.639599800109863, -4.729300022125244, -4.754700183868408, -4.837200164794922, -4.954800128936768, -5.119800090789795, -5.127699851989746, -5.19350004196167, -5.218999862670898, -5.228300094604492, -5.242199897766113, -5.27810001373291, -5.313000202178955, -5.341400146484375, -5.404699802398682, -5.4756999015808105, -5.478799819946289, -5.499100208282471, -5.501500129699707, -5.525100231170654, -5.5559000968933105, -5.55649995803833, -5.559599876403809, -5.565299987792969, -5.60860013961792, -5.609300136566162, -4.985300064086914, -4.3684000968933105, -4.990699768066406, -4.4953999519348145, -4.955100059509277, -5.2052001953125, -4.358500003814697, -4.185200214385986, -4.467199802398682, -4.555600166320801, -4.631700038909912, -4.682000160217285, -4.973299980163574, -5.065299987792969, -5.101799964904785, -5.172800064086914, -5.291399955749512, -5.323400020599365, -5.387199878692627, -5.400899887084961, -5.428199768066406, -5.457499980926514, -5.492700099945068, -5.492800235748291, -5.51609992980957, -5.5569000244140625, -5.659800052642822, -5.686399936676025, -5.690100193023682, -5.756199836730957, -5.787099838256836, -5.8429999351501465, -5.876699924468994, -5.910600185394287, -5.934700012207031, -5.938000202178955, -5.938499927520752, -5.0971999168396, -5.0960001945495605, -5.356599807739258, -5.133399963378906, -5.467800140380859, -5.710700035095215, -4.21150016784668, -4.328499794006348, -4.508299827575684, -4.521399974822998, -4.626800060272217, -4.668300151824951, -4.747900009155273, -4.802700042724609, -4.866600036621094, -4.919400215148926, -4.993599891662598, -5.038099765777588, -5.070300102233887, -5.111800193786621, -5.123600006103516, -5.1321001052856445, -5.145500183105469, -5.232999801635742, -5.23360013961792, -5.291999816894531, -5.3024001121521, -5.317500114440918, -5.328400135040283, -5.356400012969971, -5.367199897766113, -5.375400066375732, -5.440700054168701, -5.463699817657471, -5.475800037384033, -5.5721001625061035, -3.651400089263916, -4.227799892425537, -4.211299896240234, -5.209799766540527, -4.750199794769287, -5.111199855804443, -4.572500228881836, -5.267600059509277, -5.121699810028076, -5.242400169372559, -5.012700080871582, -4.043900012969971, -4.072299957275391, -4.340700149536133, -4.3480000495910645, -4.462500095367432, -4.469399929046631, -4.486000061035156, -4.516300201416016, -4.736700057983398, -4.752399921417236, -4.760700225830078, -4.904600143432617, -4.944699764251709, -5.001100063323975, -5.008699893951416, -5.0406999588012695, -5.142899990081787, -5.178199768066406, -5.242499828338623, -5.254300117492676, -5.30649995803833, -5.335700035095215, -5.353499889373779, -5.3592000007629395, -5.430500030517578, -5.467299938201904, -5.493100166320801, -5.507900238037109, -5.519400119781494, -5.528800010681152, -4.999000072479248, -4.345799922943115, -4.926000118255615, -4.67579984664917, -4.82420015335083, -5.4054999351501465, -5.3649001121521, -3.2688000202178955, -4.0609002113342285, -4.404900074005127, -4.529300212860107, -4.756999969482422, -4.785999774932861, -4.908599853515625, -4.938000202178955, -4.9380998611450195, -5.003300189971924, -5.02209997177124, -5.087900161743164, -5.1031999588012695, -5.125999927520752, -5.131999969482422, -5.142000198364258, -5.179999828338623, -5.19189977645874, -5.208199977874756, -5.2129998207092285, -5.24429988861084, -5.319499969482422, -5.326700210571289, -5.338200092315674, -5.364799976348877, -5.372900009155273, -5.428400039672852, -5.51200008392334, -5.549200057983398, -5.56850004196167, -4.240600109100342, -4.341100215911865, -4.992499828338623, -5.332699775695801, -1.3389999866485596, -3.927999973297119, -4.069900035858154, -4.125699996948242, -4.678100109100342, -4.743500232696533, -4.941999912261963, -5.464200019836426, -5.493100166320801, -5.506499767303467, -5.59089994430542, -5.6132001876831055, -5.615600109100342, -5.763500213623047, -5.789999961853027, -5.791800022125244, -5.806399822235107, -5.808800220489502, -5.82859992980957, -5.92710018157959, -5.9953999519348145, -6.019199848175049, -6.042500019073486, -6.159800052642822, -6.160200119018555, -6.167300224304199, -6.171999931335449, -6.1819000244140625, -6.196800231933594, -6.247200012207031, -6.190000057220459, -5.377999782562256, -5.717199802398682, -5.615200042724609, -5.888800144195557, -5.910200119018555, -6.072299957275391, -6.110300064086914, -2.944000005722046, -4.002900123596191, -4.056300163269043, -4.125400066375732, -4.194799900054932, -4.247300148010254, -4.402900218963623, -4.409800052642822, -4.451900005340576, -4.6722002029418945, -4.807700157165527, -4.871099948883057, -4.884099960327148, -4.895899772644043, -4.9079999923706055, -5.039599895477295, -5.2692999839782715, -5.308899879455566, -5.389400005340576, -5.422100067138672, -5.424600124359131, -5.427999973297119, -5.465099811553955, -5.484099864959717, -5.511199951171875, -5.667699813842773, -5.678500175476074, -5.7027997970581055, -5.718100070953369, -5.781799793243408, -4.667200088500977, -5.17609977722168, -5.2104997634887695, -5.596399784088135, -3.466099977493286, -3.7077999114990234, -4.188899993896484, -4.51669979095459, -4.717599868774414, -4.7530999183654785, -4.782400131225586, -4.786099910736084, -4.7947998046875, -4.971799850463867, -5.002500057220459, -5.039100170135498, -5.068699836730957, -5.154600143432617, -5.212299823760986, -5.2266998291015625, -5.2683000564575195, -5.288000106811523, -5.3059000968933105, -5.325099945068359, -5.376100063323975, -5.410299777984619, -5.478600025177002, -5.48360013961792, -5.54449987411499, -5.564199924468994, -5.579100131988525, -5.6315999031066895, -5.637599945068359, -5.641600131988525, -4.923999786376953, -5.1006999015808105, -4.901899814605713, -3.40910005569458, -3.4291999340057373, -3.7295000553131104, -3.7753000259399414, -4.117499828338623, -4.195000171661377, -4.293300151824951, -4.344299793243408, -4.619699954986572, -4.6732001304626465, -4.7052001953125, -4.795499801635742, -5.1996002197265625, -5.220799922943115, -5.361800193786621, -5.374599933624268, -5.397600173950195, -5.459400177001953, -5.482900142669678, -5.580399990081787, -5.613800048828125, -5.618199825286865, -5.651299953460693, -5.749100208282471, -5.796999931335449, -5.857100009918213, -5.89139986038208, -5.915500164031982, -5.943399906158447, -5.94350004196167, -3.842400074005127, -3.881200075149536, -4.046899795532227, -4.265900135040283, -4.301300048828125, -4.693699836730957, -4.708199977874756, -4.727799892425537, -4.847499847412109, -4.891900062561035, -4.904600143432617, -4.9166998863220215, -4.930200099945068, -4.984000205993652, -5.076399803161621, -5.1697001457214355, -5.179299831390381, -5.253499984741211, -5.260900020599365, -5.27239990234375, -5.274099826812744, -5.28879976272583, -5.3119001388549805, -5.336599826812744, -5.390399932861328, -5.445300102233887, -5.497399806976318, -5.51230001449585, -5.513599872589111, -5.576099872589111, -4.885799884796143, -5.318600177764893, -5.495299816131592, -3.5710999965667725, -4.047900199890137, -4.789999961853027, -4.827000141143799, -4.835899829864502, -4.867499828338623, -4.895400047302246, -4.902699947357178, -5.065499782562256, -5.087600231170654, -5.132299900054932, -5.166800022125244, -5.201600074768066, -5.247000217437744, -5.249100208282471, -5.277500152587891, -5.279200077056885, -5.308000087738037, -5.36460018157959, -5.3765997886657715, -5.409299850463867, -5.491700172424316, -5.543099880218506, -5.604499816894531, -5.67110013961792, -5.708499908447266, -4.560400009155273, -5.718599796295166, -5.735000133514404, -5.751399993896484, -3.2936999797821045, -5.303800106048584, -3.809799909591675, -4.109799861907959, -4.257199764251709, -4.521500110626221, -4.547900199890137, -4.573599815368652, -4.7743000984191895, -4.941299915313721, -5.015399932861328, -5.151700019836426, -5.183700084686279, -5.213699817657471, -5.227200031280518, -5.263999938964844, -5.343299865722656, -5.3557000160217285, -5.393700122833252, -5.413899898529053, -5.465199947357178, -5.6875, -5.689300060272217, -5.695899963378906, -5.702300071716309, -5.7642998695373535, -5.827000141143799, -5.9309000968933105, -5.933300018310547, -5.9355998039245605, -5.947199821472168, -5.94920015335083, -5.8495001792907715, -5.884699821472168], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.8142999410629272, 1.8136999607086182, 1.8135000467300415, 1.8134000301361084, 1.813099980354309, 1.813099980354309, 1.8122999668121338, 1.8121000528335571, 1.812000036239624, 1.811900019645691, 1.8107999563217163, 1.8107999563217163, 1.8107999563217163, 1.8105000257492065, 1.8104000091552734, 1.8099000453948975, 1.8099000453948975, 1.8098000288009644, 1.8098000288009644, 1.8095999956130981, 1.809499979019165, 1.8092999458312988, 1.808899998664856, 1.8086999654769897, 1.808500051498413, 1.808500051498413, 1.80840003490448, 1.8082000017166138, 1.8080999851226807, 1.8075000047683716, 1.8020000457763672, 1.7933000326156616, 1.784000039100647, 1.7800999879837036, 1.7933000326156616, 1.680400013923645, 1.7158000469207764, 1.660099983215332, 1.7145999670028687, 1.719499945640564, 1.7005000114440918, 1.67739999294281, 1.7303999662399292, 1.1620999574661255, 1.5621999502182007, 1.5845999717712402, 1.3913999795913696, 1.4845000505447388, 1.451799988746643, 1.3819999694824219, 1.4692000150680542, 2.2455999851226807, 2.2451000213623047, 2.2441000938415527, 2.243499994277954, 2.243499994277954, 2.243000030517578, 2.242799997329712, 2.2425999641418457, 2.2425999641418457, 2.2421998977661133, 2.242000102996826, 2.2416000366210938, 2.2416000366210938, 2.2416000366210938, 2.241499900817871, 2.240799903869629, 2.240799903869629, 2.240799903869629, 2.2407000064849854, 2.2404000759124756, 2.240299940109253, 2.2400999069213867, 2.240000009536743, 2.2397000789642334, 2.239500045776367, 2.239500045776367, 2.239300012588501, 2.2392001152038574, 2.239000082015991, 2.2388999462127686, 2.2367000579833984, 2.180799961090088, 2.1909000873565674, 2.1693999767303467, 2.0982000827789307, 2.096100091934204, 1.961899995803833, 1.876099944114685, 2.047800064086914, 1.8109999895095825, 1.8236000537872314, 1.7732000350952148, 1.7558000087738037, 1.5923000574111938, 1.4931000471115112, 1.7793999910354614, 1.9348000288009644, 1.7279000282287598, 1.3436000347137451, 2.550299882888794, 2.550100088119507, 2.550100088119507, 2.54830002784729, 2.5476999282836914, 2.547499895095825, 2.547499895095825, 2.546799898147583, 2.5467000007629395, 2.5464000701904297, 2.5462000370025635, 2.546099901199341, 2.545799970626831, 2.545599937438965, 2.5455000400543213, 2.5452001094818115, 2.5450000762939453, 2.5450000762939453, 2.5446999073028564, 2.544300079345703, 2.5439999103546143, 2.5439000129699707, 2.543800115585327, 2.5434999465942383, 2.543299913406372, 2.5429999828338623, 2.5429000854492188, 2.54229998588562, 2.541800022125244, 2.541599988937378, 2.539799928665161, 2.507999897003174, 2.4958999156951904, 2.382200002670288, 2.3013999462127686, 2.191800117492676, 2.126499891281128, 1.2939000129699707, 2.0183000564575195, 2.199899911880493, 1.9453999996185303, 1.6004999876022339, 1.4119999408721924, 2.1259000301361084, 0.08640000224113464, 2.179500102996826, 1.0506000518798828, -0.22689999639987946, 2.6412999629974365, 2.6407999992370605, 2.6407999992370605, 2.640700101852417, 2.640000104904175, 2.639400005340576, 2.6393001079559326, 2.63919997215271, 2.6389999389648438, 2.638400077819824, 2.638000011444092, 2.6373000144958496, 2.63700008392334, 2.6366000175476074, 2.6364998817443848, 2.636399984359741, 2.635999917984009, 2.635999917984009, 2.6356000900268555, 2.6347999572753906, 2.634700059890747, 2.634500026702881, 2.634200096130371, 2.6338999271392822, 2.633699893951416, 2.6333000659942627, 2.6328999996185303, 2.632699966430664, 2.632200002670288, 2.632200002670288, 2.622999906539917, 2.56850004196167, 2.4700000286102295, 2.5030999183654785, 1.7551000118255615, 2.1405999660491943, 2.214900016784668, 1.8931000232696533, 1.7547999620437622, 1.2175999879837036, 1.8853000402450562, 2.036600112915039, 2.803499937057495, 2.8029000759124756, 2.7999000549316406, 2.7999000549316406, 2.799799919128418, 2.799499988555908, 2.7994000911712646, 2.7985999584198, 2.7973999977111816, 2.7973999977111816, 2.7973999977111816, 2.7971999645233154, 2.7971999645233154, 2.7967000007629395, 2.7964000701904297, 2.796099901199341, 2.796099901199341, 2.795599937438965, 2.795300006866455, 2.795300006866455, 2.7946999073028564, 2.7945001125335693, 2.7936999797821045, 2.793600082397461, 2.7934999465942383, 2.793299913406372, 2.7929000854492188, 2.7927000522613525, 2.7923998832702637, 2.7922000885009766, 2.775899887084961, 2.7191998958587646, 2.6005001068115234, 2.5880000591278076, 0.34599998593330383, 1.8166999816894531, 1.7781000137329102, 2.5768001079559326, 2.935800075531006, 2.935499906539917, 2.933799982070923, 2.9335999488830566, 2.933500051498413, 2.933000087738037, 2.9328999519348145, 2.932499885559082, 2.9319000244140625, 2.9316999912261963, 2.9316000938415527, 2.93149995803833, 2.931299924850464, 2.9309000968933105, 2.9298999309539795, 2.9296998977661133, 2.9282000064849854, 2.927999973297119, 2.9279000759124756, 2.927500009536743, 2.927299976348877, 2.9263999462127686, 2.926300048828125, 2.9261999130249023, 2.9258999824523926, 2.9251999855041504, 2.9249000549316406, 2.9249000549316406, 2.924799919128418, 2.9245998859405518, 2.649199962615967, 2.6331000328063965, 0.6812000274658203, 2.1410000324249268, 0.9751999974250793, 2.936800003051758, 2.9363999366760254, 2.935499906539917, 2.9344000816345215, 2.9342000484466553, 2.933500051498413, 2.9328999519348145, 2.9309000968933105, 2.9302000999450684, 2.929500102996826, 2.9289000034332275, 2.9286000728607178, 2.9274001121520996, 2.9256999492645264, 2.92549991607666, 2.925299882888794, 2.9251999855041504, 2.9249000549316406, 2.9249000549316406, 2.924799919128418, 2.9247000217437744, 2.924499988555908, 2.924499988555908, 2.9242000579833984, 2.9238998889923096, 2.922800064086914, 2.922499895095825, 2.922499895095825, 2.921999931335449, 2.9217000007629395, 2.904400110244751, 2.8603999614715576, 2.325900077819824, 2.2537999153137207, 2.5736000537872314, 1.8286999464035034, 1.7057000398635864, 1.3890000581741333, 1.7489999532699585, 2.2246999740600586, 1.5920000076293945, 1.705899953842163, 3.0420000553131104, 3.0404999256134033, 3.0385000705718994, 3.0381999015808105, 3.0381999015808105, 3.038100004196167, 3.036099910736084, 3.0355000495910645, 3.0353000164031982, 3.0344998836517334, 3.033799886703491, 3.0334999561309814, 3.033400058746338, 3.0327000617980957, 3.032599925994873, 3.032399892807007, 3.0320000648498535, 3.0316998958587646, 3.031399965286255, 3.030900001525879, 3.0299999713897705, 3.029599905014038, 3.0295000076293945, 3.029400110244751, 3.0290000438690186, 3.0290000438690186, 3.0285000801086426, 3.0281999111175537, 3.0271999835968018, 3.026400089263916, 2.993499994277954, 2.8441998958587646, 2.7393999099731445, 2.256999969482422, 2.7304999828338623, 2.104599952697754, 1.5084999799728394, 1.3252999782562256, 1.9276000261306763, 2.0525999069213867, 1.651900053024292, 3.110100030899048, 3.108599901199341, 3.1066999435424805, 3.1059000492095947, 3.10479998588562, 3.1041998863220215, 3.1040000915527344, 3.1033999919891357, 3.1024999618530273, 3.1010000705718994, 3.1010000705718994, 3.1003000736236572, 3.0999999046325684, 3.099900007247925, 3.0998001098632812, 3.099400043487549, 3.0989999771118164, 3.098599910736084, 3.097899913787842, 3.09689998626709, 3.09689998626709, 3.09660005569458, 3.0964999198913574, 3.0961999893188477, 3.0957999229431152, 3.0957000255584717, 3.0957000255584717, 3.095599889755249, 3.094899892807007, 3.094899892807007, 3.02239990234375, 2.7446000576019287, 2.9102001190185547, 2.708400011062622, 2.8185999393463135, 2.9326000213623047, 2.04229998588562, 3.146399974822998, 3.14520001411438, 3.144700050354004, 3.1442999839782715, 3.1440000534057617, 3.1419999599456787, 3.141200065612793, 3.1407999992370605, 3.140199899673462, 3.1389000415802, 3.1386001110076904, 3.1377999782562256, 3.1375999450683594, 3.1373000144958496, 3.136899948120117, 3.136399984359741, 3.136399984359741, 3.1361000537872314, 3.135499954223633, 3.134000062942505, 3.1335999965667725, 3.133500099182129, 3.1324000358581543, 3.1317999362945557, 3.1308000087738037, 3.1301000118255615, 3.1294000148773193, 3.1289000511169434, 3.1289000511169434, 3.1289000511169434, 2.963599920272827, 2.9595000743865967, 2.9647998809814453, 2.827399969100952, 2.8952999114990234, 2.8838000297546387, 3.155400037765503, 3.154900074005127, 3.1540000438690186, 3.153899908065796, 3.1533000469207764, 3.15310001373291, 3.1524999141693115, 3.152100086212158, 3.151599884033203, 3.15120005607605, 3.150599956512451, 3.1501998901367188, 3.149899959564209, 3.1494998931884766, 3.1493000984191895, 3.1493000984191895, 3.1491000652313232, 3.148200035095215, 3.148200035095215, 3.1475000381469727, 3.14739990234375, 3.147200107574463, 3.1470999717712402, 3.146699905395508, 3.1466000080108643, 3.1465001106262207, 3.1456000804901123, 3.1452999114990234, 3.1451001167297363, 3.1435999870300293, 2.914400100708008, 2.940999984741211, 2.854099988937378, 3.060499906539917, 2.1717000007629395, 2.64520001411438, 1.3128999471664429, 2.903700113296509, 2.0977001190185547, 2.746500015258789, -0.03150000050663948, 3.2609000205993652, 3.260699987411499, 3.259500026702881, 3.259500026702881, 3.2588999271392822, 3.2588000297546387, 3.258699893951416, 3.258500099182129, 3.256999969482422, 3.2569000720977783, 3.2567999362945557, 3.2555999755859375, 3.2553000450134277, 3.254699945449829, 3.254699945449829, 3.254300117492676, 3.253200054168701, 3.2527999877929688, 3.252000093460083, 3.2518999576568604, 3.251199960708618, 3.2507998943328857, 3.250499963760376, 3.250499963760376, 3.2493999004364014, 3.2488999366760254, 3.2483999729156494, 3.248199939727783, 3.247999906539917, 3.2479000091552734, 3.1666998863220215, 2.914900064468384, 2.992000102996826, 2.6763999462127686, 2.745800018310547, 3.1177000999450684, 2.6298999786376953, 3.4788999557495117, 3.476300001144409, 3.474299907684326, 3.4735000133514404, 3.4714999198913574, 3.4711999893188477, 3.4700000286102295, 3.469599962234497, 3.469599962234497, 3.468899965286255, 3.468600034713745, 3.4677999019622803, 3.467600107192993, 3.4672999382019043, 3.4672000408172607, 3.467099905014038, 3.4665000438690186, 3.466399908065796, 3.466099977493286, 3.4660000801086426, 3.46560001373291, 3.464400053024292, 3.4642999172210693, 3.464099884033203, 3.463599920272827, 3.4635000228881836, 3.4625000953674316, 3.460900068283081, 3.460099935531616, 3.459700107574463, 3.29259991645813, 3.0446999073028564, 2.8166000843048096, 2.6198999881744385, 3.6010000705718994, 3.5964999198913574, 3.5957999229431152, 3.5954999923706055, 3.591099977493286, 3.5905001163482666, 3.588099956512451, 3.5790998935699463, 3.578399896621704, 3.5780999660491943, 3.5761001110076904, 3.5755999088287354, 3.575500011444092, 3.571500062942505, 3.57069993019104, 3.5706000328063965, 3.570199966430664, 3.5701000690460205, 3.569499969482422, 3.566200017929077, 3.563800096511841, 3.5629000663757324, 3.562000036239624, 3.5571999549865723, 3.5571999549865723, 3.5569000244140625, 3.5566999912261963, 3.556299924850464, 3.5555999279022217, 3.553299903869629, 3.552000045776367, 3.0822999477386475, 2.5776000022888184, 2.2600998878479004, 2.672100067138672, 2.103600025177002, 2.2372000217437744, -1.1291999816894531, 3.600800037384033, 3.5975000858306885, 3.5971999168395996, 3.5968000888824463, 3.596400022506714, 3.596100091934204, 3.594899892807007, 3.594899892807007, 3.594599962234497, 3.592600107192993, 3.591099977493286, 3.590399980545044, 3.5901999473571777, 3.590100049972534, 3.589900016784668, 3.588099956512451, 3.584399938583374, 3.583699941635132, 3.5820999145507812, 3.5815000534057617, 3.581399917602539, 3.5813000202178955, 3.5806000232696533, 3.5801000595092773, 3.5794999599456787, 3.575700044631958, 3.5754001140594482, 3.574700117111206, 3.5743000507354736, 3.5724000930786133, 3.4818999767303467, 3.1187000274658203, 1.9581999778747559, 3.080399990081787, 3.661600112915039, 3.6607000827789307, 3.6582000255584717, 3.655600070953369, 3.653599977493286, 3.6531999111175537, 3.652899980545044, 3.6528000831604004, 3.6526999473571777, 3.650399923324585, 3.649899959564209, 3.649399995803833, 3.648900032043457, 3.6475000381469727, 3.6465001106262207, 3.646199941635132, 3.645400047302246, 3.6451001167297363, 3.644700050354004, 3.6442999839782715, 3.643199920654297, 3.6424999237060547, 3.640899896621704, 3.6407999992370605, 3.6393001079559326, 3.6387999057769775, 3.6384999752044678, 3.63700008392334, 3.636899948120117, 3.6368000507354736, 2.9783999919891357, 2.8940000534057617, 1.0008000135421753, 3.664299964904785, 3.6642000675201416, 3.663100004196167, 3.662899971008301, 3.6612000465393066, 3.6607000827789307, 3.6600000858306885, 3.659600019454956, 3.6572000980377197, 3.656599998474121, 3.6563000679016113, 3.6552000045776367, 3.6493000984191895, 3.648900032043457, 3.646199941635132, 3.645900011062622, 3.645400047302246, 3.6440000534057617, 3.6435000896453857, 3.6410999298095703, 3.640199899673462, 3.6401000022888184, 3.63919997215271, 3.6363000869750977, 3.6347999572753906, 3.6328001022338867, 3.631700038909912, 3.6308000087738037, 3.6298000812530518, 3.6298000812530518, 3.7286999225616455, 3.7284998893737793, 3.72760009765625, 3.726099967956543, 3.725800037384033, 3.722100019454956, 3.72189998626709, 3.7216999530792236, 3.7202000617980957, 3.719599962234497, 3.719399929046631, 3.7191998958587646, 3.7190001010894775, 3.7181999683380127, 3.7167000770568848, 3.715100049972534, 3.714900016784668, 3.7135000228881836, 3.7132999897003174, 3.713099956512451, 3.713099956512451, 3.7128000259399414, 3.7123000621795654, 3.7118000984191895, 3.710599899291992, 3.7093000411987305, 3.7079999446868896, 3.7076001167297363, 3.7076001167297363, 3.705899953842163, 2.3336000442504883, 2.956899881362915, 2.195499897003174, 3.7994000911712646, 3.796999931335449, 3.789900064468384, 3.789400100708008, 3.7892000675201416, 3.788800001144409, 3.7883999347686768, 3.788300037384033, 3.785599946975708, 3.7852001190185547, 3.78439998626709, 3.7836999893188477, 3.7829999923706055, 3.782099962234497, 3.7820000648498535, 3.781399965286255, 3.781399965286255, 3.7808001041412354, 3.7795000076293945, 3.7792000770568848, 3.77839994430542, 3.77620005607605, 3.7748000621795654, 3.7730000019073486, 3.7709999084472656, 3.7697999477386475, 3.7695000171661377, 3.769399881362915, 3.768899917602539, 3.7683000564575195, 3.3956000804901123, 3.3606998920440674, 4.052999973297119, 4.050600051879883, 4.049200057983398, 4.04610013961792, 4.0457000732421875, 4.045300006866455, 4.042200088500977, 4.039100170135498, 4.037499904632568, 4.034299850463867, 4.0335001945495605, 4.032700061798096, 4.032299995422363, 4.031300067901611, 4.0289998054504395, 4.028600215911865, 4.027500152587891, 4.026800155639648, 4.025100231170654, 4.01669979095459, 4.016600131988525, 4.01639986038208, 4.015999794006348, 4.013400077819824, 4.01039981842041, 4.005199909210205, 4.005099773406982, 4.005000114440918, 4.004300117492676, 4.004199981689453, 2.522599935531616, 2.5755999088287354]}, \"token.table\": {\"Topic\": [4, 12, 3, 12, 14, 5, 15, 5, 1, 3, 5, 7, 11, 13, 18, 19, 11, 2, 4, 11, 14, 20, 12, 18, 7, 12, 12, 16, 19, 6, 18, 18, 13, 4, 16, 5, 9, 9, 13, 17, 11, 4, 5, 16, 2, 3, 4, 8, 10, 13, 20, 10, 18, 4, 15, 2, 7, 20, 14, 6, 7, 20, 18, 15, 1, 2, 4, 5, 2, 4, 4, 10, 10, 7, 2, 14, 4, 7, 1, 15, 15, 3, 3, 5, 10, 18, 6, 7, 19, 3, 8, 11, 20, 13, 8, 3, 2, 7, 18, 6, 4, 1, 11, 3, 7, 17, 18, 5, 19, 5, 16, 3, 4, 7, 3, 1, 18, 8, 14, 3, 16, 20, 7, 6, 16, 19, 17, 1, 3, 7, 13, 17, 9, 4, 1, 18, 3, 5, 15, 1, 3, 7, 9, 10, 9, 1, 13, 18, 10, 15, 13, 4, 17, 5, 15, 1, 17, 8, 20, 20, 14, 8, 10, 8, 17, 13, 12, 20, 13, 7, 2, 9, 9, 20, 7, 8, 2, 3, 1, 8, 14, 8, 5, 19, 1, 2, 3, 7, 4, 18, 2, 15, 2, 4, 6, 7, 4, 6, 18, 6, 10, 15, 1, 17, 5, 9, 13, 8, 2, 3, 15, 3, 9, 18, 6, 1, 3, 5, 6, 9, 11, 3, 4, 11, 11, 17, 5, 4, 9, 15, 4, 1, 2, 4, 8, 13, 6, 14, 4, 8, 8, 1, 5, 7, 11, 3, 5, 17, 15, 2, 7, 14, 20, 19, 16, 14, 12, 5, 18, 9, 13, 16, 5, 6, 6, 13, 11, 11, 15, 12, 13, 12, 5, 6, 15, 10, 19, 3, 12, 2, 3, 4, 1, 3, 6, 11, 14, 5, 20, 18, 20, 8, 14, 3, 5, 4, 11, 1, 8, 16, 14, 18, 12, 2, 5, 4, 8, 2, 19, 19, 11, 10, 8, 2, 12, 10, 1, 6, 4, 16, 5, 12, 5, 20, 2, 8, 15, 1, 6, 2, 3, 11, 18, 20, 9, 6, 6, 16, 2, 3, 3, 7, 8, 1, 3, 4, 13, 14, 12, 18, 12, 16, 7, 20, 20, 3, 4, 12, 6, 18, 10, 18, 7, 13, 4, 1, 12, 17, 17, 9, 11, 11, 18, 10, 15, 12, 14, 1, 20, 3, 1, 3, 18, 15, 16, 7, 17, 3, 15, 1, 9, 11, 16, 4, 18, 17, 17, 1, 2, 3, 4, 7, 8, 9, 9, 3, 14, 15, 9, 12, 3, 14, 7, 7, 19, 4, 10, 2, 8, 18, 11, 8, 2, 5, 13, 6, 6, 14, 8, 19, 5, 9, 9, 15, 11, 2, 3, 4, 6, 2, 7, 5, 13, 8, 20, 15, 10, 10, 4, 13, 13, 6, 4, 7, 8, 14, 19, 5, 13, 2, 12, 16, 14, 2, 1, 13, 10, 12, 7, 16, 9, 3, 20, 15, 2, 5, 10, 8, 1, 2, 4, 7, 4, 2, 15, 7, 5, 10, 11, 19, 10, 12, 1, 3, 7, 11, 5, 1, 17, 20, 2, 5, 10, 3, 6, 2, 3, 6, 1, 5, 16, 7, 17, 2, 15, 19, 13, 10, 1, 1, 4, 7, 18, 1, 4, 8, 1, 19, 19, 12, 16, 9, 15, 11, 3, 15, 13, 4, 11, 3, 5, 6, 9, 11, 17, 3, 11, 1, 2, 9, 16, 9, 11, 1, 3, 6, 20, 1, 3, 6, 18, 20, 9, 10, 19, 1, 11, 5, 8, 14, 2, 20, 2, 5, 9, 10, 5, 16, 2, 3, 4, 8, 9, 2, 9, 16, 3, 15, 13, 1, 9, 15, 1, 4, 7, 10, 5, 11, 16, 11, 18, 19, 13, 6, 11, 5, 9, 2, 3, 13, 3, 12, 5, 5, 10, 15, 3, 11, 18, 16, 10, 3, 17, 4, 12, 13, 10, 13, 14, 4, 11, 11, 16, 16, 3, 19, 14, 7, 11, 15, 1, 6, 1, 13, 9, 15, 5, 3, 7, 3, 20, 1, 4, 9, 3, 11, 12, 9, 5, 5, 13, 5, 15, 16, 9, 19, 1, 2, 3, 5, 4, 12, 1, 2, 5, 7, 3, 1, 2, 3, 16, 18, 16, 2, 5, 12, 14, 13, 8, 12, 14, 17, 8, 10, 14, 5, 7, 7, 5, 9, 7, 1, 1, 7, 2, 4, 11, 14, 17, 18, 20, 8, 11, 15, 10, 19, 18, 12, 8, 1, 4, 15, 1, 6, 20, 17, 7, 20, 7, 14, 12, 2, 8, 17, 14, 7, 9, 11, 14, 15, 20, 6, 17, 11, 12, 14, 17, 16, 4, 7, 14, 17, 1, 10, 16, 11, 15, 13, 7, 9, 1, 8, 15, 6, 3, 2, 7, 6, 20, 18, 10, 14, 16, 3, 1, 2, 18, 17, 8, 8, 14, 17, 2, 6, 6, 8, 4, 2, 5, 9, 2, 12, 11, 9, 19, 1, 2, 6, 7, 20, 12, 20, 8, 9, 5, 1, 2, 4, 11, 16, 2, 4, 5, 8, 12, 20, 19, 1, 1, 3, 6, 8, 7, 20, 7, 12, 2, 13, 11, 19, 2, 3, 4, 5, 8, 9, 2, 10, 10, 14, 17, 12, 16, 9, 11, 4, 12, 16, 19, 10, 5, 8, 12, 11, 4, 11, 11, 5, 4, 3, 6, 11, 1, 13, 12, 16, 3, 6, 14, 14, 1, 4, 5, 9, 3, 4, 7, 5, 10, 14, 19, 10, 5, 1, 15, 6, 11, 11, 1, 2, 6, 7, 11, 18, 13, 2, 2, 3, 6, 20, 19, 1, 2, 3, 8, 13, 1, 2, 3, 5, 11, 19, 6, 17, 11, 9, 19, 19, 14, 9, 5, 13, 4, 1, 2, 3, 4, 5, 6, 7, 1, 4, 5, 11, 10, 6, 3, 14, 18, 20, 1, 18, 6, 18, 8, 5, 8, 13, 18, 1, 15, 13, 19, 19, 1, 8, 13, 5, 8, 9, 10, 17, 9, 10, 4, 3, 11, 5, 17, 5, 2, 5, 20], \"Freq\": [0.9943674802780151, 0.9872269630432129, 0.2308526337146759, 0.7618137001991272, 0.9531568288803101, 0.9729499220848083, 0.02048315480351448, 0.9944815635681152, 0.3552300035953522, 0.04179176688194275, 0.012537529692053795, 0.5056803822517395, 0.008358352817595005, 0.020895883440971375, 0.05850847065448761, 0.9837744235992432, 0.9921684861183167, 0.9910462498664856, 0.9966491460800171, 0.9908111095428467, 0.9883808493614197, 0.9284496903419495, 0.9924463629722595, 0.9803987741470337, 0.2911141812801361, 0.7058521509170532, 0.9968107342720032, 0.9723419547080994, 0.9702474474906921, 0.9969425797462463, 0.9942992925643921, 0.9873809814453125, 0.9771173000335693, 0.9950577020645142, 0.9813095927238464, 0.3027286231517792, 0.6948997974395752, 0.9906977415084839, 0.9979478120803833, 0.9819571375846863, 0.9910301566123962, 0.9976503849029541, 0.9946190714836121, 0.990554928779602, 0.7306790351867676, 0.09367679804563522, 0.1342700719833374, 0.003122559981420636, 0.015612799674272537, 0.015612799674272537, 0.987169086933136, 0.9748812317848206, 0.9914401769638062, 0.9950959086418152, 0.9912664890289307, 0.5049430727958679, 0.49182769656181335, 0.9670258164405823, 0.9720378518104553, 0.9908943176269531, 0.9939210414886475, 0.9424806237220764, 0.9795147180557251, 0.9846293330192566, 0.7769762873649597, 0.1475507915019989, 0.02428050898015499, 0.05042874813079834, 0.9928245544433594, 0.9940940737724304, 0.9923653602600098, 0.9884024262428284, 0.9850726127624512, 0.9844434857368469, 0.9936749339103699, 0.9617344737052917, 0.9941425919532776, 0.9878891110420227, 0.9967238306999207, 0.9709829092025757, 0.9807522892951965, 0.9903334379196167, 0.9856904745101929, 0.1597781479358673, 0.8255204558372498, 0.986248254776001, 0.9885046482086182, 0.9940549731254578, 0.9969529509544373, 0.7792881727218628, 0.21988213062286377, 0.9083974957466125, 0.0875563845038414, 0.9920219779014587, 0.9890100955963135, 0.9885224103927612, 0.9901060461997986, 0.0035873407032340765, 0.005381010938435793, 0.9957046508789062, 0.9987308979034424, 0.9909414649009705, 0.9807127714157104, 0.997462809085846, 0.9797525405883789, 0.968012273311615, 0.9820815324783325, 0.023233551532030106, 0.9641923904418945, 0.9953639507293701, 0.9877699017524719, 0.9970406293869019, 0.9939942359924316, 0.991223931312561, 0.9954172968864441, 0.9949308633804321, 0.9758418798446655, 0.9944863319396973, 0.9838404655456543, 0.49241742491722107, 0.49999305605888367, 0.9829151034355164, 0.989612340927124, 0.9943572878837585, 0.9788925051689148, 0.9941416382789612, 0.9801483154296875, 0.04263053834438324, 0.030450385063886642, 0.9256917238235474, 0.9937487244606018, 0.9634959101676941, 0.9920753240585327, 0.997142493724823, 0.7785965800285339, 0.21457386016845703, 0.9961473941802979, 0.9211438894271851, 0.07369151711463928, 0.995457649230957, 0.29832082986831665, 0.6960819363594055, 0.9849463105201721, 0.9966241717338562, 0.9802297353744507, 0.996489942073822, 0.827424943447113, 0.1675797402858734, 0.9840322732925415, 0.9706326723098755, 0.985386312007904, 0.9889666438102722, 0.9831028580665588, 0.9943253993988037, 0.9901989698410034, 0.9950507283210754, 0.9658939838409424, 0.9911025166511536, 0.9554377198219299, 0.9262951016426086, 0.9803599119186401, 0.9876899719238281, 0.9941498637199402, 0.9887019991874695, 0.9985292553901672, 0.9852339625358582, 0.9806162714958191, 0.9813956022262573, 0.9879222512245178, 0.9833223223686218, 0.9940758347511292, 0.00451852660626173, 0.9960812330245972, 0.9712406396865845, 0.5426745414733887, 0.45643553137779236, 0.989640474319458, 0.9953217506408691, 0.99427729845047, 0.9912603497505188, 0.9872022867202759, 0.9875032305717468, 0.9926801323890686, 0.9603897333145142, 0.9096601009368896, 0.032287318259477615, 0.012634167447686195, 0.04492148384451866, 0.9906575679779053, 0.9784590601921082, 0.9973095655441284, 0.9684230089187622, 0.22615696489810944, 0.469191312789917, 0.22953243553638458, 0.07088501751422882, 0.5439468622207642, 0.4525969922542572, 0.9630685448646545, 0.9883160591125488, 0.9678381681442261, 0.9917977452278137, 0.9935523867607117, 0.9765790700912476, 0.9947970509529114, 0.9866665005683899, 0.9874637722969055, 0.9868724942207336, 0.925073504447937, 0.07216885685920715, 0.9964554309844971, 0.9916165471076965, 0.9895323514938354, 0.9805008172988892, 0.9965258240699768, 0.5206878185272217, 0.284039705991745, 0.08549068868160248, 0.10469511151313782, 0.002787739736959338, 0.001548744272440672, 0.5456276535987854, 0.0795707032084465, 0.37227723002433777, 0.9899819493293762, 0.9904966354370117, 0.9871950745582581, 0.9975563883781433, 0.9876207709312439, 0.9732959270477295, 0.9967085719108582, 0.23316413164138794, 0.4701298475265503, 0.24076731503009796, 0.04942065849900246, 0.005068785510957241, 0.9971193075180054, 0.9558417797088623, 0.9916490316390991, 0.9991720914840698, 0.9950973391532898, 0.5170860290527344, 0.04977298527956009, 0.32905474305152893, 0.1023111343383789, 0.19500373303890228, 0.7977425456047058, 0.9700149297714233, 0.9787858128547668, 0.9914765357971191, 0.9904508590698242, 0.9967656135559082, 0.9778417944908142, 0.9837720990180969, 0.9950439929962158, 0.9921902418136597, 0.9929057359695435, 0.987451434135437, 0.9769588708877563, 0.9917400479316711, 0.972260057926178, 0.993847668170929, 0.9925284385681152, 0.9885702133178711, 0.9892978072166443, 0.9884283542633057, 0.9960815906524658, 0.9952468872070312, 0.990450382232666, 0.9935792684555054, 0.9919037222862244, 0.9896904826164246, 0.9904260039329529, 0.3944340646266937, 0.5916510820388794, 0.9936582446098328, 0.9544118046760559, 0.9967042207717896, 0.9964834451675415, 0.9984392523765564, 0.5870598554611206, 0.4109418988227844, 0.8569454550743103, 0.08487840741872787, 0.007753315847367048, 0.041214995086193085, 0.008977523073554039, 0.9865073561668396, 0.9926173090934753, 0.9777894020080566, 0.9761017560958862, 0.9875994324684143, 0.9500221014022827, 0.9952094554901123, 0.9985293745994568, 0.9939361810684204, 0.9951213002204895, 0.9980368614196777, 0.9940675497055054, 0.9801866412162781, 0.9536218643188477, 0.9776375889778137, 0.9818623661994934, 0.9451640248298645, 0.0526309460401535, 0.6069190502166748, 0.393161416053772, 0.3333165645599365, 0.6643809676170349, 0.9900619983673096, 0.9912300705909729, 0.9790617823600769, 0.9884007573127747, 0.40204355120658875, 0.5976322889328003, 0.9710013270378113, 0.995470404624939, 0.9872415065765381, 0.9283503890037537, 0.06983166933059692, 0.9944604635238647, 0.983802855014801, 0.9883418083190918, 0.9638732075691223, 0.9938774704933167, 0.9946233630180359, 0.958852231502533, 0.9668593406677246, 0.031323738396167755, 0.23724205791950226, 0.16836532950401306, 0.3443836271762848, 0.24489502608776093, 0.9641821384429932, 0.9858058094978333, 0.9857728481292725, 0.9890420436859131, 0.9963580965995789, 0.6130156517028809, 0.3858983814716339, 0.9874962568283081, 0.007899969816207886, 0.9983552694320679, 0.9193440675735474, 0.07661200314760208, 0.702897846698761, 0.06774918735027313, 0.22018486261367798, 0.9860494136810303, 0.9885461926460266, 0.9914066195487976, 0.9950290322303772, 0.9877496957778931, 0.9388532042503357, 0.9844000339508057, 0.7021240592002869, 0.29361552000045776, 0.9928213953971863, 0.991226851940155, 0.9887510538101196, 0.9829321503639221, 0.9617968201637268, 0.9988161325454712, 0.9867237210273743, 0.9963558316230774, 0.9963271021842957, 0.9959933757781982, 0.9633125066757202, 0.9914831519126892, 0.9174609780311584, 0.07575365900993347, 0.9790536165237427, 0.9872215390205383, 0.7719106078147888, 0.22703254222869873, 0.9945731163024902, 0.9668047428131104, 0.9991680383682251, 0.9719406962394714, 0.9927424192428589, 0.6966034173965454, 0.3024725317955017, 0.9911724328994751, 0.9923079013824463, 0.9797212481498718, 0.9886670112609863, 0.9953576326370239, 0.996977686882019, 0.9854375720024109, 0.6548409461975098, 0.3442977964878082, 0.9868858456611633, 0.9770522713661194, 0.995205283164978, 0.9780441522598267, 0.9963741898536682, 0.9872995018959045, 0.027228614315390587, 0.7527911067008972, 0.003203366417437792, 0.004805049393326044, 0.2130238562822342, 0.32773563265800476, 0.6705395579338074, 0.9868109226226807, 0.9976818561553955, 0.9769061803817749, 0.9894555807113647, 0.9857069849967957, 0.9930056929588318, 0.9876455068588257, 0.9766033887863159, 0.989031970500946, 0.9968769550323486, 0.9821573495864868, 0.9907528162002563, 0.9976518750190735, 0.9946488738059998, 0.9869062900543213, 0.9955226182937622, 0.9827722907066345, 0.97646164894104, 0.9366886615753174, 0.030585752800107002, 0.03249736130237579, 0.9954227209091187, 0.9902607798576355, 0.9933388829231262, 0.9880632758140564, 0.9794407486915588, 0.9917396903038025, 0.9935552477836609, 0.9781909584999084, 0.9938033819198608, 0.9919728636741638, 0.40575873851776123, 0.31936144828796387, 0.13268156349658966, 0.1403956115245819, 0.9932178258895874, 0.9978564977645874, 0.9965866208076477, 0.9902836084365845, 0.9886162877082825, 0.9874062538146973, 0.997001588344574, 0.9848812818527222, 0.9874763488769531, 0.9971253871917725, 0.9919296503067017, 0.9826616048812866, 0.9817603230476379, 0.20487377047538757, 0.4325112998485565, 0.06829125434160233, 0.25040125846862793, 0.03414562717080116, 0.8167097568511963, 0.1783618927001953, 0.9945312142372131, 0.5317766070365906, 0.46530449390411377, 0.9913914203643799, 0.9934808015823364, 0.980596661567688, 0.01743282936513424, 0.9901094436645508, 0.9959685206413269, 0.9910282492637634, 0.9822852611541748, 0.9873497486114502, 0.7754772901535034, 0.21810299158096313, 0.9886807799339294, 0.9947551488876343, 0.16775909066200256, 0.8299660086631775, 0.9941624402999878, 0.5888755321502686, 0.1112835630774498, 0.006955222692340612, 0.2921193540096283, 0.9847508668899536, 0.9944502711296082, 0.9743081331253052, 0.9863379597663879, 0.21616210043430328, 0.7805853486061096, 0.9904580116271973, 0.9672671556472778, 0.9890031814575195, 0.9932758808135986, 0.9977875351905823, 0.9915257692337036, 0.25915756821632385, 0.7381069660186768, 0.9961068630218506, 0.9964309334754944, 0.9965230822563171, 0.9876165986061096, 0.6403705477714539, 0.35923224687576294, 0.9731590747833252, 0.24551579356193542, 0.7472219467163086, 0.9948826432228088, 0.9927709102630615, 0.9952191710472107, 0.9777339100837708, 0.01906444877386093, 0.9872261881828308, 0.9933987855911255, 0.9831863045692444, 0.9964030385017395, 0.9933017492294312, 0.9781252145767212, 0.988559365272522, 0.9942936897277832, 0.9907012581825256, 0.9990508556365967, 0.07700926810503006, 0.46205562353134155, 0.46205562353134155, 0.4068130552768707, 0.41156184673309326, 0.17887111008167267, 0.9953340888023376, 0.9723509550094604, 0.9676393866539001, 0.9895795583724976, 0.9724268317222595, 0.9794560074806213, 0.993226945400238, 0.9822050333023071, 0.9983653426170349, 0.9695279598236084, 0.9840306043624878, 0.9959712624549866, 0.985252857208252, 0.697733998298645, 0.08844515681266785, 0.10613418370485306, 0.0648597776889801, 0.04323985427618027, 0.9666876196861267, 0.6912840604782104, 0.3088715970516205, 0.23178040981292725, 0.6902133226394653, 0.007179039064794779, 0.06973923742771149, 0.9868507385253906, 0.9888643622398376, 0.6497312784194946, 0.2388085126876831, 0.10972283035516739, 0.9795837998390198, 0.16635243594646454, 0.6522766351699829, 0.15759705007076263, 0.021888477727770805, 0.9442113637924194, 0.98821622133255, 0.9860661625862122, 0.9523653388023376, 0.9872409701347351, 0.010769901797175407, 0.996900737285614, 0.9884777665138245, 0.9786101579666138, 0.994449257850647, 0.9903718829154968, 0.5844631791114807, 0.3713776171207428, 0.039573024958372116, 0.9688769578933716, 0.9950613379478455, 0.9858578443527222, 0.04902106150984764, 0.6545753479003906, 0.020185144618153572, 0.24798890948295593, 0.023068735376000404, 0.9995664358139038, 0.9974908828735352, 0.9802963137626648, 0.9455641508102417, 0.051111575216054916, 0.9836298227310181, 0.9956989884376526, 0.983636736869812, 0.9926087260246277, 0.7178453207015991, 0.1844618022441864, 0.033336468040943146, 0.06445050984621048, 0.049564115703105927, 0.7732002139091492, 0.16851799190044403, 0.9978015422821045, 0.9852163791656494, 0.9616997838020325, 0.9882389903068542, 0.9921936988830566, 0.9909691214561462, 0.24645809829235077, 0.7460353374481201, 0.9929689168930054, 0.9943731427192688, 0.9830897450447083, 0.9895665049552917, 0.989539623260498, 0.9903347492218018, 0.9948161840438843, 0.722766637802124, 0.2730451822280884, 0.3207876682281494, 0.5957485437393188, 0.0785602480173111, 0.9688851833343506, 0.9947524666786194, 0.9903444647789001, 0.9665533900260925, 0.4002600908279419, 0.07591139525175095, 0.5175777077674866, 0.9872608184814453, 0.9808563590049744, 0.95949387550354, 0.8415818214416504, 0.1582375317811966, 0.9836363196372986, 0.9767580628395081, 0.9845757484436035, 0.9915687441825867, 0.9770731329917908, 0.9948971271514893, 0.9979444742202759, 0.8038783669471741, 0.19278530776500702, 0.9691964387893677, 0.029161663725972176, 0.9954794049263, 0.9900282621383667, 0.9789819121360779, 0.9832156896591187, 0.9888133406639099, 0.9941644072532654, 0.9863560199737549, 0.9914405345916748, 0.982670783996582, 0.9044502377510071, 0.07583553344011307, 0.01784365437924862, 0.3304070234298706, 0.6608140468597412, 0.9834344387054443, 0.9796439409255981, 0.9953457713127136, 0.5735368728637695, 0.42218685150146484, 0.10664663463830948, 0.8822585344314575, 0.9721847176551819, 0.9860416650772095, 0.9890040755271912, 0.10669464617967606, 0.5955049991607666, 0.267977237701416, 0.0272939782589674, 0.9911153316497803, 0.9947609305381775, 0.2695135176181793, 0.6236189007759094, 0.033443283289670944, 0.07278832793235779, 0.9911102652549744, 0.29606589674949646, 0.6548742651939392, 0.047056831419467926, 0.9927147030830383, 0.981889545917511, 0.975774884223938, 0.8601610660552979, 0.06562536954879761, 0.07265665382146835, 0.9367741346359253, 0.9937962293624878, 0.9933655858039856, 0.9068923592567444, 0.039430104196071625, 0.04928762838244438, 0.9488177299499512, 0.04273953661322594, 0.9769517779350281, 0.9965550899505615, 0.9974184632301331, 0.9839764833450317, 0.8070251941680908, 0.19188012182712555, 0.9857175946235657, 0.9998390078544617, 0.8714703917503357, 0.12616461515426636, 0.9976427555084229, 0.9875136613845825, 0.9965156316757202, 0.9752368927001953, 0.9840262532234192, 0.9769906997680664, 0.9871512651443481, 0.21496032178401947, 0.7822167277336121, 0.9657973051071167, 0.3408668637275696, 0.649270236492157, 0.9631912708282471, 0.98908531665802, 0.9794849157333374, 0.9961976408958435, 0.9811243414878845, 0.017931776121258736, 0.9973227977752686, 0.9928084015846252, 0.9304692149162292, 0.9718025326728821, 0.9666074514389038, 0.02885395474731922, 0.9925550818443298, 0.9635884761810303, 0.9909845590591431, 0.17781540751457214, 0.8206865191459656, 0.9713689088821411, 0.9924920201301575, 0.9951300024986267, 0.8169912695884705, 0.17398887872695923, 0.35892587900161743, 0.6169038414955139, 0.011216433718800545, 0.9874219298362732, 0.9790066480636597, 0.9849072694778442, 0.9919831156730652, 0.9755134582519531, 0.9759742617607117, 0.980943500995636, 0.14635582268238068, 0.3951607048511505, 0.3951607048511505, 0.05854232981801033, 0.9979641437530518, 0.971444308757782, 0.9597057104110718, 0.9876238107681274, 0.9979233741760254, 0.9828935265541077, 0.9933179020881653, 0.9900159239768982, 0.992984414100647, 0.9891008734703064, 0.9821612238883972, 0.9943950772285461, 0.9928668141365051, 0.993215799331665, 0.9867621064186096, 0.9924256801605225, 0.965823769569397, 0.9949759244918823, 0.9837573766708374, 0.965941309928894, 0.9735497236251831, 0.9881181716918945, 0.7939597368240356, 0.20422662794589996, 0.9735944271087646, 0.9893988370895386, 0.9906302094459534, 0.7299478650093079, 0.25806236267089844, 0.9576420187950134, 0.9990302324295044, 0.9930557012557983, 0.9946525692939758, 0.9947625398635864, 0.9925267696380615, 0.9941534996032715, 0.15338477492332458, 0.8340297341346741, 0.9974731206893921, 0.9784706234931946, 0.9949871897697449, 0.9980192184448242, 0.9816394448280334, 0.1740717589855194, 0.6266583204269409, 0.08123348653316498, 0.11372687667608261, 0.9525240659713745, 0.9891232252120972, 0.9407408833503723, 0.9945687055587769, 0.9946762919425964, 0.995176374912262, 0.0028933282010257244, 0.81881183385849, 0.1417730748653412, 0.034719936549663544, 0.9930640459060669, 0.8620802164077759, 0.074589304625988, 0.05020434036850929, 0.0028688195161521435, 0.0028688195161521435, 0.007172048557549715, 0.9832519888877869, 0.9990319609642029, 0.7080601453781128, 0.2773011028766632, 0.013461219146847725, 0.9830381274223328, 0.9936333894729614, 0.9686904549598694, 0.12685371935367584, 0.859786331653595, 0.9943197965621948, 0.9910851120948792, 0.98089200258255, 0.9929669499397278, 0.19204160571098328, 0.08190009742975235, 0.47163158655166626, 0.13273464143276215, 0.019768988713622093, 0.09884494543075562, 0.9974513053894043, 0.9871922135353088, 0.9935239553451538, 0.9410724639892578, 0.979017972946167, 0.994573712348938, 0.9923282861709595, 0.9775708317756653, 0.9881289005279541, 0.9868196845054626, 0.9924347996711731, 0.9857428073883057, 0.9817625880241394, 0.9896381497383118, 0.06991554796695709, 0.3714263439178467, 0.5549546480178833, 0.9904428124427795, 0.8698039650917053, 0.12773345410823822, 0.9869642853736877, 0.9832157492637634, 0.9936436414718628, 0.8435465693473816, 0.11750025302171707, 0.03682843595743179, 0.9970581531524658, 0.9877263307571411, 0.9902205467224121, 0.9783430099487305, 0.9942026734352112, 0.9979977011680603, 0.9605438709259033, 0.9620295166969299, 0.8918074369430542, 0.008622447028756142, 0.0899198055267334, 0.008622447028756142, 0.3453116714954376, 0.6527810096740723, 0.9908430576324463, 0.12670870125293732, 0.8293659687042236, 0.03455691784620285, 0.9817105531692505, 0.9959754943847656, 0.986691415309906, 0.9984166622161865, 0.9797368049621582, 0.7404248714447021, 0.2536640763282776, 0.9937227964401245, 0.014716023579239845, 0.6033569574356079, 0.014716023579239845, 0.3053574860095978, 0.01839502900838852, 0.04414806887507439, 0.9823668003082275, 0.9937751889228821, 0.9949334859848022, 0.9930523037910461, 0.9845514297485352, 0.990273118019104, 0.9843997955322266, 0.3220715820789337, 0.6466206312179565, 0.0037162103690207005, 0.021058525890111923, 0.006193683948367834, 0.8745850324630737, 0.024918116629123688, 0.06209104508161545, 0.01348029263317585, 0.024918116629123688, 0.987334132194519, 0.9969788789749146, 0.9985635876655579, 0.9851380586624146, 0.9803466200828552, 0.9538018703460693, 0.9861097931861877, 0.9998148083686829, 0.9992663264274597, 0.9979248046875, 0.9883370995521545, 0.993019700050354, 0.1777663677930832, 0.5196247696876526, 0.2233474850654602, 0.044061750173568726, 0.028868043795228004, 0.006077482830733061, 0.9887287020683289, 0.9057965278625488, 0.05565275251865387, 0.036462150514125824, 0.0009595302399247885, 0.9965161085128784, 0.9852489829063416, 0.9932284355163574, 0.5955699682235718, 0.1720535308122635, 0.22499309480190277, 0.995644211769104, 0.9932878613471985, 0.9974960684776306, 0.9846311211585999, 0.9802953600883484, 0.31636473536491394, 0.03615596890449524, 0.6462879776954651, 0.9954230785369873, 0.9955392479896545, 0.9857987761497498, 0.9763131737709045, 0.9833908081054688, 0.9795846343040466, 0.9973401427268982, 0.9932471513748169, 0.9753819704055786, 0.09285266697406769, 0.7361889481544495, 0.13264666497707367, 0.03316166624426842, 0.9733021259307861, 0.9811044335365295, 0.9973732829093933, 0.9908679127693176, 0.9589897394180298, 0.03792614862322807, 0.9947639107704163, 0.9906682968139648, 0.9993999004364014, 0.9934418201446533, 0.0016724610468372703, 0.005017383024096489], \"Term\": [\"abrigo\", \"accidente\", \"accion\", \"accion\", \"achaque\", \"actor\", \"actor\", \"actore\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"adela\", \"adio\", \"administracion\", \"admirable\", \"admiracion\", \"adorable\", \"adversario\", \"afeccione\", \"africanos\", \"agradable\", \"agradable\", \"aire\", \"alba\", \"albane\", \"alegre\", \"alli\", \"almacene\", \"altar\", \"amable\", \"ambicion\", \"amigo\", \"amigo\", \"amor\", \"amore\", \"anadio\", \"andre\", \"animale\", \"anselmo\", \"ansi\", \"anteriore\", \"anteriore\", \"anteriore\", \"anteriore\", \"anteriore\", \"anteriore\", \"apacible\", \"aparecio\", \"apunte\", \"arbole\", \"ardiente\", \"area\", \"area\", \"arrojo\", \"ascension\", \"asunto\", \"atencion\", \"atribucione\", \"atributo\", \"atroce\", \"aunque\", \"aunque\", \"aunque\", \"aunque\", \"autor\", \"ave\", \"azule\", \"bad\", \"banda\", \"barrio\", \"base\", \"basis\", \"bastante\", \"baure\", \"belleza\", \"beneficio\", \"beso\", \"billet\", \"blanco\", \"blue\", \"blue\", \"bosque\", \"bote\", \"brasil\", \"brazo\", \"breve\", \"breve\", \"brillante\", \"brillante\", \"brutale\", \"bueno\", \"buque\", \"ca\", \"ca\", \"ca\", \"caballo\", \"cabeza\", \"cabo\", \"calidade\", \"call\", \"calle\", \"callejon\", \"campana\", \"cancer\", \"cancer\", \"cancione\", \"canonigo\", \"canton\", \"capace\", \"capital\", \"capitane\", \"caractere\", \"carecer\", \"carne\", \"case\", \"catedral\", \"catedral\", \"catorce\", \"caudale\", \"centenare\", \"cespe\", \"chiste\", \"chriftianos\", \"ciudade\", \"ciudade\", \"ciudade\", \"coche\", \"cohete\", \"colmo\", \"color\", \"colore\", \"colore\", \"combate\", \"come\", \"come\", \"comer\", \"comercio\", \"comercio\", \"compasion\", \"compone\", \"comprender\", \"comun\", \"comune\", \"comune\", \"comunidad\", \"conducir\", \"conductore\", \"confederacion\", \"confusa\", \"conmigo\", \"conocer\", \"considerable\", \"consideracion\", \"consideracione\", \"constelacion\", \"constituye\", \"contemplacion\", \"contigo\", \"continue\", \"continuo\", \"conversacion\", \"conversacione\", \"convulsione\", \"coro\", \"corporale\", \"corredore\", \"corriente\", \"corriente\", \"corte\", \"costa\", \"costumbre\", \"costumbre\", \"crear\", \"creia\", \"creyo\", \"criatura\", \"crimene\", \"cristiano\", \"cruel\", \"cruele\", \"cuale\", \"cuale\", \"cuale\", \"cuale\", \"cualidade\", \"culpable\", \"cura\", \"curioso\", \"cuya\", \"cuya\", \"cuya\", \"cuya\", \"cuyas\", \"cuyas\", \"dama\", \"darle\", \"death\", \"debe\", \"decir\", \"defpue\", \"dejando\", \"delicadeza\", \"denominacion\", \"dependiente\", \"derechos\", \"derechos\", \"desagradable\", \"deseo\", \"desesperacion\", \"desigual\", \"desnoyer\", \"despue\", \"despue\", \"despue\", \"despue\", \"despue\", \"despue\", \"detra\", \"detra\", \"detra\", \"dia\", \"diamante\", \"diario\", \"dice\", \"diciendo\", \"die\", \"diente\", \"diferente\", \"diferente\", \"diferente\", \"diferente\", \"diferente\", \"dificultade\", \"digna\", \"dinero\", \"dio\", \"diose\", \"direccion\", \"direccion\", \"direccion\", \"direccion\", \"director\", \"director\", \"discreta\", \"discusion\", \"division\", \"doce\", \"doctor\", \"doliente\", \"dolor\", \"dolore\", \"dona_luz\", \"dosis\", \"drama\", \"dude\", \"dulce\", \"duro\", \"echar\", \"echo\", \"edificio\", \"edificios\", \"editor\", \"educacion\", \"ejecucion\", \"ejercicio\", \"elegante\", \"elogio\", \"eminente\", \"emocione\", \"empieza\", \"empieza\", \"empleado\", \"emplear\", \"enemigo\", \"enfermedade\", \"enlace\", \"enorme\", \"enorme\", \"entonce\", \"entonce\", \"entonce\", \"entonce\", \"entonce\", \"episodio\", \"ermitano\", \"escaparate\", \"esclava\", \"escritore\", \"ese\", \"espalda\", \"espanole\", \"especie\", \"espectadore\", \"espiritu\", \"espiritual\", \"espirituale\", \"espuma\", \"estadio\", \"estrenimiento\", \"estudio\", \"estudio\", \"expresion\", \"expresion\", \"extension\", \"extension\", \"exteriore\", \"extraneza\", \"face\", \"facile\", \"factor\", \"factor\", \"fall\", \"falta\", \"faltaban\", \"favor\", \"favor\", \"felice\", \"felipe\", \"feliz\", \"ferrocarrile\", \"fiebre\", \"fiele\", \"film\", \"fin\", \"fin\", \"final\", \"final\", \"final\", \"final\", \"firm\", \"firmeza\", \"fisonomia\", \"flande\", \"flore\", \"france\", \"france\", \"francese\", \"francese\", \"frase\", \"fuerte\", \"fuerte\", \"funcione\", \"funcione\", \"funcione\", \"gala\", \"ganado\", \"gas\", \"gente\", \"gigante\", \"girl\", \"go\", \"grande\", \"grande\", \"grandeza\", \"grave\", \"guante\", \"guitarra\", \"haberme\", \"habitante\", \"hablo\", \"hace\", \"hacer\", \"hacian\", \"hallase\", \"hallo\", \"hecho\", \"hecho\", \"hermana\", \"hiciese\", \"high\", \"high\", \"hizo\", \"holande\", \"hombre\", \"home\", \"honor\", \"hora\", \"hora\", \"horizonte\", \"horrible\", \"horrore\", \"hotele\", \"humor\", \"iban\", \"ibid\", \"idea\", \"idea\", \"ideal\", \"ignorante\", \"iguale\", \"image\", \"imaginacion\", \"imaginarse\", \"importante\", \"importante\", \"importante\", \"importante\", \"importante\", \"imposible\", \"imposible\", \"impresion\", \"impulso\", \"incansable\", \"incomparable\", \"incomprensible\", \"inconveniente\", \"increible\", \"incurable\", \"india\", \"indio\", \"indios\", \"indispensable\", \"indudable\", \"industriale\", \"inefable\", \"inexplicable\", \"infante\", \"infatigable\", \"ingle\", \"ingle\", \"ingle\", \"inglese\", \"inocente\", \"insensible\", \"insignificante\", \"insomnio\", \"inspiracion\", \"instante\", \"intelectual\", \"intelectuale\", \"intencion\", \"inter\", \"inter\", \"inter\", \"inter\", \"intere\", \"interese\", \"interminable\", \"inutile\", \"invisible\", \"invitacion\", \"irresistible\", \"jazz\", \"king\", \"labio\", \"ladrone\", \"lamentable\", \"lance\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leer\", \"leer\", \"lengua\", \"leve\", \"leve\", \"liberale\", \"libertade\", \"libre\", \"libre\", \"life\", \"llave\", \"llevaban\", \"lleven\", \"llevo\", \"localidade\", \"localidade\", \"loco\", \"londre\", \"love\", \"love\", \"luce\", \"lugare\", \"lugare\", \"lugare\", \"lugare\", \"madre\", \"majestad\", \"male\", \"mamore\", \"man\", \"man\", \"mano\", \"marca\", \"mate\", \"materiale\", \"mayore\", \"me\", \"medio\", \"medio\", \"mejor\", \"meno\", \"merce\", \"merece\", \"mese\", \"mese\", \"metro\", \"militare\", \"militare\", \"millare\", \"miserable\", \"miseria\", \"mismo\", \"mismo\", \"misterio\", \"monte\", \"moradore\", \"moral\", \"morale\", \"mortale\", \"muchacha\", \"muelle\", \"mugere\", \"mujere\", \"nacional\", \"nacional\", \"nacional\", \"naturaleza\", \"naturaleza\", \"naturaleza\", \"nave\", \"negacion\", \"negarse\", \"nervio\", \"nina\", \"nino\", \"ninos\", \"noble\", \"noche\", \"note\", \"novio\", \"nube\", \"nueve\", \"nuevo\", \"nuevo\", \"nuevo\", \"nuevo\", \"nuevo\", \"numero\", \"nunca\", \"nunca\", \"obra\", \"obra\", \"obra\", \"obra\", \"observacion\", \"observo\", \"ocasion\", \"ocasion\", \"ocasion\", \"ocho\", \"oficiale\", \"oficiale\", \"oficiale\", \"oficiale\", \"ofreci\", \"onda\", \"oops_did\", \"open\", \"opinion\", \"opinion\", \"oposicion\", \"oracion\", \"oradore\", \"organizacion\", \"oriente\", \"original\", \"original\", \"original\", \"oscuridad\", \"oyente\", \"pace\", \"padre\", \"padre\", \"padre\", \"padre\", \"padre\", \"paise\", \"palabra\", \"papa\", \"papele\", \"papele\", \"paquete\", \"pare\", \"parecer\", \"pariente\", \"part\", \"part\", \"part\", \"part\", \"participacion\", \"participacion\", \"participacion\", \"particulare\", \"partidos\", \"pasan\", \"pasar\", \"pase\", \"paseo\", \"pasion\", \"pasion\", \"pece\", \"pedir\", \"peligroso\", \"pendiente\", \"pensar\", \"peor\", \"peore\", \"pepe\", \"pepe\", \"perdio\", \"perdio\", \"perdio\", \"perfeccion\", \"perfume\", \"permanecer\", \"permiso\", \"permite\", \"permite\", \"permite\", \"piano\", \"picante\", \"pide\", \"pie\", \"pie\", \"pinto\", \"pintore\", \"placere\", \"plane\", \"playoff\", \"pliegue\", \"poblacion\", \"pobre\", \"pobre\", \"poder\", \"poder\", \"podian\", \"polvo\", \"ponen\", \"poner\", \"ponerse\", \"pormenore\", \"portuguese\", \"poseia\", \"posesion\", \"posible\", \"posible\", \"posible\", \"posicion\", \"posicion\", \"precaucion\", \"pregunto\", \"premio\", \"presente\", \"presente\", \"presento\", \"presento\", \"pretendiente\", \"pretexto\", \"prevision\", \"primera\", \"primera\", \"primera\", \"primera\", \"primore\", \"princesa\", \"principal\", \"principal\", \"principal\", \"principal\", \"principale\", \"principio\", \"principio\", \"principio\", \"prisionero\", \"procesion\", \"prodigio\", \"produccion\", \"produccion\", \"produccion\", \"profesion\", \"profusion\", \"progreso\", \"propiedade\", \"propiedade\", \"propiedade\", \"propio\", \"propio\", \"proponer\", \"prosiguio\", \"provincia\", \"provincias\", \"publico\", \"publico\", \"pudiera\", \"pue\", \"pueblo\", \"pueblo\", \"puente\", \"pura\", \"puso\", \"pustula\", \"qual\", \"queda\", \"quehacere\", \"quiere\", \"quiere\", \"quinone\", \"radio\", \"radio\", \"ramillete\", \"rayo\", \"razonable\", \"razone\", \"real\", \"real\", \"reale\", \"rebelde\", \"reconocian\", \"reflexion\", \"region\", \"region\", \"regione\", \"reia\", \"relieve\", \"religion\", \"religion\", \"repitio\", \"replico\", \"resistir\", \"resolucion\", \"resolucion\", \"respecto\", \"respecto\", \"respecto\", \"respetable\", \"resulta\", \"retiro\", \"rev\", \"revolucion\", \"revolver\", \"ribera\", \"right\", \"right\", \"right\", \"right\", \"riqueza\", \"rise\", \"rogo\", \"rubio\", \"sabe\", \"saber\", \"sabian\", \"sabio\", \"sacerdote\", \"sacrificio\", \"sainete\", \"sala\", \"salon\", \"salud\", \"salvage\", \"sangre\", \"sant\", \"satisfaccion\", \"say\", \"se\", \"seculare\", \"seguia\", \"segun\", \"segun\", \"seleccion\", \"semejante\", \"senal\", \"senale\", \"senale\", \"sencillez\", \"senor\", \"senora\", \"senore\", \"sensacion\", \"sensacione\", \"sensible\", \"sentimiento\", \"sentimiento\", \"sentir\", \"separacion\", \"sera\", \"sere\", \"serio\", \"servicio\", \"servicio\", \"servicio\", \"servicio\", \"sesion\", \"severidad\", \"sevre\", \"si\", \"siempre\", \"siento\", \"siguiente\", \"siguiente\", \"siguiente\", \"siguiente\", \"siguio\", \"simple\", \"simple\", \"simple\", \"simple\", \"simple\", \"simple\", \"singular\", \"sino\", \"situacion\", \"situacion\", \"situacion\", \"situacione\", \"situada\", \"sk\", \"so\", \"so\", \"sociedade\", \"software\", \"sola\", \"solitario\", \"solo\", \"solo\", \"solo\", \"solo\", \"solo\", \"solo\", \"sombra\", \"sone\", \"sono\", \"sonreia\", \"sosten\", \"suave\", \"sublime\", \"sudore\", \"suelo\", \"sujeto\", \"supo\", \"sutile\", \"system\", \"take\", \"tale\", \"tale\", \"tale\", \"tall\", \"tampoco\", \"tampoco\", \"tarde\", \"television\", \"tener\", \"tenia\", \"tenia\", \"tenia\", \"tenian\", \"tenor\", \"tension\", \"tentacion\", \"terreno\", \"terrible\", \"tertulia\", \"tesoro\", \"tiempo\", \"tiempo\", \"tiempo\", \"tiempo\", \"tierra\", \"tierra\", \"timbue\", \"time\", \"time\", \"time\", \"tiradore\", \"toca\", \"tocaban\", \"toda\", \"toma\", \"tomo\", \"tomo\", \"tonele\", \"total\", \"total\", \"total\", \"total\", \"total\", \"total\", \"tour\", \"trabajadore\", \"traduccion\", \"trance\", \"transeunte\", \"trate\", \"trato\", \"trave\", \"trave\", \"trave\", \"trave\", \"trave\", \"tre\", \"tre\", \"tre\", \"tre\", \"tre\", \"tripulacion\", \"triste\", \"tristeza\", \"triunfo\", \"ulise\", \"ultimamente\", \"usada\", \"uste\", \"usted\", \"ustede\", \"utilidade\", \"valle\", \"vario\", \"vario\", \"vario\", \"vario\", \"vario\", \"vario\", \"vaud\", \"vece\", \"vece\", \"vece\", \"vece\", \"vehemente\", \"venerable\", \"venian\", \"ver\", \"ver\", \"ver\", \"vera\", \"verdad\", \"verde\", \"verla\", \"verse\", \"version\", \"version\", \"version\", \"vestir\", \"viage\", \"vicio\", \"viene\", \"vino\", \"vio\", \"virtud\", \"virtude\", \"virus\", \"vision\", \"vision\", \"vision\", \"vision\", \"visto\", \"viveza\", \"voce\", \"volver\", \"volvio\", \"volvio\", \"vox\", \"voy\", \"voz\", \"would\", \"would\", \"would\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 7, 5, 10, 4, 19, 9, 16, 3, 17, 18, 13, 15, 12, 1, 8, 11, 14, 2, 20]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1031397348214231684366523049\", ldavis_el1031397348214231684366523049_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1031397348214231684366523049\", ldavis_el1031397348214231684366523049_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1031397348214231684366523049\", ldavis_el1031397348214231684366523049_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "5      0.352288 -0.099349       1        1  16.291346\n",
              "6      0.122901  0.062511       2        1  10.576420\n",
              "4      0.202905 -0.137666       3        1   7.791522\n",
              "9      0.134328  0.292510       4        1   7.116217\n",
              "3      0.018286 -0.068858       5        1   6.056929\n",
              "18     0.092256 -0.091460       6        1   5.299422\n",
              "8     -0.000829  0.008586       7        1   5.297818\n",
              "15     0.010105  0.152856       8        1   4.771353\n",
              "2      0.024288  0.124232       9        1   4.456505\n",
              "16    -0.119093 -0.034894      10        1   4.284842\n",
              "17     0.020209 -0.044257      11        1   4.244612\n",
              "12    -0.054276  0.009986      12        1   3.820851\n",
              "14    -0.093869 -0.012386      13        1   3.077479\n",
              "11    -0.070792 -0.005510      14        1   2.728739\n",
              "0     -0.097082 -0.023183      15        1   2.725170\n",
              "7     -0.084537 -0.019646      16        1   2.560807\n",
              "10    -0.108554 -0.026045      17        1   2.554566\n",
              "13    -0.105449 -0.033460      18        1   2.390521\n",
              "1     -0.120984 -0.025660      19        1   2.229352\n",
              "19    -0.122100 -0.028307      20        1   1.725529, topic_info=              Term         Freq        Total Category  logprob  loglift\n",
              "4886          uste  2553.000000  2553.000000  Default  30.0000  30.0000\n",
              "113            pue  4416.000000  4416.000000  Default  29.0000  29.0000\n",
              "1026           voz  2021.000000  2021.000000  Default  28.0000  28.0000\n",
              "60             dio  1565.000000  1565.000000  Default  27.0000  27.0000\n",
              "8552         usted  1367.000000  1367.000000  Default  26.0000  26.0000\n",
              "...            ...          ...          ...      ...      ...      ...\n",
              "19052   reconocian    16.280565    17.195625  Topic20  -5.9356   4.0050\n",
              "27573        sevre    16.092812    17.007872  Topic20  -5.9472   4.0043\n",
              "1829   atribucione    16.061417    16.976477  Topic20  -5.9492   4.0042\n",
              "84      localidade    17.745321    82.529816  Topic20  -5.8495   2.5226\n",
              "925            ver    17.130819    75.557877  Topic20  -5.8847   2.5756\n",
              "\n",
              "[793 rows x 6 columns], token_table=       Topic      Freq       Term\n",
              "term                             \n",
              "8775       4  0.994367     abrigo\n",
              "2432      12  0.987227  accidente\n",
              "672        3  0.230853     accion\n",
              "672       12  0.761814     accion\n",
              "43249     14  0.953157    achaque\n",
              "...      ...       ...        ...\n",
              "29559     17  0.990668        voy\n",
              "1026       5  0.999400        voz\n",
              "140        2  0.993442      would\n",
              "140        5  0.001672      would\n",
              "140       20  0.005017      would\n",
              "\n",
              "[973 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 7, 5, 10, 4, 19, 9, 16, 3, 17, 18, 13, 15, 12, 1, 8, 11, 14, 2, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K39WrAqEl4z7",
        "colab_type": "text"
      },
      "source": [
        "Some conclusions about this visualization. On the Left side, we can see different bubbles of different sizes. Each bubble represents a topic. As we can imagine, th**e larger the bubble, the more frequent is that topic**  \n",
        "\n",
        "  \n",
        " A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
        "\n",
        " \n",
        "A model with too many topics, which happens in our case will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n",
        "\n",
        "Alright, if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic.\n",
        "\n",
        "We have successfully built a good looking topic model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBPzEAQ_naut",
        "colab_type": "text"
      },
      "source": [
        "## 9. Things To test in this Area. \n",
        "\n",
        "Heres a list of things we could try in this model. I'm sure some of them would improve the quality of the output.\n",
        "\n",
        "1. **Multilingual Document Classification**. The idea here would be to build an agnostic language NLP application, able to train a document classifier on the dataset of one language and generalize its prediction capabilities to other language datasets. \n",
        "3. **Improve the Lemmatization**: the lematization process for Spanish is not well done. Unlike the English lemmatizer, spacy Spanish lemmatizer does not use PoS tagging information. What he does, is to pick the first match in a list of inflected verbs and lemmas. E.g of element : ideo idear, ideas idear, idea idear, ideamos idear, etc.\n",
        "\n",
        "\n",
        "2. **Build a LD Mallet Model**: We have seen gensim's inbuilt version of the LDA Algorithm. Mallet's versions use to give a better quality of topics.\n",
        "3. **Find  the optimal number of topics for LDA**. To do that, we could build many LDA models with different values of number of topics (k) and pick the one that gives the highest coherence value.\n",
        "4. **Finding the dominant topic in each sentence.** One of the practical application of topic modeling is to determine what topic a given document is about. To find that, we find the topic number that has the highest percentage contribution in that document.\n",
        "3. **Modify parameters in Gensim Model**: increasing min_count and threshold, we could have more solid topics for Spanish.\n",
        "4. **Check other algorithms, like LSA**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJcOLzWbsjDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}